{
  "generatedAt": "2025-09-10T19:05:04.824Z",
  "root": "src/_data",
  "files": [
    {
      "path": "src/_data/archivesNav.js",
      "ext": "js",
      "content": "import { buildArchiveNav } from '../../lib/archive-nav.js';\nexport default buildArchiveNav();\n"
    },
    {
      "path": "src/_data/branding.js",
      "ext": "js",
      "content": "export default {\n  logoSrc: '/assets/images/logo.png',\n  logoAlt: 'Effusion Labs logo',\n  logoSizes: '(max-width: 640px) 112px, 160px'\n};\n"
    },
    {
      "path": "src/_data/eleventyComputed.js",
      "ext": "js",
      "content": "const toArray = (v) => (Array.isArray(v) ? v : v ? [v] : []);\nconst normalizeTitle = (t) => {\n  if (typeof t === 'string') return t;\n  if (Array.isArray(t)) return t.filter((v) => v != null).map(String).join(' / ');\n  if (t && typeof t === 'object') return String(t.name ?? '');\n  return '';\n};\n\nexport default {\n  title: (data) => normalizeTitle(data.title),\n  tags: (data) => {\n    const merged = [...toArray(data.tags), ...toArray(data.analytic_lens), ...toArray(data.memory_ref), ...toArray(data.spark_type)].filter((v) => typeof v === 'string');\n    return Array.from(new Set(merged)).sort();\n  },\n  categories: (data) =>\n    toArray(data.spark_type)\n      .filter((v) => typeof v === 'string')\n      .sort(),\n};\n"
    },
    {
      "path": "src/_data/nav.js",
      "ext": "js",
      "content": "import { CONTENT_AREAS } from '../../lib/constants.js';\n\nconst areaLinks = CONTENT_AREAS.map((a) => ({\n  title: a.charAt(0).toUpperCase() + a.slice(1),\n  url: `/${a}/`,\n}));\n\nconst nav = [\n  { title: 'Showcase', url: '/' },\n  ...areaLinks,\n  { title: 'Map', url: '/map/' },\n  { title: 'Join the group', url: 'https://github.com/orgs/effusion-labs/discussions', external: true },\n  { title: 'GitHub', url: 'https://github.com/effusion-labs/effusion-labs', external: true },\n].map((item, idx) => ({ ...item, order: idx + 1 }));\n\nexport default nav;\n"
    },
    {
      "path": "src/_data/provenance.11ty.js",
      "ext": "js",
      "content": "// Build a global provenance index by scanning products' provenance_ref JSONL files.\nimport fs from 'node:fs';\nimport fsp from 'node:fs/promises';\nimport path from 'node:path';\nimport { fileURLToPath } from 'node:url';\n\nconst __dirname = path.dirname(fileURLToPath(import.meta.url));\nconst ROOT = path.resolve(__dirname, '..');\n\nconst readJsonl = async (abs) => {\n  try {\n    const raw = await fsp.readFile(abs, 'utf8');\n    return raw.split('\\n').map(l=>l.trim()).filter(Boolean).map(l=>{ try { return JSON.parse(l); } catch { return null; } }).filter(Boolean);\n  } catch { return []; }\n};\nconst hostname = (u='') => { try { return new URL(u).hostname; } catch { return ''; } };\n\nexport default async function (data = {}) {\n  const collections = data?.collections || {};\n  const archiveProducts = Array.isArray(collections.archiveProducts) ? collections.archiveProducts : [];\n  const provToProduct = new Map();\n  for (const p of archiveProducts) {\n    const ref = p?.data?.provenance_ref;\n    if (ref && typeof ref === 'string') {\n      const rel = ref.startsWith('/') ? ref.slice(1) : ref;\n      const abs = path.join(ROOT, rel);\n      provToProduct.set(path.resolve(abs), p.data);\n    }\n  }\n  const hosts = new Map(); const currencies = new Map(); const markets = new Map(); const products = new Map();\n  const push = (m,k,init)=>{ if(!m.has(k)) m.set(k, typeof init==='function'?init(): (init??{})); return m.get(k); };\n\n  for (const [absJsonl, pdata] of provToProduct.entries()) {\n    const entries = await readJsonl(absJsonl);\n    if (!entries.length) continue;\n    const ps = push(products, pdata.productSlug, ()=>({ entries:[], hosts:new Set(), currencies:new Set(), markets:new Set(), first:null, last:null, url:pdata.url, title:pdata.title||pdata.product_id||pdata.productSlug, companySlug:pdata.companySlug, lineSlug:pdata.lineSlug, charSlug:pdata.charSlug, seriesSlug:pdata.seriesSlug }));\n    for (const e of entries) {\n      const h = hostname(e.url || e.source || '');\n      const ccy = (e.currency||'').toString().trim().toUpperCase();\n      const mkt = (e.market||e.region||'').toString().trim().toUpperCase();\n      const price = typeof e.price==='number'? e.price : (Number(e.price)||null);\n      const ts = e.retrieved_at || e.date || e.timestamp || null;\n      ps.entries.push({ host:h, url:e.url||'', title:e.title||'', price, currency:ccy||null, market:mkt||null, retrieved_at:ts });\n      if(h) ps.hosts.add(h); if(ccy) ps.currencies.add(ccy); if(mkt) ps.markets.add(mkt);\n      if(ts){ const t=new Date(ts).getTime(); if(!Number.isNaN(t)){ if(!ps.first||t<ps.first) ps.first=t; if(!ps.last||t>ps.last) ps.last=t; } }\n      if(h){ const hs=push(hosts,h,()=>({host:h, entries:0, products:new Set(), first:null,last:null})); hs.entries+=1; hs.products.add(pdata.productSlug); if(ts){ const t=new Date(ts).getTime(); if(!Number.isNaN(t)){ if(!hs.first||t<hs.first) hs.first=t; if(!hs.last||t>hs.last) hs.last=t; } } }\n      if(ccy){ const cs=push(currencies,ccy,()=>({code:ccy, entries:0, min:null, max:null, products:new Set()})); cs.entries+=1; cs.products.add(pdata.productSlug); if(typeof price==='number'){ if(cs.min==null||price<cs.min) cs.min=price; if(cs.max==null||price>cs.max) cs.max=price; } }\n      if(mkt){ const ms=push(markets,mkt,()=>({code:mkt, entries:0, products:new Set()})); ms.entries+=1; ms.products.add(pdata.productSlug); }\n    }\n  }\n  const toArr=(m,cmp)=>Array.from(m.values()).sort(cmp);\n  const hostsArr = toArr(hosts,(a,b)=>b.entries-a.entries); hostsArr.forEach(h=>h.products=Array.from(h.products));\n  const currenciesArr = toArr(currencies,(a,b)=>b.entries-a.entries); currenciesArr.forEach(c=>c.products=Array.from(c.products));\n  const marketsArr = toArr(markets,(a,b)=>b.entries-a.entries); marketsArr.forEach(m=>m.products=Array.from(m.products));\n  const productsArr = Array.from(products.entries()).sort((a,b)=> (b[1]?.entries.length??0)-(a[1]?.entries.length??0)).map(([slug,v])=>({ slug, ...v, hosts:Array.from(v.hosts), currencies:Array.from(v.currencies), markets:Array.from(v.markets) }));\n  return { stats:{ products:productsArr.length, hosts:hostsArr.length, currencies:currenciesArr.length, markets:marketsArr.length, entries:productsArr.reduce((n,p)=>n+p.entries.length,0) }, hosts:hostsArr, currencies:currenciesArr, markets:marketsArr, products:productsArr, byProduct:Object.fromEntries(productsArr.map(p=>[p.slug,p])) };\n}\n"
    },
    {
      "path": "src/_data/resume.json",
      "ext": "json",
      "content": "{\n  \"name\": \"Christopher Ortega\",\n  \"title\": \"LLM Engineering • LLMOps • Data Platforms\",\n  \"location\": \"Denver, CO\",\n  \"phoneNote\": \"Shareable on request via email\",\n  \"email\": \"denverchrisortega@gmail.com\",\n  \"linkedin\": \"https://linkedin.com/in/denverchrisortega\",\n  \"website\": \"https://effusionlabs.com\",\n  \"github\": \"https://github.com/toxicwind\",\n  \"downloadPdf\": \"/assets/Christopher_Ortega_Resume_2025.pdf\",\n  \"ogImage\": \"/assets/og/resume-christopher-ortega.png\",\n  \"updated\": \"2025-09-06\",\n\n  \"address\": {\n    \"@type\": \"PostalAddress\",\n    \"addressLocality\": \"Denver\",\n    \"addressRegion\": \"CO\",\n    \"addressCountry\": \"US\"\n  },\n\n  \"summary\": \"Software engineer with 6+ years across backend services and streaming data systems, now centered on LLM applications and LLMOps. Built and operated APIs and pipelines on AWS (EMR, Lambda, Kinesis, S3), containerized services on Kubernetes, and delivered search/analytics with Elasticsearch. Focus areas: retrieval that returns the right context, evaluation gates that block bad releases, and dashboards that surface drift early.\",\n\n  \"highlights\": [\n    {\n      \"title\": \"HackAPrompt 2025\",\n      \"value\": \"Top-10 (#7)\",\n      \"sub\": \"Adversarial prompt contest\"\n    },\n    {\n      \"title\": \"High-throughput data\",\n      \"value\": \"10+ TB/day\",\n      \"sub\": \"Scala/Spark • Kafka/Kinesis/Lambda\"\n    },\n    {\n      \"title\": \"API governance\",\n      \"value\": \"RBAC + OpenAPI\",\n      \"sub\": \"Spring Security • JWT • versioning\"\n    },\n    {\n      \"title\": \"Release hygiene\",\n      \"value\": \"CI/CD + K8s\",\n      \"sub\": \"GitLab checks • containerized\"\n    }\n  ],\n\n  \"skills\": {\n    \"groups\": [\n      {\n        \"name\": \"AI / LLM\",\n        \"items\": [\n          {\n            \"name\": \"Prompt design\",\n            \"hint\": \"Task/format constraints, system prompting, self-checks\"\n          },\n          {\n            \"name\": \"Retrieval / RAG\",\n            \"hint\": \"Chunking heuristics, hybrid search, re-ranking, citations\"\n          },\n          {\n            \"name\": \"Evaluation / metrics\",\n            \"hint\": \"Small gold sets, pass@k, coverage/latency/safety gates\"\n          },\n          {\n            \"name\": \"Safety controls\",\n            \"hint\": \"Guardrails, allow/deny lists, output sanitization\"\n          },\n          { \"name\": \"PyTorch\" },\n          { \"name\": \"Transformers\" },\n          { \"name\": \"LangChain\" },\n          { \"name\": \"Ollama\" }\n        ]\n      },\n      {\n        \"name\": \"Backend & Data\",\n        \"items\": [\n          { \"name\": \"Python\" },\n          { \"name\": \"Scala (background)\" },\n          { \"name\": \"Spark\", \"hint\": \"Batch + streaming on EMR\" },\n          {\n            \"name\": \"Elasticsearch\",\n            \"hint\": \"Index design, aggregations, analyzers\"\n          },\n          { \"name\": \"Kafka\" },\n          { \"name\": \"Kinesis\" },\n          { \"name\": \"pandas\" },\n          { \"name\": \"NumPy\" }\n        ]\n      },\n      {\n        \"name\": \"Cloud & DevOps\",\n        \"items\": [\n          {\n            \"name\": \"AWS\",\n            \"hint\": \"EMR, Lambda, Kinesis, S3, CloudWatch, RDS\"\n          },\n          { \"name\": \"Kubernetes\" },\n          { \"name\": \"Terraform\" },\n          { \"name\": \"Docker\" },\n          { \"name\": \"GitLab CI/CD\" }\n        ]\n      },\n      {\n        \"name\": \"APIs & Practices\",\n        \"items\": [\n          { \"name\": \"REST\" },\n          {\n            \"name\": \"OpenAPI\",\n            \"hint\": \"Versioning, schema linting, compatibility checks\"\n          },\n          { \"name\": \"JWT/OAuth2\" },\n          {\n            \"name\": \"Release checks\",\n            \"hint\": \"Quality bars + rollout/rollback playbooks\"\n          },\n          { \"name\": \"Observability\", \"hint\": \"Metrics, logs, traces, SLOs\" },\n          { \"name\": \"Response playbooks\" },\n          { \"name\": \"TRDs\" },\n          { \"name\": \"BDD acceptance\" }\n        ]\n      }\n    ]\n  },\n\n  \"tools\": [\n    \"VS Code\",\n    \"Git\",\n    \"GitLab\",\n    \"OpenAPI Generator\",\n    \"Postman\",\n    \"cURL\",\n    \"jq\",\n    \"DBeaver\",\n    \"Markdown / MDX\",\n    \"Eleventy (11ty)\",\n    \"Tailwind 4\",\n    \"Nunjucks\"\n  ],\n\n  \"experience\": [\n    {\n      \"company\": \"Independent Engineering & Security Research\",\n      \"role\": \"Engineer / Consultant\",\n      \"start\": \"Dec 2023\",\n      \"end\": \"\",\n      \"location\": \"Denver, CO\",\n      \"highlights\": [\n        \"HackAPrompt 2025 — Top-10 (7th): turned jailbreak tactics into repeatable tests and mitigations; added rollout controls for accuracy and safety with shadow and canary runs.\",\n        \"Authored evaluation suites (200+ prompts) with Positive/Negative/Risk cases; checks for groundedness (“no citation → no claim”), refusal-appropriateness, unsafe-rate, and p50/p95; deltas: +9 accuracy points, p95 ≤1.8s, unsafe probes ~0 on re-tests.\",\n        \"Patent Intelligence Agent (consulting, private client): constrained Q&A over patent corpora with hybrid semantic + CPC/IPC filtering, claim/abstract parsing, citation-trail review, and landscape digests; outputs include inline citations and limitation mapping; added RBAC, prompt-safety controls, and clear notices.\",\n        \"Built local LLM workflows with modular orchestration (prompt-rewrite steps, LoRA adapters, graph-style configs) to compare prompts/models offline with reproducible inputs.\",\n        \"Engineered a modular Eleventy (11ty) 3.x system (Nunjucks, Tailwind 4) with markdown-it extensions, interlinking/navigation plugins, and GitHub Actions for reproducible builds.\"\n      ],\n      \"tags\": [\n        \"RAG\",\n        \"Guardrails\",\n        \"RBAC\",\n        \"OpenAPI\",\n        \"Elasticsearch\",\n        \"LangChain\",\n        \"PyTorch\",\n        \"Ollama\",\n        \"Tailwind 4\",\n        \"Eleventy 3\"\n      ]\n    },\n    {\n      \"company\": \"Charter Communications\",\n      \"role\": \"Senior Software Engineer / Platform Tech Lead\",\n      \"start\": \"Feb 2019\",\n      \"end\": \"Nov 2023\",\n      \"location\": \"Denver, CO\",\n      \"highlights\": [\n        \"Shaped backend architecture for segmentation/measurement across millions of subscribers; aligned product, SRE, and engineering on release criteria and operational readiness.\",\n        \"Implemented role-based access with Spring Security + JWT; enforced OpenAPI hygiene and versioning to keep partner integrations stable across releases.\",\n        \"Built Scala/Spark batch + stream services processing 10+ TB/day; added Kafka·Kinesis·Lambda pathways to support near-real-time activation triggers.\",\n        \"Drove Elasticsearch indexing/aggregation patterns for complex eligibility queries; containerized on Kubernetes and enforced CI/CD checks in GitLab.\"\n      ],\n      \"tags\": [\n        \"Scala\",\n        \"Spark\",\n        \"Kafka\",\n        \"Kinesis\",\n        \"AWS EMR\",\n        \"Lambda\",\n        \"Elasticsearch\",\n        \"Kubernetes\",\n        \"GitLab CI\",\n        \"Spring Security\",\n        \"JWT\",\n        \"OpenAPI\"\n      ]\n    },\n    {\n      \"company\": \"Access Data Consulting (Contract @ Charter)\",\n      \"role\": \"Software Engineer (Frontend/Platform)\",\n      \"start\": \"Sep 2017\",\n      \"end\": \"Feb 2019\",\n      \"location\": \"Denver, CO\",\n      \"highlights\": [\n        \"Moved legacy interfaces to React + TypeScript; introduced shared components and patterns adopted across internal tools.\",\n        \"Delivered accessible dashboards tied to real-time targeting APIs; partnered with backend and QA on staged rollouts.\"\n      ],\n      \"tags\": [\n        \"React\",\n        \"TypeScript\",\n        \"Design systems\",\n        \"Accessibility\",\n        \"Dashboards\",\n        \"API integration\"\n      ]\n    }\n  ],\n\n  \"projects\": [\n    {\n      \"name\": \"HackAPrompt Top-10 (7th)\",\n      \"subtitle\": \"Jailbreak and prompt‑injection challenge (2025)\",\n      \"badge\": \"security\",\n      \"blurb\": \"Placed 7th; built reproducible jailbreak tests with shadow and canary rollouts that enforced accuracy and safety thresholds.\",\n      \"tags\": [\n        \"LLM Safety\",\n        \"Prompt Engineering\",\n        \"Red Teaming\",\n        \"Guardrails\",\n        \"Eval Harness\",\n        \"Retrieval\",\n        \"Function Calling\",\n        \"Unicode/Confusables\"\n      ],\n      \"url\": \"/projects/hackaprompt-2025/\"\n    },\n    {\n      \"name\": \"Patent Intelligence Agent\",\n      \"badge\": \"client\",\n      \"subtitle\": \"Agentic Q&A over patent corpora\",\n      \"blurb\": \"Hybrid search with CPC/IPC filters and citation trails; maps claims and limitations and returns answers with inline citations and scope notes.\",\n      \"tags\": [\"RAG\", \"Guardrails\", \"RBAC\", \"Citations\"],\n      \"url\": \"/projects/patent-intelligence-agent/\"\n    },\n    {\n      \"name\": \"LLM Release Watcher\",\n      \"badge\": \"ops\",\n      \"subtitle\": \"Safe, measurable LLM releases\",\n      \"blurb\": \"Monitors accuracy, latency, and safety metrics with shadow runs, timed canaries, and automatic rollback.\",\n      \"tags\": [\"CI/CD gates\", \"Metrics\", \"Playbooks\"],\n      \"url\": \"/projects/llm-release-watcher/\"\n    },\n    {\n      \"name\": \"RAG Quality Kit\",\n      \"badge\": \"evals\",\n      \"subtitle\": \"Retrieval reliability\",\n      \"blurb\": \"Small gold sets and sanity checks for chunking, indexing, and retrieval; scripts to catch regressions early and visualize coverage.\",\n      \"tags\": [\"Eval sets\", \"Chunking\", \"Index heuristics\"],\n      \"url\": \"\"\n    },\n    {\n      \"name\": \"Local-LLM Inference Graphs\",\n      \"badge\": \"infra\",\n      \"subtitle\": \"Reproducible offline A/B\",\n      \"blurb\": \"Configurable offline A/B harness for prompts, models, and tools with LoRA adapters and rewrite steps; designed for reproducible experiments.\",\n      \"tags\": [\"LoRA\", \"Offline A/B\", \"Pipelines\"],\n      \"url\": \"\"\n    }\n  ],\n\n  \"education\": [\n    {\n      \"school\": \"Metropolitan State University of Denver\",\n      \"degree\": \"B.S., Computer Information Systems\",\n      \"meta\": \"\",\n      \"start\": \"2012\",\n      \"end\": \"2016\"\n    },\n    {\n      \"school\": \"Front Range Community College\",\n      \"degree\": \"A.S., Business Management\",\n      \"meta\": \"\",\n      \"start\": \"2010\",\n      \"end\": \"2012\"\n    }\n  ]\n  ,\n  \"projectPages\": {\n    \"llm-release-watcher\": {\n      \"title\": \"LLM Release Watcher\",\n      \"badge\": \"ops\",\n      \"blurb\": \"A lightweight guardrail for shipping LLM features: shadow runs, timed canaries, accuracy/safety gates, and automatic rollback.\",\n      \"highlights\": [\n        \"Shadow traffic + metric compare (accuracy, latency, safety).\",\n        \"Timed canary with promotion thresholds.\",\n        \"Rollback playbooks and post‑release verification.\"\n      ],\n      \"stack\": [\"Metrics\", \"Dashboards\", \"CI/CD gates\", \"Playbooks\"],\n      \"status\": \"Open to share patterns and code snippets on request.\"\n    },\n    \"patent-intelligence-agent\": {\n      \"title\": \"Patent Intelligence Agent\",\n      \"badge\": \"client\",\n      \"blurb\": \"Agentic Q&A over patent corpora with CPC/IPC filters, citation trails, and limitation mapping. Returns scoped answers with inline citations.\",\n      \"highlights\": [\n        \"Hybrid search (semantic + CPC/IPC filters + re‑rank).\",\n        \"Citation trail preview and export.\",\n        \"Claim/limitation mapping with uncertainty notes.\",\n        \"RBAC + audit logging; guarded outputs.\"\n      ],\n      \"stack\": [\"RAG\", \"Guardrails\", \"RBAC\", \"Elasticsearch\", \"LangChain\", \"PyTorch\"],\n      \"status\": \"Private client work; demo available upon request.\"\n    }\n  }\n}\n"
    },
    {
      "path": "src/_data/sections.json",
      "ext": "json",
      "content": "{\n  \"sparks\": {\n    \"intro\": \"Here you'll find nascent ideas, quick notes, and experimental fragments that may one day ignite into full concepts or projects.\"\n  },\n  \"concepts\": {\n    \"intro\": \"This is the central hub for all individual concepts explored within the lab.\"\n  },\n  \"projects\": {\n    \"intro\": \"This is the central hub for all projects explored within the lab.\"\n  }\n}\n"
    },
    {
      "path": "src/_data/site.json",
      "ext": "json",
      "content": "{\n  \"heroBand\": false,\n  \"heroBandRings\": false\n}\n"
    }
  ]
}
