{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae2bfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'py312-jupyter-2025 (Python 3.12.11)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. document.addEventListener is not a function"
     ]
    }
   ],
   "source": [
    "# --- Dependencies ---\n",
    "!pip install --upgrade jinja2 pandas requests seaborn matplotlib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c302856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup ---\n",
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from datetime import datetime\n",
    "import io\n",
    "import base64\n",
    "import math\n",
    "\n",
    "# --- Constants ---\n",
    "BASE_V2 = \"https://api-g.weedmaps.com/discovery/v2\"\n",
    "BASE_V1 = \"https://api-g.weedmaps.com/discovery/v1\"\n",
    "LATLNG = \"39.642867,-104.826711\"  # Aurora, CO\n",
    "HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:141.0) Gecko/20100101 Firefox/141.0\",\n",
    "        \"Accept\": \"application/json, */*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"none\",\n",
    "        \"Sec-Fetch-User\": \"?1\",\n",
    "        \"wm-user-latlng\": LATLNG,\n",
    "        \"If-None-Match\": \"W/\\\"2d61d944c89769b44d46f9622ac2427b\\\"\",\n",
    "        \"Priority\": \"u=0, i\"\n",
    "}\n",
    "HEADERSV1 = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:141.0) Gecko/20100101 Firefox/141.0\",\n",
    "    \"Accept\": \"application/json, */*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Authorization\": \"Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzUxMiJ9.eyJqdGkiOiJON3pucGt1VSIsImV4cCI6MTc1NzQ2NzcwNSwiaXNzIjoid2VlZG1hcHMuY29tIiwiaGFzdXJhIjp7ImFsbG93ZWQtcm9sZXMiOlsidXNlciJdfSwic3ViIjoiNTIyNTUiLCJzY29wZSI6InVzZXIifQ.hLVKwu92I4QAyxgov9Uf78ZcWKjZMSU0LxgKGPBfAjf0KNuQ0aGJH36qgfG3xfdebjdeHgY6ajZSHJUuKSlnmuOGNtiLowzj2ZH2qwO-cjpwH3SKMHDdEPUk5_mQSdGxtXJ9FeJt7vzR6blnQR5KAuTJQ00UKQsRjDyQeD8upKJY7ZqEMibcHUHsP6Uo5WqNA6VN9S9vuozX52AzUaU7IAqCfENMMzMrp-e9qr5XzNeljsEMwf5TC4koC6xdQbbfFWH7EGzvQULsIrRj8d9eUKlEM59aWsF-bCldVjH7MY4HxvYsea83H_GrntmOgGpVrCIZq10vAwOYUh9GMMkmCeQzGr_aAXALj0QsDzHt_AfMtsQmz3C_qi-evJB12xvt4hMNyD_zhN1ZmYbsvwDacnBozrX_tDkQR3x6SQyuWNS9pzM3wdsSAx2idJWgURc_PH4MM1GCzaI7vkIl25MPz362MmoqCG8FxCweZz0BMLVOa4F4YqsGmIfVdObIHunV773oipRl3nOmMxVX95EDgvN6WgoPAlkEK3KkMAn4Cnf_fn3f8tiSLanUL72Ex9DSpKs-M4S02lO1SXWIkk-__H_X_s9Rgz5QDC3wrYTl2quhLuz1OSQ2gW4-9ERuuGteduEYfGFT6bC-GIw8TyEPb4j6ksh_TMzikzGJEWej-oE\",\n",
    "    \"wm-user-latlng\": LATLNG,\n",
    "    \"Referer\": \"https://weedmaps.com/\",\n",
    "}\n",
    "\n",
    "print(\"✅ Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21ce268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Find & Select Dispensary ---\n",
    "print(\"Searching for nearby medical dispensaries...\")\n",
    "lat, lng = map(float, LATLNG.split(','))\n",
    "RADIUS_MI = 20\n",
    "lat_deg = RADIUS_MI / 69.0\n",
    "lng_deg = RADIUS_MI / (69.0 * math.cos(math.radians(lat)))\n",
    "bounding_box = f\"{lat - lat_deg},{lng - lng_deg},{lat + lat_deg},{lng + lng_deg}\"\n",
    "\n",
    "params = {\n",
    "    \"latlng\": LATLNG, \"filter[any_retailer_services][]\": \"storefront\",\n",
    "    \"filter[amenities][]\": \"is_medical\", \"filter[bounding_box]\": bounding_box,\n",
    "    \"sort_by\": \"position_distance\", \"sort_order\": \"asc\", \"page_size\": 100,\n",
    "}\n",
    "response = requests.get(f\"{BASE_V2}/listings\", headers=HEADERS, params=params)\n",
    "response.raise_for_status()\n",
    "listings = response.json().get(\"data\", {}).get(\"listings\", [])\n",
    "dispensary_list_df = pd.json_normalize(listings, sep=\".\")\n",
    "print(f\"Found {len(dispensary_list_df)} total medical storefronts.\")\n",
    "\n",
    "# --- Select a Dispensary ---\n",
    "# Set the target dispensary slug here, or pick a random one from the 5 closest dispensaries.\n",
    "# To randomly select from the 5 closest, use the following line:\n",
    "#DISPENSARY_SLUG = dispensary_list_df.head(5)[\"slug\"].sample(1).values[0]\n",
    "# Or set to a specific slug, e.g.:\n",
    "# DISPENSARY_SLUG = \"little-brown-house\"  # <-- Change this to your target\n",
    "#DISPENSARY_SLUG = \"magic-city-cannabis-colorado\"\n",
    "DISPENSARY_SLUG = \"reefer-madness\"\n",
    "if DISPENSARY_SLUG in dispensary_list_df[\"slug\"].values:\n",
    "    dispensary_info = dispensary_list_df[dispensary_list_df['slug'] == DISPENSARY_SLUG].iloc[0]\n",
    "    print(f\"\\n✅ Selected Dispensary: {dispensary_info.get('name', DISPENSARY_SLUG)}\")\n",
    "else:\n",
    "    # Create a dummy object if not found, so the report can still run\n",
    "    dispensary_info = pd.Series({'name': DISPENSARY_SLUG.replace('-', ' ').title()})\n",
    "    print(f\"\\n⚠️  Slug '{DISPENSARY_SLUG}' not found in list. Using slug as name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f442371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Full Flower dataset, paginated & flattened ---\n",
    "page, page_size = 1, 50\n",
    "flower_pool = []\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        \"filter[license_type]\": \"medical\",\n",
    "        \"filter[any_client_categories][]\": \"flower-category-pages\",\n",
    "        \"sort_by\": \"min_price\",\n",
    "        \"sort_order\": \"asc\",\n",
    "        \"page\": page,\n",
    "        \"page_size\": page_size,\n",
    "        \"include[]\": \"facets.categories\",\n",
    "    }\n",
    "    url = f\"{BASE_V1}/listings/dispensaries/{DISPENSARY_SLUG}/menu_items\"\n",
    "    resp = requests.get(url, headers=HEADERS, params=params)\n",
    "    resp.raise_for_status()\n",
    "    page_items = resp.json()[\"data\"][\"menu_items\"]\n",
    "\n",
    "    if not page_items:\n",
    "        break\n",
    "\n",
    "    flower_pool.extend(page_items)\n",
    "    print(f\"Fetched page {page}: {len(page_items)} items\")\n",
    "    if len(page_items) < page_size:\n",
    "        break\n",
    "    page += 1\n",
    "\n",
    "# flatten every nested level using dot-notation keys\n",
    "flower_df = pd.json_normalize(flower_pool, sep='.')\n",
    "print(f\"\\nTOTAL flower items fetched: {len(flower_df)}\")\n",
    "flower_df\n",
    "for col, val in flower_df.iloc[0].items():\n",
    "    print(f\"{col}: {val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Data & Create Final DataFrame (Corrected) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"⚙️ PROCESSING RAW DATA INTO A FLAT PRICE TABLE...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "OZ_TO_G = 28.35\n",
    "LEGAL_LIMIT_G = 2 * OZ_TO_G\n",
    "\n",
    "def format_grams(g):\n",
    "    \"\"\"Rounds gram weights to their common market values for display.\"\"\"\n",
    "    common_weights = [1, 3.5, 7, 14, 28, 57]\n",
    "    for w in common_weights:\n",
    "        if abs(g - w) < 0.4:\n",
    "            return f\"{w:g}g\"\n",
    "    return f\"{round(g, 1):g}g\"\n",
    "\n",
    "final_rows = []\n",
    "for item in flower_pool:\n",
    "    prices = item.get(\"prices\", {}) or {}\n",
    "    all_deals_raw = (prices.get(\"gram\") or []) + (prices.get(\"ounce\") or [])\n",
    "    if not all_deals_raw:\n",
    "        continue\n",
    "\n",
    "    # ⭐ Categorization: include \"Red Tier\" variants (e.g., \"Red-Tier\", \"Red -Tier\") as Shake/Popcorn/Trim\n",
    "    name = item.get('name', '') or ''\n",
    "    SHAKE_PATTERN = re.compile(r'\\b(shake|trim|popcorn|littles|red\\s*[-]?\\s*tier)\\b', flags=re.IGNORECASE)\n",
    "\n",
    "    if SHAKE_PATTERN.search(name):\n",
    "        report_category = 'Shake/Popcorn/Trim'\n",
    "    elif len(all_deals_raw) <= 2:\n",
    "        report_category = 'Pre-Pack Specialty'\n",
    "    else:\n",
    "        report_category = 'Bulk Value'\n",
    "\n",
    "    for p in all_deals_raw:\n",
    "        try:\n",
    "            gram_unit_price = float(p.get('gram_unit_price'))\n",
    "            weight_val = float((p.get('weight', {}) or {}).get('value'))\n",
    "            weight_unit = ((p.get('weight', {}) or {}).get('unit') or '').lower()\n",
    "            price = float(p.get('price'))\n",
    "            label = p.get('label')\n",
    "\n",
    "            # Normalize to grams (assume grams unless explicitly ounce-based)\n",
    "            weight_g = weight_val * OZ_TO_G if weight_unit.startswith('oz') else weight_val\n",
    "\n",
    "            # Basic validity checks (also enforce a 2 oz legal cap)\n",
    "            if not (weight_g > 0 and price > 0 and label and weight_g <= LEGAL_LIMIT_G):\n",
    "                continue\n",
    "\n",
    "            price_per_oz = gram_unit_price * OZ_TO_G\n",
    "            size_label_g = format_grams(weight_g)\n",
    "\n",
    "            final_rows.append({\n",
    "                'name': name,\n",
    "                'slug': item.get('slug'),\n",
    "                'report_category': report_category,\n",
    "                'size_label': size_label_g,\n",
    "                'price': price,\n",
    "                'price_per_oz': price_per_oz,\n",
    "                'weight_g': weight_g\n",
    "            })\n",
    "        except (ValueError, TypeError, AttributeError):\n",
    "            continue\n",
    "\n",
    "# --- Create the final DataFrame ---\n",
    "columns = ['name', 'slug', 'report_category', 'size_label', 'price', 'weight_g', 'price_per_oz']\n",
    "price_df = pd.DataFrame(final_rows)\n",
    "\n",
    "if not price_df.empty:\n",
    "    price_df = price_df[columns]\n",
    "    price_df.drop_duplicates(inplace=True)\n",
    "    price_df = price_df.sort_values('price_per_oz').reset_index(drop=True)\n",
    "\n",
    "print(f\"✅ Analysis complete. Created a flat price table with {len(price_df)} purchasable items.\")\n",
    "display(price_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935df2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Bands (per product), aesthetic like original, no collapse\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "if 'price_df' not in globals() or price_df is None or price_df.empty:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"p-4 mb-4 text-sm text-yellow-300 bg-yellow-900/50 rounded-lg border border-yellow-700\" role=\"alert\">\n",
    "      <span class=\"font-bold\">No Data:</span> Nothing to render for this dispensary.\n",
    "    </div>\"\"\"))\n",
    "else:\n",
    "    # Canonical: cheapest $/oz, break tie by larger size, drop Shake/Popcorn/Trim\n",
    "    canonical = (price_df.sort_values(['slug','price_per_oz','weight_g'], ascending=[True,True,False])\n",
    "                          .groupby('slug', as_index=False).head(1))\n",
    "    base = canonical[canonical['report_category']!='Shake/Popcorn/Trim'].copy()\n",
    "\n",
    "    labels = [\"≤ $60\", \"$61–$90\", \"$91–$120\", \"$121–$200\", \">$200\"]\n",
    "    bins   = [0, 60, 90, 120, 200, float('inf')]\n",
    "    bands_df = (base[['name','report_category','size_label','price','price_per_oz']]\n",
    "                .rename(columns={'name':'Product','report_category':'Category','size_label':'Best Size','price':'Best Price','price_per_oz':'Best $/Oz (28g)'}))\n",
    "    bands_df['Price Band'] = pd.cut(bands_df['Best $/Oz (28g)'], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    bands_df['Price Band'] = pd.Categorical(bands_df['Price Band'], categories=labels, ordered=True)\n",
    "    bands_df = bands_df.sort_values(['Price Band','Best $/Oz (28g)','Product']).reset_index(drop=True)\n",
    "\n",
    "    counts = bands_df['Price Band'].value_counts().reindex(labels, fill_value=0)\n",
    "    total  = max(len(bands_df), 1)\n",
    "    shares = (counts/total*100).round(0).astype(int)\n",
    "    chips  = \"\".join(\n",
    "        f\"\"\"<div class=\"bg-gray-800 border border-gray-700 rounded-lg p-3\">\n",
    "               <div class=\"text-sm text-gray-400\">{lbl} (28g)</div>\n",
    "               <div class=\"mt-1 text-lg font-semibold text-white\">{int(counts[lbl])}\n",
    "                 <span class=\"text-xs text-gray-400\">({shares[lbl]}%)</span></div>\n",
    "             </div>\"\"\"\n",
    "        for lbl in labels\n",
    "    )\n",
    "    def _tbl(sub):\n",
    "        return sub[['Product','Category','Best Size','Best Price','Best $/Oz (28g)']].to_html(\n",
    "            index=False, classes=\"w-full text-left my-4 text-base\", border=0, escape=False,\n",
    "            formatters={'Best Price':lambda x:f'${x:,.2f}', 'Best $/Oz (28g)':lambda x:f'${x:,.2f}'})\n",
    "    sections = [f\"\"\"<div class=\"mt-6\">\n",
    "          <h3 class=\"text-lg font-semibold text-white\">{lbl}</h3>\n",
    "          <div class=\"overflow-x-auto\">{_tbl(sub)}</div>\n",
    "        </div>\"\"\"\n",
    "        for lbl in labels if not bands_df[bands_df['Price Band'].astype(str)==lbl].empty\n",
    "        for sub in [bands_df[bands_df['Price Band'].astype(str)==lbl]]\n",
    "    ]\n",
    "\n",
    "    html = f\"\"\"\n",
    "    <section class=\"mb-6\">\n",
    "      <h2 class=\"text-3xl font-semibold text-cyan-400 border-b border-gray-700 pb-2\">Price band coverage (per product)</h2>\n",
    "      <div class=\"grid grid-cols-1 sm:grid-cols-3 lg:grid-cols-5 gap-3 mt-3\">{chips}</div>\n",
    "      {''.join(sections) if sections else \"<p class='text-gray-400 mt-4'>No products available after filters.</p>\"}\n",
    "    </section>\"\"\"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Optimized Medical Flower Price Report with Enhanced Error Handling & Performance ---\n",
    "\n",
    "import io\n",
    "import re\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =========================\n",
    "# SECTION 1: DATA VALIDATION & PREPARATION\n",
    "# =========================\n",
    "\n",
    "def validate_and_prepare_data():\n",
    "    \"\"\"Validate input data and handle edge cases gracefully.\"\"\"\n",
    "    try:\n",
    "        # Validate price_df exists and has required columns\n",
    "        if 'price_df' not in globals() or price_df.empty:\n",
    "            raise ValueError(\"No price data available\")\n",
    "        \n",
    "        required_cols = ['name', 'slug', 'report_category', 'size_label', 'price', 'weight_g', 'price_per_oz']\n",
    "        missing_cols = [col for col in required_cols if col not in price_df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Clean and validate data\n",
    "        clean_df = price_df.copy()\n",
    "        clean_df = clean_df.dropna(subset=['price_per_oz', 'weight_g', 'price'])\n",
    "        clean_df = clean_df[clean_df['price_per_oz'] > 0]\n",
    "        clean_df = clean_df[clean_df['price'] > 0]\n",
    "        \n",
    "        if clean_df.empty:\n",
    "            raise ValueError(\"No valid price data after cleaning\")\n",
    "        \n",
    "        return clean_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Data validation error: {e}\")\n",
    "        # Return minimal dummy data to prevent complete failure\n",
    "        return pd.DataFrame({\n",
    "            'name': ['Sample Product'],\n",
    "            'slug': ['sample-product'],\n",
    "            'report_category': ['Bulk Value'],\n",
    "            'size_label': ['1g'],\n",
    "            'price': [10.0],\n",
    "            'weight_g': [1.0],\n",
    "            'price_per_oz': [283.5]\n",
    "        })\n",
    "\n",
    "def safe_dispensary_info():\n",
    "    \"\"\"Safely extract dispensary information with fallbacks.\"\"\"\n",
    "    try:\n",
    "        if 'dispensary_info' in globals() and not dispensary_info.empty:\n",
    "            return {\n",
    "                'name': str(dispensary_info.get('name', 'Unknown Dispensary')),\n",
    "                'address': str(dispensary_info.get('address', '')),\n",
    "                'city': str(dispensary_info.get('city', '')),\n",
    "                'state': str(dispensary_info.get('state', '')),\n",
    "                'rating': float(dispensary_info.get('rating', 0)),\n",
    "                'reviews_count': int(dispensary_info.get('reviews_count', 0)),\n",
    "                'phone_number': str(dispensary_info.get('phone_number', 'N/A')),\n",
    "                'web_url': str(dispensary_info.get('web_url', '#'))\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Dispensary info error: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'name': 'Unknown Dispensary',\n",
    "        'address': '',\n",
    "        'city': '',\n",
    "        'state': '',\n",
    "        'rating': 0.0,\n",
    "        'reviews_count': 0,\n",
    "        'phone_number': 'N/A',\n",
    "        'web_url': '#'\n",
    "    }\n",
    "\n",
    "# Initialize validated data\n",
    "try:\n",
    "    price_df_clean = validate_and_prepare_data()\n",
    "    dispensary_data = safe_dispensary_info()\n",
    "    print(f\"✅ Data validation complete. Processing {len(price_df_clean)} valid items.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Critical error in data preparation: {e}\")\n",
    "    raise\n",
    "\n",
    "# =========================\n",
    "# SECTION 2: CORE DATA PROCESSING\n",
    "# =========================\n",
    "\n",
    "def calculate_category_order(df):\n",
    "    \"\"\"Calculate category order by median price with error handling.\"\"\"\n",
    "    try:\n",
    "        if df.empty:\n",
    "            return []\n",
    "        return (df.groupby('report_category')['price_per_oz']\n",
    "                .median()\n",
    "                .sort_values()\n",
    "                .index.tolist())\n",
    "    except Exception:\n",
    "        return df['report_category'].unique().tolist()\n",
    "\n",
    "def calculate_savings_analysis(df):\n",
    "    \"\"\"Calculate bulk savings with comprehensive error handling.\"\"\"\n",
    "    savings_detail = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        # Find multi-size products\n",
    "        multi_size_slugs = df['slug'].value_counts()[lambda s: s > 1].index\n",
    "        if len(multi_size_slugs) == 0:\n",
    "            return savings_detail\n",
    "        \n",
    "        multi_size_df = df[df['slug'].isin(multi_size_slugs)].copy()\n",
    "        \n",
    "        # Get min/max rows by weight per slug\n",
    "        min_rows = multi_size_df.loc[multi_size_df.groupby('slug')['weight_g'].idxmin()]\n",
    "        max_rows = multi_size_df.loc[multi_size_df.groupby('slug')['weight_g'].idxmax()]\n",
    "        \n",
    "        # Merge and calculate savings\n",
    "        small_cols = ['slug', 'name', 'report_category', 'size_label', 'weight_g', 'price', 'price_per_oz']\n",
    "        large_cols = ['slug', 'size_label', 'weight_g', 'price', 'price_per_oz']\n",
    "        \n",
    "        savings_detail = pd.merge(\n",
    "            min_rows[small_cols].rename(columns={\n",
    "                'size_label': 'size_label_small',\n",
    "                'weight_g': 'weight_g_small',\n",
    "                'price': 'price_small',\n",
    "                'price_per_oz': 'price_per_oz_small'\n",
    "            }),\n",
    "            max_rows[large_cols].rename(columns={\n",
    "                'size_label': 'size_label_large',\n",
    "                'weight_g': 'weight_g_large',\n",
    "                'price': 'price_large',\n",
    "                'price_per_oz': 'price_per_oz_large'\n",
    "            }),\n",
    "            on='slug',\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # Safe percentage calculation\n",
    "        savings_detail['savings_pct'] = np.where(\n",
    "            savings_detail['price_per_oz_small'] > 0,\n",
    "            (1 - (savings_detail['price_per_oz_large'] / savings_detail['price_per_oz_small'])) * 100,\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        savings_detail['delta_per_oz'] = (\n",
    "            savings_detail['price_per_oz_small'] - savings_detail['price_per_oz_large']\n",
    "        )\n",
    "        \n",
    "        # Keep only positive savings\n",
    "        savings_detail = (\n",
    "            savings_detail[savings_detail['savings_pct'] > 0]\n",
    "            .sort_values('savings_pct', ascending=False)\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Savings analysis error: {e}\")\n",
    "        savings_detail = pd.DataFrame()\n",
    "    \n",
    "    return savings_detail\n",
    "\n",
    "def efficient_sizes_analysis(df):\n",
    "    \"\"\"Calculate efficient sizes with improved error handling.\"\"\"\n",
    "    EPS = 1e-6\n",
    "    \n",
    "    def _efficient_sizes_df(group):\n",
    "        try:\n",
    "            g = group[['slug','name','size_label','weight_g','price','price_per_oz']].dropna().copy()\n",
    "            if g.empty:\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            g['ppoz_round'] = g['price_per_oz'].round(2)\n",
    "            g = g.sort_values(['ppoz_round','weight_g']).groupby('ppoz_round', as_index=False).head(1)\n",
    "            g = g.sort_values('weight_g').reset_index(drop=True)\n",
    "            \n",
    "            kept = []\n",
    "            best_ppoz_so_far = np.inf\n",
    "            \n",
    "            for _, row in g.iterrows():\n",
    "                p = row['price_per_oz']\n",
    "                if p < best_ppoz_so_far - EPS:\n",
    "                    kept.append(row)\n",
    "                    best_ppoz_so_far = p\n",
    "            \n",
    "            if kept:\n",
    "                return pd.DataFrame(kept).reset_index(drop=True).drop(columns=['ppoz_round'])\n",
    "            else:\n",
    "                idx = group['price_per_oz'].idxmin()\n",
    "                return group.loc[[idx], ['slug','name','size_label','weight_g','price','price_per_oz']]\n",
    "                \n",
    "        except Exception:\n",
    "            # Fallback to best price per oz\n",
    "            try:\n",
    "                idx = group['price_per_oz'].idxmin()\n",
    "                return group.loc[[idx], ['slug','name','size_label','weight_g','price','price_per_oz']]\n",
    "            except Exception:\n",
    "                return pd.DataFrame()\n",
    "    \n",
    "    def _sizes_badge_from_df(sizedf):\n",
    "        try:\n",
    "            def _key(lbl):\n",
    "                try:\n",
    "                    return float(lbl.replace('g',''))\n",
    "                except Exception:\n",
    "                    return 9e9\n",
    "            labels = sorted(sizedf['size_label'].tolist(), key=_key)\n",
    "            return \" → \".join(labels)\n",
    "        except Exception:\n",
    "            return \"N/A\"\n",
    "    \n",
    "    # Build efficient sizes map\n",
    "    eff_map = {}\n",
    "    for slug, g in df.groupby('slug', sort=False):\n",
    "        try:\n",
    "            eff_map[slug] = _efficient_sizes_df(g)\n",
    "        except Exception:\n",
    "            eff_map[slug] = pd.DataFrame()\n",
    "    \n",
    "    return eff_map, _sizes_badge_from_df\n",
    "\n",
    "def calculate_best_per_slug(df, eff_map, sizes_badge_func, savings_detail):\n",
    "    \"\"\"Calculate best product per slug with error handling.\"\"\"\n",
    "    try:\n",
    "        rows = []\n",
    "        for _, g in df.groupby('slug', sort=False):\n",
    "            g2 = g.sort_values(['price_per_oz','weight_g'], ascending=[True, False])\n",
    "            rows.append(g2.iloc[0])\n",
    "        \n",
    "        best_per_slug = pd.DataFrame(rows).copy()\n",
    "        best_per_slug['Efficient Sizes'] = best_per_slug['slug'].map(\n",
    "            lambda s: sizes_badge_func(eff_map.get(s, pd.DataFrame()))\n",
    "        )\n",
    "        \n",
    "        # Merge savings data\n",
    "        if not savings_detail.empty:\n",
    "            best_per_slug = best_per_slug.merge(\n",
    "                savings_detail[['slug','savings_pct']], \n",
    "                on='slug', how='left'\n",
    "            )\n",
    "        else:\n",
    "            best_per_slug['savings_pct'] = pd.NA\n",
    "            \n",
    "        return best_per_slug\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Best per slug calculation error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Execute core processing\n",
    "cat_order = calculate_category_order(price_df_clean)\n",
    "savings_detail = calculate_savings_analysis(price_df_clean)\n",
    "eff_map, sizes_badge_func = efficient_sizes_analysis(price_df_clean)\n",
    "best_per_slug = calculate_best_per_slug(price_df_clean, eff_map, sizes_badge_func, savings_detail)\n",
    "\n",
    "# =========================\n",
    "# SECTION 3: EXECUTIVE SUMMARY CALCULATIONS\n",
    "# =========================\n",
    "\n",
    "def calculate_executive_metrics(best_per_slug, savings_detail):\n",
    "    \"\"\"Calculate all executive summary metrics with error handling.\"\"\"\n",
    "    try:\n",
    "        if best_per_slug.empty:\n",
    "            return {\n",
    "                'best_ppoz': 0, 'best_name': 'N/A', 'best_size': 'N/A', 'best_price': 0,\n",
    "                'overall_median': 0, 'overall_p25': 0, 'overall_p75': 0,\n",
    "                'cat_stats': [], 'band_counts': pd.Series(), 'band_shares': pd.Series(),\n",
    "                'pct_leq60': 0, 'pct_leq90': 0, 'shake_share': 0, 'shake_min_ppoz': None,\n",
    "                'savings_headline': {}, 'top3': pd.DataFrame(), 'verdict_label': 'No data available'\n",
    "            }\n",
    "        \n",
    "        # Overall best value (exclude Shake/Popcorn/Trim)\n",
    "        value_pool = best_per_slug[best_per_slug['report_category'] != 'Shake/Popcorn/Trim']\n",
    "        if value_pool.empty:\n",
    "            value_pool = best_per_slug.copy()\n",
    "        \n",
    "        best_row = value_pool.loc[value_pool['price_per_oz'].idxmin()]\n",
    "        \n",
    "        # Distribution stats\n",
    "        overall_median = float(best_per_slug['price_per_oz'].median())\n",
    "        overall_p25 = float(best_per_slug['price_per_oz'].quantile(0.25))\n",
    "        overall_p75 = float(best_per_slug['price_per_oz'].quantile(0.75))\n",
    "        \n",
    "        # Category stats\n",
    "        cat_stats = []\n",
    "        for cat in cat_order:\n",
    "            sub = best_per_slug[best_per_slug['report_category']==cat]\n",
    "            if not sub.empty:\n",
    "                cat_stats.append({\n",
    "                    'cat': cat,\n",
    "                    'n_products': int(sub['slug'].nunique()),\n",
    "                    'median': float(sub['price_per_oz'].median()),\n",
    "                    'min': float(sub['price_per_oz'].min())\n",
    "                })\n",
    "        \n",
    "        # Price bands\n",
    "        band_labels = [\"≤ $60\", \"$61–$90\", \"$91–$120\", \"$121–$200\", \">$200\"]\n",
    "        band_bins = [0, 60, 90, 120, 200, np.inf]\n",
    "        band_series = pd.cut(best_per_slug['price_per_oz'], bins=band_bins, labels=band_labels, right=True, include_lowest=True)\n",
    "        band_counts = band_series.value_counts().reindex(band_labels, fill_value=0)\n",
    "        band_shares = (band_counts / len(best_per_slug)).fillna(0)\n",
    "        \n",
    "        pct_leq60 = float((best_per_slug['price_per_oz'] <= 60).mean())\n",
    "        pct_leq90 = float((best_per_slug['price_per_oz'] <= 90).mean())\n",
    "        \n",
    "        # Shake analysis\n",
    "        shake_sub = best_per_slug[best_per_slug['report_category']=='Shake/Popcorn/Trim']\n",
    "        shake_share = float(len(shake_sub) / len(best_per_slug)) if len(best_per_slug) else 0.0\n",
    "        shake_min_ppoz = float(shake_sub['price_per_oz'].min()) if not shake_sub.empty else None\n",
    "        \n",
    "        # Savings headline\n",
    "        savings_headline = {}\n",
    "        if not savings_detail.empty:\n",
    "            top_sav = savings_detail.iloc[0]\n",
    "            savings_headline = {\n",
    "                'product': str(top_sav['name']),\n",
    "                'pct': float(top_sav['savings_pct']),\n",
    "                'small_label': str(top_sav['size_label_small']),\n",
    "                'small_ppoz': float(top_sav['price_per_oz_small']),\n",
    "                'large_label': str(top_sav['size_label_large']),\n",
    "                'large_ppoz': float(top_sav['price_per_oz_large']),\n",
    "            }\n",
    "        \n",
    "        # Top 3 products\n",
    "        top3 = (value_pool[['name','size_label','price','price_per_oz','report_category','Efficient Sizes']]\n",
    "                .sort_values('price_per_oz').head(3)\n",
    "                .rename(columns={'name':'Product','size_label':'Best Size','price':'Best Price'}))\n",
    "        \n",
    "        # Value verdict\n",
    "        if pct_leq60 >= 0.50: \n",
    "            verdict_label = \"Strong value (≥50% of products ≤ $60/oz, 28g norm)\"\n",
    "        elif pct_leq60 >= 0.25: \n",
    "            verdict_label = \"Mixed value (25–49% of products ≤ $60/oz, 28g norm)\"\n",
    "        else: \n",
    "            verdict_label = \"Premium-leaning (<25% of products ≤ $60/oz, 28g norm)\"\n",
    "        \n",
    "        return {\n",
    "            'best_ppoz': float(best_row['price_per_oz']),\n",
    "            'best_name': str(best_row['name']),\n",
    "            'best_size': str(best_row['size_label']),\n",
    "            'best_price': float(best_row['price']),\n",
    "            'overall_median': overall_median,\n",
    "            'overall_p25': overall_p25,\n",
    "            'overall_p75': overall_p75,\n",
    "            'cat_stats': cat_stats,\n",
    "            'band_counts': band_counts,\n",
    "            'band_shares': band_shares,\n",
    "            'pct_leq60': pct_leq60,\n",
    "            'pct_leq90': pct_leq90,\n",
    "            'shake_share': shake_share,\n",
    "            'shake_min_ppoz': shake_min_ppoz,\n",
    "            'savings_headline': savings_headline,\n",
    "            'top3': top3,\n",
    "            'verdict_label': verdict_label\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Executive metrics calculation error: {e}\")\n",
    "        return {\n",
    "            'best_ppoz': 0, 'best_name': 'Error', 'best_size': 'N/A', 'best_price': 0,\n",
    "            'overall_median': 0, 'overall_p25': 0, 'overall_p75': 0,\n",
    "            'cat_stats': [], 'band_counts': pd.Series(), 'band_shares': pd.Series(),\n",
    "            'pct_leq60': 0, 'pct_leq90': 0, 'shake_share': 0, 'shake_min_ppoz': None,\n",
    "            'savings_headline': {}, 'top3': pd.DataFrame(), 'verdict_label': 'Error calculating metrics'\n",
    "        }\n",
    "\n",
    "# Calculate executive metrics\n",
    "exec_metrics = calculate_executive_metrics(best_per_slug, savings_detail)\n",
    "\n",
    "# =========================\n",
    "# SECTION 4: ENHANCED VISUALIZATIONS\n",
    "# =========================\n",
    "\n",
    "def create_enhanced_visualizations(df, cat_order):\n",
    "    \"\"\"Create enhanced visualizations with better error handling.\"\"\"\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': 'white',\n",
    "        'axes.facecolor': '#FAFAFA',\n",
    "        'font.size': 11,\n",
    "        'font.family': 'sans-serif'\n",
    "    })\n",
    "    \n",
    "    def _encode_fig(fig, dpi=150):\n",
    "        try:\n",
    "            buf = io.BytesIO()\n",
    "            fig.savefig(buf, format='png', dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "            img = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "            plt.close(fig)\n",
    "            return img\n",
    "        except Exception as e:\n",
    "            print(f\"Figure encoding error: {e}\")\n",
    "            plt.close(fig)\n",
    "            return \"\"\n",
    "    \n",
    "    # Enhanced box plot\n",
    "    try:\n",
    "        fig1, ax1 = plt.subplots(figsize=(14, 6))\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'][:len(cat_order)]\n",
    "        \n",
    "        if not df.empty and len(cat_order) > 0:\n",
    "            sns.boxplot(\n",
    "                data=df, x=\"price_per_oz\", y=\"report_category\",\n",
    "                order=cat_order, palette=colors, ax=ax1,\n",
    "                fliersize=4, linewidth=1.5\n",
    "            )\n",
    "            \n",
    "            # Add median labels\n",
    "            for i, cat in enumerate(cat_order):\n",
    "                try:\n",
    "                    cat_data = df[df['report_category']==cat]['price_per_oz']\n",
    "                    if not cat_data.empty:\n",
    "                        median_val = cat_data.median()\n",
    "                        ax1.text(median_val, i, f'${median_val:.0f}', \n",
    "                                verticalalignment='center', fontweight='bold',\n",
    "                                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        ax1.set_title(\"Price Distribution by Product Category\", fontsize=16, fontweight='bold', pad=20)\n",
    "        ax1.set_xlabel(\"Price per Ounce ($, 28g normalized)\", fontsize=12, fontweight='medium')\n",
    "        ax1.set_ylabel(\"\")\n",
    "        ax1.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "        \n",
    "        img_box = _encode_fig(fig1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Box plot error: {e}\")\n",
    "        img_box = \"\"\n",
    "    \n",
    "    # Enhanced ECDF\n",
    "    try:\n",
    "        fig2, ax2 = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        if not df.empty and len(cat_order) > 0:\n",
    "            for i, cat in enumerate(cat_order):\n",
    "                try:\n",
    "                    cat_data = df[df['report_category']==cat]['price_per_oz']\n",
    "                    if not cat_data.empty:\n",
    "                        x_vals = np.sort(cat_data)\n",
    "                        y_vals = np.arange(1, len(x_vals) + 1) / len(x_vals)\n",
    "                        ax2.plot(x_vals, y_vals, label=cat, color=colors[i % len(colors)], \n",
    "                                linewidth=2.5, alpha=0.8)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        ax2.set_title(\"Cumulative Price Distribution Comparison\", fontsize=16, fontweight='bold', pad=20)\n",
    "        ax2.set_xlabel(\"Price per Ounce ($, 28g normalized)\", fontsize=12, fontweight='medium')\n",
    "        ax2.set_ylabel(\"Cumulative Percentage\", fontsize=12, fontweight='medium')\n",
    "        ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        ax2.grid(alpha=0.3, linestyle='--')\n",
    "        ax2.set_yticklabels([f'{int(y*100)}%' for y in ax2.get_yticks()])\n",
    "        \n",
    "        img_ecdf = _encode_fig(fig2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ECDF plot error: {e}\")\n",
    "        img_ecdf = \"\"\n",
    "    \n",
    "    return img_box, img_ecdf\n",
    "\n",
    "# Create visualizations\n",
    "img_box, img_ecdf = create_enhanced_visualizations(price_df_clean, cat_order)\n",
    "# FULL Price Bands (per product) generation for a collapsible section\n",
    "# Build bands_df from canonical products — EXCLUDE Shake/Popcorn/Trim\n",
    "base_for_bands = best_per_slug[best_per_slug['report_category'] != 'Shake/Popcorn/Trim'].copy()\n",
    "\n",
    "bands_df = (\n",
    "    base_for_bands[['name','report_category','size_label','price','price_per_oz']]\n",
    "    .rename(columns={\n",
    "        'name': 'Product',\n",
    "        'report_category': 'Category',\n",
    "        'size_label': 'Best Size',\n",
    "        'price': 'Best Price',\n",
    "        'price_per_oz': 'Best $/Oz (28g)'\n",
    "    })\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "bands_df['Price Band'] = pd.cut(\n",
    "    bands_df['Best $/Oz (28g)'],\n",
    "    bins=[0, 60, 90, 120, 200, float('inf')],\n",
    "    labels=[\"≤ $60\", \"$61–$90\", \"$91–$120\", \"$121–$200\", \">$200\"],\n",
    "    right=True, include_lowest=True\n",
    ")\n",
    "\n",
    "# Order by band then by price then by product\n",
    "bands_df['Price Band'] = pd.Categorical(\n",
    "    bands_df['Price Band'],\n",
    "    categories=[\"≤ $60\", \"$61–$90\", \"$91–$120\", \"$121–$200\", \">$200\"],\n",
    "    ordered=True\n",
    ")\n",
    "bands_df = bands_df.sort_values(['Price Band','Best $/Oz (28g)','Product']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Summary counts (string HTML chips already exist as bands_html in Exec Summary),\n",
    "# but we will build a collapsible panel with unlimited rows per band below.\n",
    "def _format_band_table_html(sub: pd.DataFrame) -> str:\n",
    "    return sub[['Product','Category','Best Size','Best Price','Best $/Oz (28g)']].to_html(\n",
    "        index=False,\n",
    "        classes=\"w-full text-left my-4 text-base\",\n",
    "        border=0,\n",
    "        formatters={\n",
    "            'Best Price': lambda x: f'${x:,.2f}',\n",
    "            'Best $/Oz (28g)': lambda x: f'${x:,.2f}',\n",
    "        },\n",
    "        escape=False\n",
    "    )\n",
    "\n",
    "full_bands_sections = []\n",
    "for label in [\"≤ $60\", \"$61–$90\", \"$91–$120\", \"$121–$200\", \">$200\"]:\n",
    "    sub = bands_df[bands_df['Price Band'].astype(str) == label]\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    full_bands_sections.append(\n",
    "        f\"\"\"\n",
    "        <div class=\"mt-4\">\n",
    "          <h4 class=\"text-lg font-semibold text-white\">{label}</h4>\n",
    "          <div class=\"overflow-x-auto\">{_format_band_table_html(sub)}</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "full_bands_html = (\n",
    "    f\"\"\"\n",
    "    <details class=\"group bg-gray-800 border border-gray-700 rounded-lg mt-4\">\n",
    "      <summary class=\"cursor-pointer select-none list-none px-4 py-3 flex items-center justify-between\">\n",
    "        <span class=\"text-white font-semibold\">Full Price Bands — per product (28g-normalized, unlimited)</span>\n",
    "        <span class=\"text-gray-400 text-sm group-open:hidden\">Click to expand</span>\n",
    "        <span class=\"text-gray-400 text-sm hidden group-open:inline\">Click to collapse</span>\n",
    "      </summary>\n",
    "      <div class=\"px-4 pb-4 pt-0\">\n",
    "        {''.join(full_bands_sections) if full_bands_sections else \"<p class='text-gray-400 mt-2'>No products available.</p>\"}\n",
    "      </div>\n",
    "    </details>\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# SECTION 5: HTML GENERATION\n",
    "# =========================\n",
    "\n",
    "def generate_enhanced_html(dispensary_data, exec_metrics, savings_detail, best_per_slug, \n",
    "                          price_df_clean, cat_order, img_box, img_ecdf, eff_map, sizes_badge_func):\n",
    "    \"\"\"Generate enhanced HTML with better error handling and performance.\"\"\"\n",
    "    \n",
    "    EMOJIS = {'Bulk Value':'🏆', 'Pre-Pack Specialty':'💎', 'Shake/Popcorn/Trim':'💸'}\n",
    "    \n",
    "    def safe_format_currency(value):\n",
    "        try:\n",
    "            return f\"${float(value):,.2f}\"\n",
    "        except Exception:\n",
    "            return \"$0.00\"\n",
    "    \n",
    "    def safe_format_percentage(value):\n",
    "        try:\n",
    "            return f\"{float(value):.0f}%\"\n",
    "        except Exception:\n",
    "            return \"0%\"\n",
    "    \n",
    "    def build_category_kpis():\n",
    "        kpi_html = \"\"\n",
    "        for c in exec_metrics['cat_stats']:\n",
    "            try:\n",
    "                kpi_html += f'''\n",
    "                <div class=\"bg-gradient-to-br from-gray-800 to-gray-700 border border-gray-600 rounded-xl p-4 transform hover:scale-105 transition-transform duration-200\">\n",
    "                    <div class=\"text-sm text-gray-400 font-medium\">{c[\"cat\"]}</div>\n",
    "                    <div class=\"mt-2 text-xl font-bold text-white\">${c[\"median\"]:.0f}/oz \n",
    "                        <span class=\"text-xs text-gray-400 font-normal\">(median, 28g)</span>\n",
    "                    </div>\n",
    "                    <div class=\"mt-1 text-xs text-gray-400\">min ${c[\"min\"]:.0f} • {c[\"n_products\"]} products</div>\n",
    "                </div>\n",
    "                '''\n",
    "            except Exception:\n",
    "                continue\n",
    "        return kpi_html\n",
    "    \n",
    "    def build_price_bands():\n",
    "        bands_html = \"\"\n",
    "        band_labels = [\"≤ $60\", \"$61–$90\", \"$91–$120\", \"$121–$200\", \">$200\"]\n",
    "        band_colors = ['bg-green-600', 'bg-blue-600', 'bg-yellow-600', 'bg-orange-600', 'bg-red-600']\n",
    "        \n",
    "        for i, label in enumerate(band_labels):\n",
    "            try:\n",
    "                color_class = band_colors[i] if i < len(band_colors) else 'bg-gray-600'\n",
    "                count = int(exec_metrics['band_counts'].get(label, 0))\n",
    "                share = exec_metrics['band_shares'].get(label, 0) * 100\n",
    "                \n",
    "                bands_html += f'''\n",
    "                <div class=\"bg-gradient-to-br from-gray-800 to-gray-700 border border-gray-600 rounded-xl p-4 transform hover:scale-105 transition-transform duration-200\">\n",
    "                    <div class=\"flex items-center gap-2\">\n",
    "                        <div class=\"{color_class} w-3 h-3 rounded-full\"></div>\n",
    "                        <div class=\"text-sm text-gray-400 font-medium\">{label} (28g)</div>\n",
    "                    </div>\n",
    "                    <div class=\"mt-2 text-xl font-bold text-white\">{count} \n",
    "                        <span class=\"text-xs text-gray-400 font-normal\">({share:.0f}%)</span>\n",
    "                    </div>\n",
    "                </div>\n",
    "                '''\n",
    "            except Exception:\n",
    "                continue\n",
    "        return bands_html\n",
    "    \n",
    "    def build_savings_or_shake_kpi():\n",
    "        if exec_metrics['savings_headline']:\n",
    "            try:\n",
    "                sh = exec_metrics['savings_headline']\n",
    "                return f'''\n",
    "                <div class=\"bg-gradient-to-br from-green-800 to-green-700 border border-green-600 rounded-xl p-4\">\n",
    "                    <div class=\"text-sm text-green-200 font-medium\">💰 Largest bulk savings</div>\n",
    "                    <div class=\"mt-2 text-xl font-bold text-white\">{sh[\"pct\"]:.0f}%</div>\n",
    "                    <div class=\"mt-1 text-sm text-green-100\">{sh[\"product\"][:30]}{'...' if len(sh[\"product\"]) > 30 else ''}</div>\n",
    "                    <div class=\"mt-1 text-xs text-green-200\">\n",
    "                        {sh[\"small_label\"]} @ ${sh[\"small_ppoz\"]:.0f}/oz → \n",
    "                        {sh[\"large_label\"]} @ ${sh[\"large_ppoz\"]:.0f}/oz\n",
    "                    </div>\n",
    "                </div>\n",
    "                '''\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            return f'''\n",
    "            <div class=\"bg-gradient-to-br from-gray-800 to-gray-700 border border-gray-600 rounded-xl p-4\">\n",
    "                <div class=\"text-sm text-gray-400 font-medium\">💸 Shake/Popcorn coverage</div>\n",
    "                <div class=\"mt-2 text-xl font-bold text-white\">{exec_metrics[\"shake_share\"]*100:.0f}% of products</div>\n",
    "                {f'<div class=\"mt-1 text-xs text-gray-400\">cheapest: ${exec_metrics[\"shake_min_ppoz\"]:.0f}/oz (28g)</div>' if exec_metrics[\"shake_min_ppoz\"] is not None else ''}\n",
    "            </div>\n",
    "            '''\n",
    "        except Exception:\n",
    "            return '<div class=\"bg-gray-800 p-4 rounded-xl\"><span class=\"text-gray-400\">Data unavailable</span></div>'\n",
    "    \n",
    "    def build_top3_products():\n",
    "        if exec_metrics['top3'].empty:\n",
    "            return '<p class=\"text-gray-400\">No products available</p>'\n",
    "        \n",
    "        items = []\n",
    "        medals = ['🥇', '🥈', '🥉']\n",
    "        \n",
    "        for i, (_, r) in enumerate(exec_metrics['top3'].iterrows()):\n",
    "            try:\n",
    "                medal = medals[i] if i < len(medals) else '🏅'\n",
    "                product_name = str(r[\"Product\"])[:40] + ('...' if len(str(r[\"Product\"])) > 40 else '')\n",
    "                \n",
    "                items.append(f'''\n",
    "                <div class=\"bg-gray-800 border border-gray-600 rounded-lg p-4 flex items-center justify-between hover:bg-gray-750 transition-colors duration-200\">\n",
    "                    <div class=\"flex items-center gap-3\">\n",
    "                        <span class=\"text-2xl\">{medal}</span>\n",
    "                        <div>\n",
    "                            <div class=\"font-semibold text-white\">{product_name}</div>\n",
    "                            <div class=\"text-sm text-gray-400\">{r[\"report_category\"]} • {r[\"Best Size\"]} • {safe_format_currency(r[\"Best Price\"])}</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                    <div class=\"text-right\">\n",
    "                        <div class=\"text-lg font-bold text-cyan-400\">{safe_format_currency(r[\"price_per_oz\"])}/oz</div>\n",
    "                        <div class=\"text-xs text-gray-400\">28g normalized</div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                ''')\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        return '<div class=\"space-y-3\">' + \"\".join(items) + '</div>'\n",
    "    \n",
    "    def build_category_leaderboards():\n",
    "        if price_df_clean.empty or not cat_order:\n",
    "            return '<p class=\"text-gray-400\">No category data available</p>'\n",
    "        \n",
    "        sections = []\n",
    "        for cat in cat_order:\n",
    "            try:\n",
    "                sub = price_df_clean[price_df_clean['report_category'] == cat]\n",
    "                if sub.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Build best per slug for this category\n",
    "                rows = []\n",
    "                for slug, g in sub.groupby('slug', sort=False):\n",
    "                    try:\n",
    "                        g2 = g.sort_values(['price_per_oz','weight_g'], ascending=[True, False])\n",
    "                        row = g2.iloc[0].copy()\n",
    "                        row['Efficient Sizes'] = sizes_badge_func(eff_map.get(slug, pd.DataFrame()))\n",
    "                        \n",
    "                        # Add savings info\n",
    "                        if not savings_detail.empty:\n",
    "                            spct = savings_detail.loc[savings_detail['slug']==slug, 'savings_pct']\n",
    "                            row['Max Savings vs Smallest'] = spct.iloc[0] if not spct.empty else np.nan\n",
    "                        else:\n",
    "                            row['Max Savings vs Smallest'] = np.nan\n",
    "                        \n",
    "                        rows.append(row)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                \n",
    "                if not rows:\n",
    "                    continue\n",
    "                \n",
    "                best_df = pd.DataFrame(rows)\n",
    "                best_df = best_df.sort_values(['price_per_oz','name'], ascending=[True, True]).head(20)  # Limit for performance\n",
    "                \n",
    "                table_html = best_df[['name','size_label','price','price_per_oz','Efficient Sizes','Max Savings vs Smallest']].to_html(\n",
    "                    index=False,\n",
    "                    classes=\"w-full text-left text-sm bg-gray-800 rounded-lg overflow-hidden\",\n",
    "                    formatters={\n",
    "                        'price': safe_format_currency,\n",
    "                        'price_per_oz': lambda x: f'<span class=\"font-semibold text-cyan-400\">{safe_format_currency(x)}</span>',\n",
    "                        'Max Savings vs Smallest': lambda x: (f'<span class=\"font-semibold text-green-400\">{x:.0f}%</span>'\n",
    "                                                            if pd.notna(x) else '<span class=\"text-gray-400\">—</span>')\n",
    "                    },\n",
    "                    escape=False,\n",
    "                    table_id=f\"table-{cat.lower().replace(' ', '-')}\"\n",
    "                )\n",
    "                \n",
    "                sections.append(f'''\n",
    "                <div class=\"mb-8\">\n",
    "                    <h2 class=\"text-2xl font-bold text-cyan-400 border-b-2 border-cyan-400 pb-2 mb-4\">\n",
    "                        {EMOJIS.get(cat,'📦')} {cat}\n",
    "                    </h2>\n",
    "                    {table_html}\n",
    "                </div>\n",
    "                ''')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error building leaderboard for {cat}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return \"\\n\".join(sections)\n",
    "    \n",
    "    def build_savings_table():\n",
    "        if savings_detail.empty:\n",
    "            return '<p class=\"text-gray-400 my-4\">No multi-size products with positive ounce-price savings found.</p>'\n",
    "        \n",
    "        try:\n",
    "            cols = [\n",
    "                'name', 'report_category', 'size_label_small', 'weight_g_small', 'price_small', 'price_per_oz_small',\n",
    "                'size_label_large', 'weight_g_large', 'price_large', 'price_per_oz_large', 'savings_pct', 'delta_per_oz'\n",
    "            ]\n",
    "            \n",
    "            display_df = savings_detail[cols].rename(columns={\n",
    "                'name':'Product', 'report_category':'Category', 'size_label_small':'Small Size',\n",
    "                'weight_g_small':'Small (g)', 'price_small':'Small Price', 'price_per_oz_small':'Small $/oz (28g)',\n",
    "                'size_label_large':'Large Size', 'weight_g_large':'Large (g)', 'price_large':'Large Price',\n",
    "                'price_per_oz_large':'Large $/oz (28g)', 'savings_pct':'Savings %', 'delta_per_oz':'Δ $/oz (28g)'\n",
    "            })\n",
    "            \n",
    "            return display_df.to_html(\n",
    "                index=False,\n",
    "                classes=\"w-full text-left text-sm overflow-x-auto\",\n",
    "                escape=False,\n",
    "                formatters={\n",
    "                    'Small Price': safe_format_currency,\n",
    "                    'Small $/oz (28g)': safe_format_currency,\n",
    "                    'Large Price': safe_format_currency,\n",
    "                    'Large $/oz (28g)': safe_format_currency,\n",
    "                    'Savings %': lambda x: f'<span class=\"font-semibold text-green-400\">{x:.0f}%</span>',\n",
    "                    'Δ $/oz (28g)': lambda x: f'<span class=\"font-semibold text-cyan-400\">{safe_format_currency(x)}</span>',\n",
    "                    'Small (g)': lambda x: f'{x:.0f}g' if abs(x - round(x)) < 1e-6 else f'{x:g}g',\n",
    "                    'Large (g)': lambda x: f'{x:.0f}g' if abs(x - round(x)) < 1e-6 else f'{x:g}g',\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Savings table error: {e}\")\n",
    "            return '<p class=\"text-red-400\">Error generating savings table</p>'\n",
    "    \n",
    "    # Build HTML components\n",
    "    cat_kpi_html = build_category_kpis()\n",
    "    bands_html = build_price_bands()\n",
    "    additional_kpi_html = build_savings_or_shake_kpi()\n",
    "    top3_html = build_top3_products()\n",
    "    category_leaderboards = build_category_leaderboards()\n",
    "    savings_table_html = build_savings_table()\n",
    "    \n",
    "    # Main HTML template\n",
    "    html_output = f'''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"utf-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
    "    <meta name=\"description\" content=\"Medical flower price analysis report for {dispensary_data['name']}\" />\n",
    "    <title>Medical Flower Price Report - {dispensary_data['name']}</title>\n",
    "    <script src=\"https://cdn.tailwindcss.com?plugins=typography\"></script>\n",
    "    <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\" />\n",
    "    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\n",
    "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap\" rel=\"stylesheet\" />\n",
    "    <style>\n",
    "        body {{ font-family: 'Inter', system-ui, sans-serif; }}\n",
    "        .hover\\\\:scale-105:hover {{ transform: scale(1.05); }}\n",
    "        .bg-gray-750 {{ background-color: #374151; }}\n",
    "        table {{ border-collapse: collapse; }}\n",
    "        th, td {{ padding: 12px 8px; border-bottom: 1px solid #374151; }}\n",
    "        th {{ background-color: #1F2937; font-weight: 600; }}\n",
    "        .transition-transform {{ transition: transform 0.2s ease-in-out; }}\n",
    "        @media (max-width: 768px) {{\n",
    "            .text-5xl {{ font-size: 2.5rem; }}\n",
    "            .grid-cols-4 {{ grid-template-columns: repeat(2, 1fr); }}\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body class=\"bg-gray-900 text-gray-200 min-h-screen\">\n",
    "    <main class=\"max-w-6xl mx-auto p-4 sm:p-6\">\n",
    "\n",
    "        <!-- Dispensary Header -->\n",
    "        <header class=\"text-center mb-8\">\n",
    "            <h1 class=\"text-4xl sm:text-5xl font-extrabold text-white mb-4\">Medical Flower Price Report</h1>\n",
    "            <p class=\"text-lg text-gray-400\">Value Analysis for {dispensary_data['name']}</p>\n",
    "        </header>\n",
    "\n",
    "        <section class=\"grid grid-cols-1 md:grid-cols-2 gap-6 bg-gray-800 p-6 rounded-lg border border-gray-700 mb-10\">\n",
    "            <div>\n",
    "                <h2 class=\"text-2xl font-semibold text-cyan-400\">{dispensary_data['name']}</h2>\n",
    "                <p class=\"mt-1 text-gray-300\">\n",
    "                    {dispensary_data['address']}<br />\n",
    "                    {dispensary_data['city']}, {dispensary_data['state']}\n",
    "                </p>\n",
    "            </div>\n",
    "            <div class=\"text-right space-y-1\">\n",
    "                <p class=\"text-gray-300\"><strong>Rating:</strong> <span class=\"text-cyan-400\">{dispensary_data['rating']:.1f}⭐ ({dispensary_data['reviews_count']} reviews)</span></p>\n",
    "                <p class=\"text-gray-300\"><strong>Phone:</strong> <a href=\"tel:{dispensary_data['phone_number']}\" class=\"text-cyan-400 hover:underline\">{dispensary_data['phone_number']}</a></p>\n",
    "                <p class=\"text-gray-300\"><strong>Menu:</strong> <a class=\"text-cyan-400 hover:underline\" href=\"{dispensary_data['web_url']}\" target=\"_blank\" rel=\"noopener\">View Menu</a></p>\n",
    "            </div>\n",
    "        </section>\n",
    "\n",
    "        <!-- Executive Summary -->\n",
    "        <section class=\"mb-10\">\n",
    "            <h2 class=\"text-3xl font-semibold text-cyan-400 border-b border-gray-700 pb-2\">Executive Summary</h2>\n",
    "            <div class=\"grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-4 gap-3 mt-4\">\n",
    "                <div class=\"bg-gray-800 border border-gray-700 rounded-lg p-4\">\n",
    "                    <div class=\"text-sm text-gray-400\">Cheapest ounce-equivalent (28g)</div>\n",
    "                    <div class=\"mt-1 text-2xl font-bold text-cyan-400\">{safe_format_currency(exec_metrics['best_ppoz'])}/oz</div>\n",
    "                    <div class=\"mt-1 text-xs text-gray-400\">{exec_metrics['best_name'][:40]}{'...' if len(exec_metrics['best_name']) > 40 else ''}</div>\n",
    "                    <div class=\"mt-1 text-xs text-gray-500\">{exec_metrics['best_size']} • {safe_format_currency(exec_metrics['best_price'])}</div>\n",
    "                </div>\n",
    "                <div class=\"bg-gray-800 border border-gray-700 rounded-lg p-4\">\n",
    "                    <div class=\"text-sm text-gray-400\">Typical price (per product, 28g norm)</div>\n",
    "                    <div class=\"mt-1 text-2xl font-bold text-white\">${exec_metrics['overall_median']:.0f}/oz</div>\n",
    "                    <div class=\"mt-1 text-xs text-gray-400\">IQR ${exec_metrics['overall_p25']:.0f}–${exec_metrics['overall_p75']:.0f}</div>\n",
    "                </div>\n",
    "                <div class=\"bg-gray-800 border border-gray-700 rounded-lg p-4\">\n",
    "                    <div class=\"text-sm text-gray-400\">Low-price coverage (28g)</div>\n",
    "                    <div class=\"mt-1 text-2xl font-bold text-white\">{exec_metrics['pct_leq60']*100:.0f}% ≤ $60/oz</div>\n",
    "                    <div class=\"mt-1 text-xs text-gray-400\">{exec_metrics['pct_leq90']*100:.0f}% ≤ $90/oz</div>\n",
    "                </div>\n",
    "                {additional_kpi_html}\n",
    "            </div>\n",
    "\n",
    "            <div class=\"mt-4\">\n",
    "                <div class=\"bg-emerald-900/30 border border-emerald-700 rounded-lg p-3 text-emerald-300 text-sm font-semibold\">\n",
    "                    Bottom line: {exec_metrics['verdict_label']}\n",
    "                </div>\n",
    "            </div>\n",
    "\n",
    "            <h3 class=\"text-xl font-semibold text-white mt-6\">Category medians & counts</h3>\n",
    "            <div class=\"grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-3 mt-2\">\n",
    "                {cat_kpi_html}\n",
    "            </div>\n",
    "\n",
    "            <h3 class=\"text-xl font-semibold text-white mt-6\">Price band coverage (per product)</h3>\n",
    "            <div class=\"grid grid-cols-1 sm:grid-cols-3 lg:grid-cols-5 gap-3 mt-2\">\n",
    "                {bands_html}\n",
    "            </div>\n",
    "            <!-- Collapsible FULL Price Bands (unlimited rows per band) -->\n",
    "            {full_bands_html}\n",
    "            <h3 class=\"text-xl font-semibold text-white mt-6\">Top 3 best-value products (by $/oz)</h3>\n",
    "            {top3_html}\n",
    "        </section>\n",
    "\n",
    "        <!-- Visuals -->\n",
    "        <section class=\"mb-6\">\n",
    "            <h2 class=\"text-3xl font-semibold text-cyan-400 border-b border-gray-700 pb-2\">Price Distribution Visuals</h2>\n",
    "            {f'<div class=\"mt-6 bg-gray-800 rounded-lg p-4 border border-gray-700\"><h3 class=\"text-xl font-semibold text-white mb-2\">Box Plot (quartiles + whiskers)</h3><img src=\"data:image/png;base64,{img_box}\" alt=\"Box plot\" class=\"mx-auto rounded bg-white p-2 shadow max-w-full h-auto\" /></div>' if img_box else '<div class=\"mt-6 bg-gray-800 rounded-lg p-4 border border-gray-700\"><p class=\"text-gray-400\">Box plot unavailable</p></div>'}\n",
    "            \n",
    "            {f'<div class=\"mt-6 bg-gray-800 rounded-lg p-4 border border-gray-700\"><h3 class=\"text-xl font-semibold text-white mb-2\">ECDF Overlay (cumulative comparison)</h3><img src=\"data:image/png;base64,{img_ecdf}\" alt=\"ECDF overlay\" class=\"mx-auto rounded bg-white p-2 shadow max-w-full h-auto\" /></div>' if img_ecdf else '<div class=\"mt-6 bg-gray-800 rounded-lg p-4 border border-gray-700\"><p class=\"text-gray-400\">ECDF plot unavailable</p></div>'}\n",
    "        </section>\n",
    "\n",
    "        <!-- Dynamic category leaderboards -->\n",
    "        {category_leaderboards}\n",
    "\n",
    "        <!-- FULL Bulk Savings Spotlight -->\n",
    "        <section class=\"mb-12\">\n",
    "            <h2 class=\"text-3xl font-semibold text-cyan-400 border-b border-gray-700 pb-2 mt-10\">Bulk Savings Spotlight — Full Detail</h2>\n",
    "            <div class=\"overflow-x-auto\">\n",
    "                {savings_table_html}\n",
    "            </div>\n",
    "        </section>\n",
    "\n",
    "        <footer class=\"text-center text-sm text-gray-500 mt-10 border-t border-gray-700 pt-4\">\n",
    "            Report generated on {datetime.now().strftime('%B %d, %Y at %I:%M %p')}.\n",
    "        </footer>\n",
    "    </main>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "    \n",
    "    return html_output\n",
    "\n",
    "# Generate final HTML\n",
    "try:\n",
    "    html_output = generate_enhanced_html(\n",
    "        dispensary_data, exec_metrics, savings_detail, best_per_slug, \n",
    "        price_df_clean, cat_order, img_box, img_ecdf, eff_map, sizes_badge_func\n",
    "    )\n",
    "    \n",
    "    # Save to file with date (dispensaries rarely update menus more than once a day) timestamp and dispensary name\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "    dispensary_name = dispensary_data['name'].replace(' ', '_').replace('-', '_').replace('/', '-')\n",
    "    # Write to file\n",
    "    output_filename = f\"{dispensary_name}_{timestamp}_report.html\"\n",
    "    # Check if output directory exists, if not create it\n",
    "    import os\n",
    "    output_parent_dir = 'flower_reports_showcase' # main parent directory\n",
    "    output_report_dir = 'reports' # subdirectory for reports\n",
    "    output_path = os.path.join(output_parent_dir, output_report_dir)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    output_path = os.path.join(output_path, output_filename)\n",
    "    \n",
    "    # Write the HTML to file    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_output)\n",
    "        \n",
    "\n",
    "    print(\"✅ Enhanced HTML report generated successfully!\")\n",
    "    display(HTML(html_output))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ HTML generation error: {e}\")\n",
    "    # Fallback minimal HTML\n",
    "    fallback_html = f'''\n",
    "    <!DOCTYPE html>\n",
    "    <html><head><title>Error</title></head>\n",
    "    <body style=\"font-family: Arial, sans-serif; padding: 20px; background: #1a1a1a; color: white;\">\n",
    "        <h1>Report Generation Error</h1>\n",
    "        <p>An error occurred while generating the full report: {e}</p>\n",
    "        <p>Please check your data and try again.</p>\n",
    "    </body></html>\n",
    "    '''\n",
    "    display(HTML(fallback_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# --- Seed & Populate: Distance-Adjusted Value Leaderboard (FULL; uses flower_reports_showcase) ---\n",
    "# This cell:\n",
    "#   • Normalizes LATLNG -> tuple and preserves original string\n",
    "#   • Builds listings_df from your existing v2 discovery results (dispensary_list_df)\n",
    "#   • Selects K nearest dispensaries (by great-circle miles)\n",
    "#   • Fetches full flower menus via v1 for those slugs (polite pagination)\n",
    "#   • Normalizes per-item data with 28g normalization and persists caches via ATOMIC WRITES:\n",
    "#       flower_reports_showcase/normalized/listings.parquet\n",
    "#       flower_reports_showcase/normalized/menus/{slug}.parquet\n",
    "#     (with CSV fallbacks; mirrored to ./data/normalized/* for your existing loader)\n",
    "#   • Emits an aesthetic HTML status panel (with audit columns) and saves it atomically to flower_reports_showcase/reports/\n",
    "#   • Hides rows with Valid == 0 (no qualifying MED flower) in the status table\n",
    "#\n",
    "# Inputs expected from earlier cells (you already have them):\n",
    "#   LATLNG (str \"lat,lon\" or tuple), BASE_V1, HEADERS, optional HEADERSV1, dispensary_list_df (from v2 /listings)\n",
    "#\n",
    "# No external deps; safe to re-run. Gentle rate limiting + small header variance.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "import os, re, time, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import HTML, display\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------------- simple anti-bot / rate controls ----------------\n",
    "BASE_SLEEP    = float(os.environ.get(\"WM_BASE_SLEEP\", \"0.4\"))   # base delay between requests\n",
    "JITTER        = float(os.environ.get(\"WM_JITTER\", \"0.3\"))       # random extra seconds (0..JITTER)\n",
    "MAX_TRIES     = int(os.environ.get(\"WM_MAX_TRIES\", \"4\"))        # per-request attempts on 429/5xx\n",
    "TTL_HOURS     = float(os.environ.get(\"WM_TTL_HOURS\", \"6\"))      # skip refetch if cache newer than this\n",
    "K_NEAREST     = int(os.environ.get(\"WM_K_NEAREST\", \"50\"))       # number of nearest listings to consider\n",
    "FORCE_REFRESH = os.environ.get(\"WM_FORCE_REFRESH\", \"1\").strip().lower() in (\"1\",\"true\",\"yes\",\"y\")\n",
    "\n",
    "SESSION = requests.Session()\n",
    "if 'HEADERS' in globals() and isinstance(HEADERS, dict):\n",
    "    SESSION.headers.update({k: str(v) for k, v in HEADERS.items()})\n",
    "\n",
    "_ACCEPT_LANG = [\"en-US,en;q=0.9\",\"en-US,en;q=0.8\",\"en-US,en;q=0.7\"]\n",
    "\n",
    "def _sleep():  # small helper for jittered waits\n",
    "    time.sleep(BASE_SLEEP + random.random() * JITTER)\n",
    "\n",
    "def _respect_retry_after(resp, attempt_i: int):\n",
    "    ra = resp.headers.get(\"Retry-After\")\n",
    "    if ra:\n",
    "        try:\n",
    "            wait = max(float(ra), 1.0)\n",
    "            time.sleep(wait + random.random() * 0.7)\n",
    "            return\n",
    "        except Exception:\n",
    "            pass\n",
    "    time.sleep(min(2 ** attempt_i, 16) + random.random() * 0.8)  # fallback exponential-ish backoff\n",
    "\n",
    "def _fresh_enough(path: Path) -> bool:\n",
    "    try:\n",
    "        age = time.time() - path.stat().st_mtime\n",
    "        return age < (TTL_HOURS * 3600)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# ---------------- atomic write helpers ----------------\n",
    "def _atomic_write_bytes(path: Path, data: bytes):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        f.write(data)\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "    tmp.replace(path)  # atomic move on same filesystem\n",
    "\n",
    "def _atomic_write_text(path: Path, text: str, encoding=\"utf-8\"):\n",
    "    _atomic_write_bytes(path, text.encode(encoding))\n",
    "\n",
    "def _atomic_write_table_parquet(df: pd.DataFrame, path: Path):\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        df.to_parquet(tmp, index=False)\n",
    "        with open(tmp, \"rb+\") as f:\n",
    "            os.fsync(f.fileno())\n",
    "        tmp.replace(path)\n",
    "        return path\n",
    "    finally:\n",
    "        if tmp.exists():\n",
    "            try: tmp.unlink()\n",
    "            except: pass\n",
    "\n",
    "def _atomic_write_table_csv(df: pd.DataFrame, path: Path):\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        df.to_csv(tmp, index=False)\n",
    "        with open(tmp, \"rb+\") as f:\n",
    "            os.fsync(f.fileno())\n",
    "        tmp.replace(path)\n",
    "        return path\n",
    "    finally:\n",
    "        if tmp.exists():\n",
    "            try: tmp.unlink()\n",
    "            except: pass\n",
    "\n",
    "def _atomic_save_table(df: pd.DataFrame, target_parquet: Path):\n",
    "    \"\"\"Try parquet atomically, fallback to CSV atomically. Return final Path.\"\"\"\n",
    "    try:\n",
    "        return _atomic_write_table_parquet(df, target_parquet)\n",
    "    except Exception:\n",
    "        csv_path = target_parquet.with_suffix(\".csv\")\n",
    "        return _atomic_write_table_csv(df, csv_path)\n",
    "\n",
    "def _atomic_save_dual(df: pd.DataFrame, main_path: Path, mirror_path: Path) -> Tuple[Path, Path]:\n",
    "    main_final = _atomic_save_table(df, main_path)\n",
    "    mirror_final = _atomic_save_table(df, mirror_path)\n",
    "    return main_final.resolve(), mirror_final.resolve()\n",
    "\n",
    "# ---------------- paths ----------------\n",
    "FRS_ROOT     = Path(\"flower_reports_showcase\")\n",
    "FRS_NORM     = FRS_ROOT / \"normalized\"\n",
    "FRS_REPORTS  = FRS_ROOT / \"reports\"\n",
    "FRS_MENUS    = FRS_NORM / \"menus\"\n",
    "FRS_AUDITS   = FRS_REPORTS / \"audits\"\n",
    "FRS_NORM.mkdir(parents=True, exist_ok=True)\n",
    "FRS_MENUS.mkdir(parents=True, exist_ok=True)\n",
    "FRS_REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "FRS_AUDITS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mirror for your existing leaderboard loader (keeps ./data/normalized/* working)\n",
    "LEGACY_NORM  = Path(\"./data/normalized\")\n",
    "LEGACY_MENUS = LEGACY_NORM / \"menus\"\n",
    "LEGACY_NORM.mkdir(parents=True, exist_ok=True)\n",
    "LEGACY_MENUS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- LATLNG normalize ----------------\n",
    "def _latlng_tuple(val) -> Tuple[float, float]:\n",
    "    if isinstance(val, str):\n",
    "        a, b = val.split(\",\", 1)\n",
    "        return (float(a.strip()), float(b.strip()))\n",
    "    if isinstance(val, (tuple, list)) and len(val) == 2:\n",
    "        return (float(val[0]), float(val[1]))\n",
    "    raise ValueError(\"LATLNG must be 'lat,lon' string or (lat, lon) tuple\")\n",
    "\n",
    "if 'LATLNG' not in globals():\n",
    "    raise RuntimeError(\"LATLNG is not defined by prior cells.\")\n",
    "LATLNG = _latlng_tuple(LATLNG)\n",
    "LATLNG_STRING = f\"{LATLNG[0]},{LATLNG[1]}\"\n",
    "SESSION.headers.update({\"wm-user-latlng\": LATLNG_STRING})  # subtle anti-bot consistency\n",
    "\n",
    "# ---------------- listings_df from v2 discovery ----------------\n",
    "if 'dispensary_list_df' not in globals() or not isinstance(dispensary_list_df, pd.DataFrame) or dispensary_list_df.empty:\n",
    "    raise RuntimeError(\"dispensary_list_df missing/empty — run your v2 /listings discovery cell first.\")\n",
    "\n",
    "def _coerce_listings_schema(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    lat_candidates = [\"position.lat\",\"position.latitude\",\"geo.lat\",\"coordinates.lat\",\"location.lat\",\"lat\",\"latitude\"]\n",
    "    lon_candidates = [\"position.lng\",\"position.longitude\",\"geo.lng\",\"coordinates.lng\",\"location.lng\",\"lon\",\"lng\",\"longitude\"]\n",
    "    name_candidates = [\"name\",\"retailer.name\",\"listing_name\",\"business_name\",\"name.display\"]\n",
    "    slug_col = \"slug\" if \"slug\" in df.columns else None\n",
    "    lat_col  = next((c for c in lat_candidates if c in df.columns), None)\n",
    "    lon_col  = next((c for c in lon_candidates if c in df.columns), None)\n",
    "    name_col = next((c for c in name_candidates if c in df.columns), None)\n",
    "    if slug_col is None or lat_col is None or lon_col is None:\n",
    "        missing = []\n",
    "        if slug_col is None: missing.append(\"slug\")\n",
    "        if lat_col  is None: missing.append(\"lat\")\n",
    "        if lon_col  is None: missing.append(\"lon\")\n",
    "        raise KeyError(f\"dispensary_list_df is missing required columns: {', '.join(missing)}\")\n",
    "\n",
    "    out = df[[slug_col, lat_col, lon_col] + ([name_col] if name_col else [])].copy()\n",
    "    out.columns = [\"slug\",\"lat\",\"lon\"] + ([\"name\"] if name_col else [])\n",
    "    if \"name\" not in out.columns:\n",
    "        out[\"name\"] = out[\"slug\"]\n",
    "    out[\"lat\"] = pd.to_numeric(out[\"lat\"], errors=\"coerce\")\n",
    "    out[\"lon\"] = pd.to_numeric(out[\"lon\"], errors=\"coerce\")\n",
    "    out = out.dropna(subset=[\"slug\",\"lat\",\"lon\"]).drop_duplicates(subset=[\"slug\"])\n",
    "    return out[[\"slug\",\"lat\",\"lon\",\"name\"]].reset_index(drop=True)\n",
    "\n",
    "listings_df = _coerce_listings_schema(dispensary_list_df)\n",
    "\n",
    "# Persist listings_df (primary + mirror) — atomic\n",
    "listings_main, listings_mirror = _atomic_save_dual(\n",
    "    listings_df,\n",
    "    FRS_NORM / \"listings.parquet\",\n",
    "    LEGACY_NORM / \"listings.parquet\"\n",
    ")\n",
    "\n",
    "# ---------------- nearest selection ----------------\n",
    "def _haversine_mi(lat1, lon1, lat2, lon2) -> float:\n",
    "    R = 3958.7613\n",
    "    p1, p2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dl = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(p1)*math.cos(p2)*math.sin(dl/2)**2\n",
    "    return R * (2*math.atan2(math.sqrt(a), math.sqrt(1-a)))\n",
    "\n",
    "sel_df = listings_df.copy()\n",
    "sel_df[\"miles\"] = [\n",
    "    _haversine_mi(LATLNG[0], LATLNG[1], float(a), float(b))\n",
    "    for a,b in zip(sel_df[\"lat\"], sel_df[\"lon\"])\n",
    "]\n",
    "sel_df = sel_df.sort_values(\"miles\").head(K_NEAREST).reset_index(drop=True)\n",
    "\n",
    "# ---------------- v1 menu fetch + normalize (with polite pacing) ----------------\n",
    "OZ_TO_G = 28.0\n",
    "SIZE_ALIAS = {\n",
    "    \"1g\":1.0, \"2g\":2.0, \"3.5g\":3.5, \"eighth\":3.5, \"1/8\":3.5,\n",
    "    \"7g\":7.0, \"quarter\":7.0, \"1/4\":7.0, \"14g\":14.0, \"half\":14.0, \"1/2\":14.0,\n",
    "    \"28g\":28.0, \"1oz\":28.0, \"oz\":28.0, \"ounce\":28.0\n",
    "}\n",
    "\n",
    "def _guess_weight_g(label: str) -> Optional[float]:\n",
    "    if not isinstance(label, str):\n",
    "        return None\n",
    "    s = label.strip().lower()\n",
    "\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(g|gram|grams)', s)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "\n",
    "    m = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(oz|ounce|ounces)', s)\n",
    "    if m:\n",
    "        return float(m.group(1)) * OZ_TO_G\n",
    "\n",
    "    for k, g in SIZE_ALIAS.items():\n",
    "        if k in s:\n",
    "            return g\n",
    "\n",
    "    return None\n",
    "\n",
    "BAD_OUNCE_PAT = re.compile(\n",
    "    r'\\b(shake|trim|popcorn|littles?|smalls?|small\\s*buds?|red\\s*[-\\s]*tier|moon\\s*rocks?|moonrock|infused|pre[-\\s]?rolls?|prerolls?)\\b',\n",
    "    re.I\n",
    ")\n",
    "BUNDLE_PAT = re.compile(\n",
    "    r'\\b(mix[-\\s]*and[-\\s]*match|bundle|bogo|two[-\\s]?for|\\d+\\s*x|pack|multi[-\\s]*pack)\\b', re.I\n",
    ")\n",
    "\n",
    "# ---- safe Series access helpers (prevent scalar defaults) ----\n",
    "def _col_str(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return df[col].astype(str) if col in df.columns else pd.Series(\"\", index=df.index, dtype=str)\n",
    "\n",
    "def _col_bool(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return df[col].fillna(False).astype(bool) if col in df.columns else pd.Series(False, index=df.index, dtype=bool)\n",
    "\n",
    "def _col_num(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return pd.to_numeric(df[col], errors=\"coerce\") if col in df.columns else pd.Series(np.nan, index=df.index, dtype=float)\n",
    "\n",
    "def _normalize_menu_items(items: List[Dict[str,Any]]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for it in (items or []):\n",
    "        name  = (it.get(\"name\") or \"\").strip()\n",
    "        brand = (it.get(\"brand\") or {}).get(\"name\") or it.get(\"brand\") or \"\"\n",
    "        prices = it.get(\"prices\") or {}\n",
    "        deals = []\n",
    "        if isinstance(prices.get(\"gram\"), list):   deals += prices[\"gram\"]\n",
    "        if isinstance(prices.get(\"ounce\"), list):  deals += prices[\"ounce\"]\n",
    "        for p in deals:\n",
    "            try:\n",
    "                price = float(p.get(\"price\"))\n",
    "                w = p.get(\"weight\") or {}\n",
    "                w_val = w.get(\"value\"); w_unit = (w.get(\"unit\") or \"\").lower()\n",
    "                label = (p.get(\"label\") or \"\").strip()\n",
    "                if w_val is not None:\n",
    "                    weight_g = float(w_val) * 28.0 if w_unit.startswith(\"oz\") else float(w_val)\n",
    "                else:\n",
    "                    weight_g = _guess_weight_g(label)\n",
    "                if not (price and weight_g and weight_g > 0): \n",
    "                    continue\n",
    "                ppoz = (price / weight_g) * 28.0\n",
    "                is_bad_kind = bool(BAD_OUNCE_PAT.search(name) or BAD_OUNCE_PAT.search(label))\n",
    "                is_bundle   = bool(BUNDLE_PAT.search(name) or BUNDLE_PAT.search(label))\n",
    "                rows.append({\n",
    "                    \"name\": name,\n",
    "                    \"brand\": brand,\n",
    "                    \"size_label\": label if label else f\"{weight_g:g}g\",\n",
    "                    \"weight_g\": float(weight_g),\n",
    "                    \"price\": float(price),\n",
    "                    \"price_per_oz\": float(ppoz),\n",
    "                    \"report_category\": \"Shake/Popcorn/Trim\" if is_bad_kind else \"Flower\",\n",
    "                    \"is_bundle\": is_bundle\n",
    "                })\n",
    "            except Exception:\n",
    "                continue\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df = df[(pd.to_numeric(df[\"price\"], errors=\"coerce\") > 0) &\n",
    "                (pd.to_numeric(df[\"weight_g\"], errors=\"coerce\") > 0)]\n",
    "    return df\n",
    "\n",
    "def _headers_for_request():\n",
    "    h = dict(SESSION.headers)\n",
    "    h[\"Accept-Language\"] = random.choice(_ACCEPT_LANG)\n",
    "    h[\"Cache-Control\"] = \"no-cache\"\n",
    "    h[\"Pragma\"] = \"no-cache\"\n",
    "    return h\n",
    "\n",
    "def _fetch_menu_v1(slug: str,\n",
    "                   license_type=\"medical\",\n",
    "                   client_category=\"flower-category-pages\") -> pd.DataFrame:\n",
    "    \"\"\"Paginate discovery v1 menu_items with jitter + backoff + TTL caching (ATOMIC writes).\"\"\"\n",
    "    if 'BASE_V1' not in globals():\n",
    "        raise RuntimeError(\"BASE_V1 not defined in Setup cell.\")\n",
    "\n",
    "    # TTL: skip network if menu is fresh and not forcing refresh\n",
    "    cache_path = FRS_MENUS / f\"{slug}.parquet\"\n",
    "    if cache_path.exists() and _fresh_enough(cache_path) and not FORCE_REFRESH:\n",
    "        try:\n",
    "            return pd.read_parquet(cache_path)\n",
    "        except Exception:\n",
    "            pass  # fall through to network\n",
    "\n",
    "    headers_main = _headers_for_request()\n",
    "    headers_alt  = _headers_for_request()\n",
    "    if 'HEADERSV1' in globals():   headers_main.update(HEADERSV1)\n",
    "    if 'HEADERSV1' in globals(): headers_alt.update(HEADERSV1)\n",
    "\n",
    "    page, page_size = 1, 50\n",
    "    acc: List[Dict[str,Any]] = []\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"filter[license_type]\": license_type,\n",
    "            \"filter[any_client_categories][]\": client_category,\n",
    "            \"sort_by\": \"min_price\",\n",
    "            \"sort_order\": \"asc\",\n",
    "            \"page\": page,\n",
    "            \"page_size\": page_size,\n",
    "            \"include[]\": \"facets.categories\",\n",
    "        }\n",
    "        url = f\"{BASE_V1}/listings/dispensaries/{slug}/menu_items\"\n",
    "\n",
    "        # polite retry loop\n",
    "        resp = None\n",
    "        for attempt in range(1, MAX_TRIES + 1):\n",
    "            try:\n",
    "                resp = SESSION.get(url, headers=headers_main, params=params, timeout=30)\n",
    "                if resp.status_code == 401 and 'HEADERSV1' in globals():\n",
    "                    resp = SESSION.get(url, headers=headers_alt, params=params, timeout=30)\n",
    "\n",
    "                if resp.status_code in (429, 503, 504):\n",
    "                    _respect_retry_after(resp, attempt)\n",
    "                    continue  # try again\n",
    "\n",
    "                resp.raise_for_status()\n",
    "                break\n",
    "            except requests.RequestException:\n",
    "                if resp is not None and resp.status_code in (429, 503, 504):\n",
    "                    _respect_retry_after(resp, attempt)\n",
    "                else:\n",
    "                    time.sleep(0.6 + random.random() * 0.6)\n",
    "                if attempt == MAX_TRIES:\n",
    "                    raise\n",
    "\n",
    "        data = resp.json()\n",
    "        items = (data.get(\"data\") or {}).get(\"menu_items\") if isinstance(data.get(\"data\"), dict) else data.get(\"data\")\n",
    "        if not items:\n",
    "            break\n",
    "        acc.extend(items)\n",
    "        if len(items) < page_size:  # last page\n",
    "            break\n",
    "        page += 1\n",
    "        _sleep()  # gentle page pacing\n",
    "\n",
    "    df = _normalize_menu_items(acc)\n",
    "\n",
    "    # write cache (primary + mirror) — ATOMIC\n",
    "    _atomic_save_dual(df, FRS_MENUS / f\"{slug}.parquet\", LEGACY_MENUS / f\"{slug}.parquet\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ---------------- harvest menus for top-K nearest (with audit stats) ----------------\n",
    "def _age_str(p: Path) -> str:\n",
    "    try:\n",
    "        sec = max(0, time.time() - p.stat().st_mtime)\n",
    "        if sec < 90: return f\"{int(sec)}s\"\n",
    "        mins = sec / 60\n",
    "        if mins < 90: return f\"{mins:.0f}m\"\n",
    "        hrs = mins / 60\n",
    "        if hrs < 48: return f\"{hrs:.1f}h\"\n",
    "        days = hrs / 24\n",
    "        return f\"{days:.1f}d\"\n",
    "    except Exception:\n",
    "        return \"—\"\n",
    "\n",
    "coverage = []\n",
    "for i, row in sel_df.iterrows():\n",
    "    slug  = str(row[\"slug\"])\n",
    "    name  = str(row[\"name\"])\n",
    "    miles = float(row[\"miles\"])\n",
    "\n",
    "    source = \"fetched\"\n",
    "    cache_file = FRS_MENUS / f\"{slug}.parquet\"\n",
    "\n",
    "    # If cache exists & fresh and not forcing refresh, avoid network entirely\n",
    "    if cache_file.exists() and _fresh_enough(cache_file) and not FORCE_REFRESH:\n",
    "        try:\n",
    "            dfm = pd.read_parquet(cache_file)\n",
    "            source = \"cached\"\n",
    "        except Exception:\n",
    "            dfm = pd.DataFrame()\n",
    "    else:\n",
    "        try:\n",
    "            time.sleep(0.4 + random.random() * 0.5)  # pre-request think time\n",
    "            dfm = _fetch_menu_v1(slug)\n",
    "        except Exception as e:\n",
    "            coverage.append({\n",
    "                \"rank\": i+1, \"slug\": slug, \"name\": name, \"miles\": miles,\n",
    "                \"items_total\": 0, \"items_valid\": 0,\n",
    "                \"best_ppoz_flower\": np.nan, \"median_ppoz_flower\": np.nan,\n",
    "                \"best_size\": \"\", \"best_item\": \"\", \"best_price\": np.nan,\n",
    "                \"min_ppoz_any\": np.nan, \"shake_pct\": np.nan, \"bundle_pct\": np.nan,\n",
    "                \"source\": \"error\", \"age\": \"—\", \"audit\": \"\", \"error\": str(e)\n",
    "            })\n",
    "            print(f\"× {slug}  error: {e}\")\n",
    "            _sleep()\n",
    "            continue\n",
    "\n",
    "    total_rows = int(len(dfm))\n",
    "\n",
    "    # shake / bundle counts (robust to missing cols)\n",
    "    if total_rows > 0 and \"report_category\" in dfm.columns:\n",
    "        shake_rows = int((dfm[\"report_category\"].astype(str).str.lower() == \"shake/popcorn/trim\").sum())\n",
    "    else:\n",
    "        # fallback: regex inspect if needed\n",
    "        nm_f = _col_str(dfm, \"name\")\n",
    "        sl_f = _col_str(dfm, \"size_label\")\n",
    "        shake_rows = int((nm_f.str.contains(BAD_OUNCE_PAT, regex=True, na=False) |\n",
    "                          sl_f.str.contains(BAD_OUNCE_PAT, regex=True, na=False)).sum())\n",
    "\n",
    "    if \"is_bundle\" in dfm.columns:\n",
    "        bundle_rows = int(_col_bool(dfm, \"is_bundle\").sum())\n",
    "    else:\n",
    "        nm_b = _col_str(dfm, \"name\")\n",
    "        sl_b = _col_str(dfm, \"size_label\")\n",
    "        bundle_rows = int((nm_b.str.contains(BUNDLE_PAT, regex=True, na=False) |\n",
    "                           sl_b.str.contains(BUNDLE_PAT, regex=True, na=False)).sum())\n",
    "\n",
    "    min_ppoz_any = float(pd.to_numeric(dfm.get(\"price_per_oz\", pd.Series(np.nan, index=dfm.index)), errors=\"coerce\").min()) if total_rows else np.nan\n",
    "\n",
    "    # Valid flower set = what the leaderboard will actually use (non-shake, non-bundle)\n",
    "    dfv = dfm.copy()\n",
    "\n",
    "    # 1) remove shake/trim/popcorn\n",
    "    if \"report_category\" in dfv.columns:\n",
    "        dfv = dfv[dfv[\"report_category\"].astype(str).str.lower() != \"shake/popcorn/trim\"]\n",
    "    else:\n",
    "        nm = _col_str(dfv, \"name\"); sl = _col_str(dfv, \"size_label\")\n",
    "        mask_bad = nm.str.contains(BAD_OUNCE_PAT, regex=True, na=False) | sl.str.contains(BAD_OUNCE_PAT, regex=True, na=False)\n",
    "        dfv = dfv[~mask_bad]\n",
    "\n",
    "    # 2) remove bundles/mix-and-match\n",
    "    if \"is_bundle\" in dfv.columns:\n",
    "        dfv = dfv[~_col_bool(dfv, \"is_bundle\")]\n",
    "    else:\n",
    "        nm = _col_str(dfv, \"name\"); sl = _col_str(dfv, \"size_label\")\n",
    "        mask_bundle = nm.str.contains(BUNDLE_PAT, regex=True, na=False) | sl.str.contains(BUNDLE_PAT, regex=True, na=False)\n",
    "        dfv = dfv[~mask_bundle]\n",
    "\n",
    "    # ---- 3) SUSPECT-LOW GUARDRAILS (robust, auditable) ----\n",
    "    SUSPECT_PPOZ_FLOOR = float(os.environ.get(\"WM_SUSPECT_PPOZ_FLOOR\", \"54\"))   # hard $/oz floor\n",
    "    SUSPECT_PG_FLOOR   = float(os.environ.get(\"WM_SUSPECT_PG_FLOOR\",   \"1.00\")) # hard $/g floor\n",
    "    OZ_TOL             = float(os.environ.get(\"WM_OZ_TOL\",             \"3.0\"))  # ± grams for 1 oz\n",
    "    VERY_LOW_FLOOR     = float(os.environ.get(\"WM_VERY_LOW_FLOOR\",     \"20\"))   # allow unusual but not absurd\n",
    "    STEM_OUTLIER_RATIO = float(os.environ.get(\"WM_STEM_OUTLIER_RATIO\", \"0.70\")) # ounce must be ≥ 70% of its stem median\n",
    "\n",
    "    # IMPORTANT: do NOT reset dfv here (we already removed shake/bundle above)\n",
    "    # dfv = dfm.copy()   <-- remove this line if present\n",
    "\n",
    "    # ensure numerics\n",
    "    dfv[\"price\"]        = pd.to_numeric(dfv.get(\"price\"), errors=\"coerce\")\n",
    "    dfv[\"weight_g\"]     = pd.to_numeric(dfv.get(\"weight_g\"), errors=\"coerce\")\n",
    "    dfv[\"price_per_oz\"] = pd.to_numeric(dfv.get(\"price_per_oz\"), errors=\"coerce\")\n",
    "\n",
    "    name_s  = _col_str(dfv, \"name\")\n",
    "    brand_s = _col_str(dfv, \"brand\")\n",
    "    size_s  = _col_str(dfv, \"size_label\")\n",
    "\n",
    "    # “budsish” signal for house-tier lines\n",
    "    budsish = name_s.str.contains(r'^\\s*(med\\s*)?buds\\b', flags=re.I, regex=True) | \\\n",
    "            brand_s.str.contains(r'\\bbuds\\b', flags=re.I, regex=True)\n",
    "\n",
    "    # Normalize a \"stem\" (product family) to compare 1 oz vs its own 1/8, etc.\n",
    "    def _stemify(s: str) -> str:\n",
    "        s = re.sub(r'(?i)\\b(med(ical)?\\s*)?buds\\b[\\/\\-\\s]*', '', s or '')\n",
    "        s = re.sub(r'[^a-z0-9]+', ' ', s.lower()).strip()\n",
    "        return s[:80]\n",
    "\n",
    "    dfv[\"stem\"] = name_s.apply(_stemify)\n",
    "\n",
    "    # Store-level floor from current (already non-shake/non-bundle) dfv\n",
    "    flower_ppoz   = dfv[\"price_per_oz\"]\n",
    "    store_median  = float(np.nanmedian(flower_ppoz)) if flower_ppoz.notna().any() else np.nan\n",
    "    if flower_ppoz.notna().sum() >= 4:\n",
    "        q1, q3 = np.nanpercentile(flower_ppoz.dropna(), [25, 75])\n",
    "        iqr = q3 - q1\n",
    "        iqr_floor = q1 - 1.5 * iqr\n",
    "    else:\n",
    "        iqr_floor = np.nan\n",
    "\n",
    "    candidates = [SUSPECT_PPOZ_FLOOR]\n",
    "    if np.isfinite(store_median): candidates.append(store_median * 0.65)\n",
    "    if np.isfinite(iqr_floor):    candidates.append(iqr_floor)\n",
    "    store_floor = max(candidates)\n",
    "\n",
    "    # Stem medians for internal consistency (on the same filtered dfv)\n",
    "    stem_medians = dfv.groupby(\"stem\")[\"price_per_oz\"].median()\n",
    "\n",
    "    # Row-level checks\n",
    "    is_ounce  = dfv[\"weight_g\"].between(28.0 - OZ_TOL, 28.0 + OZ_TOL, inclusive=\"both\")\n",
    "    per_g     = dfv[\"price\"] / dfv[\"weight_g\"]\n",
    "\n",
    "    low_abs     = is_ounce & (dfv[\"price_per_oz\"] < store_floor)\n",
    "    low_pg      = per_g < SUSPECT_PG_FLOOR\n",
    "    low_vs_stem = is_ounce & dfv[\"stem\"].map(stem_medians).notna() & \\\n",
    "                (dfv[\"price_per_oz\"] < STEM_OUTLIER_RATIO * dfv[\"stem\"].map(stem_medians))\n",
    "\n",
    "    # Build reason strings safely (no DataFrame-to-column assignment mistakes)\n",
    "    reasons_df = pd.DataFrame({\n",
    "        \"abs\":  np.where(low_abs,     f\"abs<{store_floor:.0f}\", \"\"),\n",
    "        \"pg\":   np.where(low_pg,      \"per_g_floor\",            \"\"),\n",
    "        \"stem\": np.where(low_vs_stem, \"stem_outlier\",           \"\"),\n",
    "    }, index=dfv.index)\n",
    "\n",
    "    dfv[\"suspect_reason\"] = reasons_df.replace(\"\", np.nan).agg(lambda s: \",\".join(s.dropna()), axis=1)\n",
    "    dfv[\"is_suspect\"] = low_abs | low_pg | low_vs_stem\n",
    "\n",
    "    # Allow unusual-but-not-insane non-buds items to pass (don’t clear stem outliers)\n",
    "    clear_mask = (~budsish) & (dfv[\"price_per_oz\"] >= VERY_LOW_FLOOR) & (~low_vs_stem)\n",
    "    dfv.loc[clear_mask, [\"is_suspect\",\"suspect_reason\"]] = [False, \"\"]\n",
    "\n",
    "    # Snapshot flags for the audit before we drop anything further\n",
    "    _flags_for_audit = dfv[[\"is_suspect\",\"suspect_reason\"]].copy()\n",
    "\n",
    "    # 4) now compute validity on the filtered set\n",
    "    valid_mask = (~dfv[\"is_suspect\"]) & \\\n",
    "                (dfv[\"price\"] > 0) & (dfv[\"weight_g\"] > 0) & dfv[\"price_per_oz\"].notna() & np.isfinite(dfv[\"price_per_oz\"])\n",
    "    dfv = dfv.loc[valid_mask].copy()\n",
    "    items_valid = int(len(dfv))\n",
    "\n",
    "    # 5) best + median on valid flower\n",
    "    if items_valid > 0:\n",
    "        best_row = dfv.sort_values([\"price_per_oz\",\"weight_g\"], ascending=[True, False]).iloc[0]\n",
    "        best_ppoz_flower   = float(best_row[\"price_per_oz\"])\n",
    "        median_ppoz_flower = float(dfv[\"price_per_oz\"].median())\n",
    "        best_size  = str(best_row.get(\"size_label\") or (f\"{best_row.get('weight_g', ''):g}g\"))\n",
    "        best_item  = str(best_row.get(\"name\") or \"\")\n",
    "        best_price = float(best_row.get(\"price\") or np.nan)\n",
    "    else:\n",
    "        best_ppoz_flower = np.nan\n",
    "        median_ppoz_flower = np.nan\n",
    "        best_size = \"\"\n",
    "        best_item = \"\"\n",
    "        best_price = np.nan\n",
    "\n",
    "\n",
    "    # write a small per-slug audit CSV (top 50 by $/oz) for human inspection\n",
    "    audit_path = \"\"\n",
    "    try:\n",
    "        if total_rows > 0:\n",
    "            audit_df = dfm.copy()\n",
    "            audit_df[\"price\"]        = pd.to_numeric(audit_df.get(\"price\"), errors=\"coerce\")\n",
    "            audit_df[\"weight_g\"]     = pd.to_numeric(audit_df.get(\"weight_g\"), errors=\"coerce\")\n",
    "            audit_df[\"price_per_oz\"] = pd.to_numeric(audit_df.get(\"price_per_oz\"), errors=\"coerce\")\n",
    "\n",
    "            # join the pre-drop flags; rows not present simply won’t have flags\n",
    "            if '_flags_for_audit' in locals():\n",
    "                audit_df = audit_df.join(_flags_for_audit, how=\"left\")\n",
    "            if \"is_suspect\" not in audit_df.columns:\n",
    "                audit_df[\"is_suspect\"] = False\n",
    "            if \"suspect_reason\" not in audit_df.columns:\n",
    "                audit_df[\"suspect_reason\"] = \"\"\n",
    "\n",
    "            audit_df.rename(columns={\"is_suspect\":\"aud_suspect\"}, inplace=True)\n",
    "            audit_df = audit_df.sort_values(\"price_per_oz\")\n",
    "\n",
    "            audit_file = FRS_AUDITS / f\"audit_{slug}.csv\"\n",
    "            keep_cols = [c for c in [\n",
    "                \"name\",\"brand\",\"size_label\",\"price\",\"weight_g\",\"price_per_oz\",\n",
    "                \"report_category\",\"is_bundle\",\"aud_suspect\",\"suspect_reason\"\n",
    "            ] if c in audit_df.columns]\n",
    "            _atomic_write_table_csv(audit_df[keep_cols].head(50), audit_file)\n",
    "            audit_path = str(audit_file)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "    age = _age_str(cache_file) if cache_file.exists() else \"—\"\n",
    "    shake_pct  = (shake_rows/total_rows*100) if total_rows else np.nan\n",
    "    bundle_pct = (bundle_rows/total_rows*100) if total_rows else np.nan\n",
    "\n",
    "    coverage.append({\n",
    "        \"rank\": i+1, \"slug\": slug, \"name\": name, \"miles\": miles,\n",
    "        \"items_total\": total_rows, \"items_valid\": items_valid,\n",
    "        \"shake_pct\": shake_pct, \"bundle_pct\": bundle_pct,\n",
    "        \"min_ppoz_any\": min_ppoz_any,\n",
    "        \"best_ppoz_flower\": best_ppoz_flower,\n",
    "        \"median_ppoz_flower\": median_ppoz_flower,\n",
    "        \"best_size\": best_size, \"best_item\": best_item, \"best_price\": best_price,\n",
    "        \"source\": source, \"age\": age, \"audit\": audit_path\n",
    "    })\n",
    "\n",
    "    # console trace\n",
    "    bp = f\"${best_ppoz_flower:.2f}\" if np.isfinite(best_ppoz_flower) else \"—\"\n",
    "    print(f\"{'•' if source=='cached' else '✓'} {slug:>24s}  items={total_rows:4d}  valid={items_valid:4d}  best_flower={bp}\")\n",
    "\n",
    "    _sleep()  # throttle between slugs\n",
    "\n",
    "cov_df = pd.DataFrame(coverage)\n",
    "\n",
    "# --- hide rows with no qualifying MED flower (Valid == 0) ---\n",
    "shown_df = cov_df[cov_df[\"items_valid\"] > 0].copy().reset_index(drop=True)\n",
    "excluded_zero_items = int((cov_df[\"items_total\"] == 0).sum())\n",
    "excluded_zero_valid = int((cov_df[\"items_valid\"] == 0).sum())\n",
    "\n",
    "# ---------------- HTML status panel (auditable) ----------------\n",
    "def _fmt_money(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "        return f\"${x:,.2f}\" if np.isfinite(x) else \"—\"\n",
    "    except Exception:\n",
    "        return \"—\"\n",
    "\n",
    "def _fmt_pct(x):\n",
    "    try:\n",
    "        x = float(x)\n",
    "        return f\"{x:.0f}%\"\n",
    "    except Exception:\n",
    "        return \"—\"\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "rows_html = \"\"\n",
    "for _, r in shown_df.iterrows():\n",
    "    best_combo = f\"{r['best_size']} • {_fmt_money(r['best_price'])}\" if pd.notna(r['best_price']) else r['best_size']\n",
    "    best_item  = (str(r['best_item'])[:60] + \"…\") if len(str(r['best_item'])) > 60 else str(r['best_item'])\n",
    "    audit_cell = f\"<code style='opacity:.8'>{Path(r['audit']).as_posix()}</code>\" if r['audit'] else \"—\"\n",
    "    rows_html += f\"\"\"\n",
    "      <tr>\n",
    "        <td>{int(r['rank'])}</td>\n",
    "        <td>{r['name']}</td>\n",
    "        <td><code style=\"opacity:.8\">{r['slug']}</code></td>\n",
    "        <td>{r['miles']:.2f} mi</td>\n",
    "        <td>{int(r['items_total'])}</td>\n",
    "        <td>{int(r['items_valid'])}</td>\n",
    "        <td>{_fmt_money(r['best_ppoz_flower'])}</td>\n",
    "        <td>{_fmt_money(r['median_ppoz_flower'])}</td>\n",
    "        <td title=\"{best_item}\">{best_combo}</td>\n",
    "        <td>{_fmt_money(r['min_ppoz_any'])}</td>\n",
    "        <td>{_fmt_pct(r['shake_pct'])}</td>\n",
    "        <td>{_fmt_pct(r['bundle_pct'])}</td>\n",
    "        <td>{r['source']}</td>\n",
    "        <td>{r['age']}</td>\n",
    "        <td>{audit_cell}</td>\n",
    "      </tr>\n",
    "    \"\"\"\n",
    "\n",
    "panel_html = f\"\"\"\n",
    "<style>\n",
    ":root{{color-scheme:dark light}}\n",
    ".card{{background:linear-gradient(180deg,rgba(255,255,255,.06),rgba(255,255,255,.02));\n",
    "border:1px solid rgba(255,255,255,.12);border-radius:14px;padding:16px;color:#E6EAF2;\n",
    "font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto}}\n",
    ".kv{{display:grid;grid-template-columns: 160px 1fr;gap:6px;font-size:13px}}\n",
    ".badge{{display:inline-block;padding:2px 8px;border-radius:999px;background:rgba(255,255,255,.10);border:1px solid rgba(255,255,255,.14);font-size:11px}}\n",
    ".table-wrap{{overflow:auto;}}\n",
    "table{{width:100%;border-collapse:collapse;margin-top:10px;font-size:12.5px;min-width:1200px}}\n",
    "th,td{{border-bottom:1px dashed rgba(255,255,255,.12);padding:6px 8px;text-align:left;vertical-align:top}}\n",
    "thead th{{opacity:.8;position:sticky;top:0;background:rgba(0,0,0,.25);backdrop-filter:saturate(180%) blur(6px)}}\n",
    ".small{{opacity:.75;font-size:11px}}\n",
    "</style>\n",
    "<div class=\"card\">\n",
    "  <div style=\"display:flex;align-items:baseline;gap:10px;margin-bottom:6px\">\n",
    "    <div style=\"font-weight:700;font-size:18px;\">Leaderboard Seed Status (Auditable)</div>\n",
    "    <span class=\"badge\">nearest considered: {K_NEAREST}</span>\n",
    "    <span class=\"badge\">shown (valid MED flower): {len(shown_df)}/{len(sel_df)}</span>\n",
    "    <span class=\"badge\">generated {ts}</span>\n",
    "  </div>\n",
    "  <div class=\"kv\">\n",
    "    <div>LATLNG</div><div>{LATLNG_STRING}</div>\n",
    "    <div>listings</div><div>{len(listings_df)} (saved → {Path(listings_main).name})</div>\n",
    "    <div>cache dir</div><div>flower_reports_showcase/normalized/menus</div>\n",
    "    <div>rate</div><div>sleep {BASE_SLEEP}s ± {JITTER}s • TTL {TTL_HOURS}h • tries {MAX_TRIES} • force {FORCE_REFRESH}</div>\n",
    "  </div>\n",
    "  <div class=\"table-wrap\">\n",
    "  <table>\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th>#</th><th>Name</th><th>Slug</th><th>Distance</th>\n",
    "        <th>Items</th><th>Valid</th>\n",
    "        <th>Best $/oz (FLOWER)</th><th>Median $/oz (FLOWER)</th>\n",
    "        <th>Best size/price</th>\n",
    "        <th>Min $/oz (ANY)</th><th>Shake%</th><th>Bundle%</th>\n",
    "        <th>Source</th><th>Age</th><th>Audit CSV</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      {rows_html if rows_html else \"<tr><td colspan='15' class='small'>No menus fetched.</td></tr>\"}\n",
    "    </tbody>\n",
    "  </table>\n",
    "  </div>\n",
    "  <div class=\"small\" style=\"margin-top:8px\">\n",
    "    Mirrors written to ./data/normalized/menus for compatibility.\n",
    "    Set WM_FORCE_REFRESH=1 to bypass TTL. Hidden rows: Items=0 → {excluded_zero_items}, Valid=0 → {excluded_zero_valid}.\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Save + display status (ATOMIC)\n",
    "status_path = FRS_REPORTS / \"nearby_value_cache_status.html\"\n",
    "_atomic_write_text(status_path, panel_html, encoding=\"utf-8\")\n",
    "display(HTML(panel_html))\n",
    "\n",
    "# Final minimal console confirmation (useful if HTML isn't displayed by environment)\n",
    "print(f\"✅ listings_df → {listings_main}\")\n",
    "print(f\"✅ menus cached to {FRS_MENUS}  (shown in table: {len(shown_df)}, hidden: items=0 [{excluded_zero_items}], valid=0 [{excluded_zero_valid}])\")\n",
    "print(f\"ℹ️  status HTML → {status_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91310337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Distance-Adjusted Value Leaderboard — single idempotent cell\n",
    "# Uses outputs from the prior seed/populate cell:\n",
    "#   - LATLNG, listings_df (or FRS_NORM/LEGACY files)\n",
    "#   - sel_df (K-nearest with miles) if present; otherwise recompute\n",
    "#   - cov_df (per-slug audit metrics) if present; otherwise derive from cached menus\n",
    "#   - cached menus under flower_reports_showcase/normalized/menus\n",
    "#\n",
    "# Ranks by Adjusted $/oz = best_flower_$per_oz × (1 + 0.02 × miles)\n",
    "# Only includes slugs with items_valid > 0 (valid MED flower after filters).\n",
    "# Saves an auditable HTML to flower_reports_showcase/reports/nearby_value_leaderboard.html\n",
    "\n",
    "import os, math, re, time, glob\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ---------------- paths & small helpers ----------------\n",
    "FRS_ROOT     = Path(\"flower_reports_showcase\")\n",
    "FRS_NORM     = FRS_ROOT / \"normalized\"\n",
    "FRS_MENUS    = FRS_NORM / \"menus\"\n",
    "FRS_REPORTS  = FRS_ROOT / \"reports\"\n",
    "FRS_AUDITS   = FRS_REPORTS / \"audits\"\n",
    "FRS_REPORTS.mkdir(parents=True, exist_ok=True)\n",
    "FRS_AUDITS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LEGACY_NORM  = Path(\"./data/normalized\")\n",
    "LEGACY_MENUS = LEGACY_NORM / \"menus\"\n",
    "\n",
    "# use existing atomic writer if provided by the previous cell, otherwise a local safe fallback\n",
    "_prev_atomic_write_text = globals().get(\"_atomic_write_text\", None)\n",
    "\n",
    "def write_text_atomic(path: Path, text: str, encoding=\"utf-8\"):\n",
    "    if callable(_prev_atomic_write_text):\n",
    "        try:\n",
    "            return _prev_atomic_write_text(path, text, encoding=encoding)\n",
    "        except Exception:\n",
    "            pass  # fall back to local implementation below\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    with open(tmp, \"w\", encoding=encoding) as f:\n",
    "        f.write(text)\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "def _safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def haversine_mi(lat1, lon1, lat2, lon2) -> float:\n",
    "    R = 3958.7613  # miles\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    return R * (2*math.atan2(math.sqrt(a), math.sqrt(1 - a)))\n",
    "\n",
    "def _exists_df(name):\n",
    "    return (name in globals()) and isinstance(globals()[name], pd.DataFrame) and not globals()[name].empty\n",
    "\n",
    "def _age_str(p: Path) -> str:\n",
    "    try:\n",
    "        sec = max(0, time.time() - p.stat().st_mtime)\n",
    "        if sec < 90: return f\"{int(sec)}s\"\n",
    "        mins = sec / 60\n",
    "        if mins < 90: return f\"{mins:.0f}m\"\n",
    "        hrs = mins / 60\n",
    "        if hrs < 48: return f\"{hrs:.1f}h\"\n",
    "        days = hrs / 24\n",
    "        return f\"{days:.1f}d\"\n",
    "    except Exception:\n",
    "        return \"—\"\n",
    "\n",
    "# ---------------- reuse regex & filters from previous cell ----------------\n",
    "OZ_TO_G = 28.0\n",
    "if \"BAD_OUNCE_PAT\" not in globals():\n",
    "    BAD_OUNCE_PAT = re.compile(r'\\b(shake|trim|popcorn|littles?|smalls?|small\\s*buds?|red\\s*[-\\s]*tier|moon\\s*rocks?|moonrock|infused|pre[-\\s]?rolls?|prerolls?)\\b', re.I)\n",
    "if \"BUNDLE_PAT\" not in globals():\n",
    "    BUNDLE_PAT   = re.compile(r'\\b(mix[-\\s]*and[-\\s]*match|bundle|bogo|two[-\\s]?for|\\d+\\s*x|pack|multi[-\\s]*pack)\\b', re.I)\n",
    "\n",
    "def _col_str(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return df[col].astype(str) if col in df.columns else pd.Series(\"\", index=df.index, dtype=str)\n",
    "def _col_bool(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return df[col].fillna(False).astype(bool) if col in df.columns else pd.Series(False, index=df.index, dtype=bool)\n",
    "def _col_num(df: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return pd.to_numeric(df[col], errors=\"coerce\") if col in df.columns else pd.Series(np.nan, index=df.index, dtype=float)\n",
    "\n",
    "# ---------------- load LATLNG and listings ----------------\n",
    "if \"LATLNG\" not in globals() or LATLNG is None:\n",
    "    raise RuntimeError(\"LATLNG is missing; run the previous cell first.\")\n",
    "\n",
    "def _ensure_listings_df():\n",
    "    if _exists_df(\"listings_df\"):\n",
    "        return globals()[\"listings_df\"][[\"slug\",\"lat\",\"lon\",\"name\"]].copy()\n",
    "    # try FRS then LEGACY\n",
    "    for p in [FRS_NORM / \"listings.parquet\", LEGACY_NORM / \"listings.parquet\",\n",
    "              FRS_NORM / \"listings.csv\",      LEGACY_NORM / \"listings.csv\"]:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                df = pd.read_parquet(p) if p.suffix == \".parquet\" else pd.read_csv(p)\n",
    "                cols = {c.lower(): c for c in df.columns}\n",
    "                slug = cols.get(\"slug\") or \"slug\"\n",
    "                lat  = cols.get(\"lat\") or cols.get(\"latitude\") or \"lat\"\n",
    "                lon  = cols.get(\"lon\") or cols.get(\"longitude\") or \"lon\"\n",
    "                name = cols.get(\"name\") or \"name\"\n",
    "                df = df.rename(columns={slug:\"slug\", lat:\"lat\", lon:\"lon\", name:\"name\"})\n",
    "                return df[[\"slug\",\"lat\",\"lon\",\"name\"]].dropna()\n",
    "            except Exception:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "list_df = _ensure_listings_df()\n",
    "if list_df is None or list_df.empty:\n",
    "    raise RuntimeError(\"No listings available; run the previous cell to generate normalized listings.\")\n",
    "\n",
    "origin_lat, origin_lon = float(LATLNG[0]), float(LATLNG[1])\n",
    "\n",
    "# ---------------- nearest set (re-use sel_df if present for consistency) ----------------\n",
    "if _exists_df(\"sel_df\"):\n",
    "    nearest = globals()[\"sel_df\"][[\"slug\",\"name\",\"miles\"]].copy()\n",
    "else:\n",
    "    df2 = list_df.copy()\n",
    "    df2[\"miles\"] = df2.apply(lambda r: haversine_mi(origin_lat, origin_lon, _safe_float(r[\"lat\"]), _safe_float(r[\"lon\"])), axis=1)\n",
    "    K = int(globals().get(\"K_NEAREST\", 50))\n",
    "    nearest = df2.sort_values(\"miles\").head(K)[[\"slug\",\"name\",\"miles\"]].copy()\n",
    "\n",
    "# ---------------- get per-slug metrics (prefer cov_df from previous cell) ----------------\n",
    "def _read_cached_menu(slug: str) -> pd.DataFrame:\n",
    "    for p in [FRS_MENUS / f\"{slug}.parquet\",\n",
    "              LEGACY_MENUS / f\"{slug}.parquet\",\n",
    "              FRS_MENUS / f\"{slug}.csv\",\n",
    "              LEGACY_MENUS / f\"{slug}.csv\"]:\n",
    "        if p.exists():\n",
    "            try:\n",
    "                return pd.read_parquet(p) if p.suffix == \".parquet\" else pd.read_csv(p)\n",
    "            except Exception:\n",
    "                continue\n",
    "    return pd.DataFrame()\n",
    "\n",
    "def _valid_flower_stats_from_df(dfm: pd.DataFrame):\n",
    "    \"\"\"Return dict with items_valid, best_ppoz_flower, median_ppoz_flower, best fields, min_ppoz_any, shake_pct, bundle_pct.\"\"\"\n",
    "    out = {\n",
    "        \"items_valid\": 0, \"best_ppoz_flower\": np.nan, \"median_ppoz_flower\": np.nan,\n",
    "        \"best_size\": \"\", \"best_item\": \"\", \"best_price\": np.nan,\n",
    "        \"min_ppoz_any\": np.nan, \"shake_pct\": np.nan, \"bundle_pct\": np.nan\n",
    "    }\n",
    "    total = int(len(dfm))\n",
    "    if total == 0:\n",
    "        return out\n",
    "\n",
    "    # counts for audit\n",
    "    if \"report_category\" in dfm.columns:\n",
    "        shake_rows = int((dfm[\"report_category\"].astype(str).str.lower() == \"shake/popcorn/trim\").sum())\n",
    "    else:\n",
    "        nm = _col_str(dfm, \"name\"); sl = _col_str(dfm, \"size_label\")\n",
    "        shake_rows = int((nm.str.contains(BAD_OUNCE_PAT, regex=True, na=False) |\n",
    "                          sl.str.contains(BAD_OUNCE_PAT, regex=True, na=False)).sum())\n",
    "\n",
    "    if \"is_bundle\" in dfm.columns:\n",
    "        bundle_rows = int(_col_bool(dfm, \"is_bundle\").sum())\n",
    "    else:\n",
    "        nm = _col_str(dfm, \"name\"); sl = _col_str(dfm, \"size_label\")\n",
    "        bundle_rows = int((nm.str.contains(BUNDLE_PAT, regex=True, na=False) |\n",
    "                           sl.str.contains(BUNDLE_PAT, regex=True, na=False)).sum())\n",
    "\n",
    "    out[\"min_ppoz_any\"] = float(pd.to_numeric(dfm.get(\"price_per_oz\"), errors=\"coerce\").min())\n",
    "\n",
    "    # filter valid flower (non-shake, non-bundle, numeric price/weight/ppoz)\n",
    "    dfv = dfm.copy()\n",
    "    if \"report_category\" in dfv.columns:\n",
    "        dfv = dfv[dfv[\"report_category\"].astype(str).str.lower() != \"shake/popcorn/trim\"]\n",
    "    else:\n",
    "        nm = _col_str(dfv, \"name\"); sl = _col_str(dfv, \"size_label\")\n",
    "        mask_bad = nm.str.contains(BAD_OUNCE_PAT, regex=True, na=False) | sl.str.contains(BAD_OUNCE_PAT, regex=True, na=False)\n",
    "        dfv = dfv[~mask_bad]\n",
    "    if \"is_bundle\" in dfv.columns:\n",
    "        dfv = dfv[~_col_bool(dfv, \"is_bundle\")]\n",
    "    else:\n",
    "        nm = _col_str(dfv, \"name\"); sl = _col_str(dfv, \"size_label\")\n",
    "        mask_bundle = nm.str.contains(BUNDLE_PAT, regex=True, na=False) | sl.str.contains(BUNDLE_PAT, regex=True, na=False)\n",
    "        dfv = dfv[~mask_bundle]\n",
    "\n",
    "    price_s = _col_num(dfv, \"price\")\n",
    "    wt_s    = _col_num(dfv, \"weight_g\")\n",
    "    ppoz_s  = _col_num(dfv, \"price_per_oz\")\n",
    "    valid_mask = (price_s > 0) & (wt_s > 0) & ppoz_s.notna() & np.isfinite(ppoz_s)\n",
    "    dfv = dfv.loc[valid_mask].copy()\n",
    "    out[\"items_valid\"] = int(valid_mask.sum())\n",
    "\n",
    "    if out[\"items_valid\"] > 0:\n",
    "        dfv[\"price_per_oz\"] = ppoz_s.loc[dfv.index]\n",
    "        dfv[\"weight_g\"]     = wt_s.loc[dfv.index]\n",
    "        dfv[\"price\"]        = price_s.loc[dfv.index]\n",
    "        best = dfv.sort_values([\"price_per_oz\",\"weight_g\"], ascending=[True, False]).iloc[0]\n",
    "        out[\"best_ppoz_flower\"]   = float(best[\"price_per_oz\"])\n",
    "        out[\"median_ppoz_flower\"] = float(dfv[\"price_per_oz\"].median())\n",
    "        out[\"best_item\"]  = str(best.get(\"name\") or \"\")\n",
    "        if \"size_label\" in dfv.columns and pd.notna(best.get(\"size_label\")) and str(best.get(\"size_label\")).strip():\n",
    "            out[\"best_size\"] = str(best.get(\"size_label\"))\n",
    "        else:\n",
    "            g = best.get(\"weight_g\")\n",
    "            out[\"best_size\"] = (f\"{g:.0f}g\" if pd.notna(g) and abs(g - round(g)) < 1e-6 else f\"{g:g}g\") if pd.notna(g) else \"\"\n",
    "        out[\"best_price\"] = float(best.get(\"price\") or np.nan)\n",
    "\n",
    "    out[\"shake_pct\"]  = (shake_rows/total*100.0) if total else np.nan\n",
    "    out[\"bundle_pct\"] = (bundle_rows/total*100.0) if total else np.nan\n",
    "    return out\n",
    "\n",
    "# Compose leaderboard rows\n",
    "rows = []\n",
    "cov = globals().get(\"cov_df\", None)\n",
    "for _, r in nearest.iterrows():\n",
    "    slug  = str(r[\"slug\"])\n",
    "    name  = str(r[\"name\"])\n",
    "    miles = float(r[\"miles\"])\n",
    "    cache_p = FRS_MENUS / f\"{slug}.parquet\"\n",
    "    age = _age_str(cache_p) if cache_p.exists() else \"—\"\n",
    "\n",
    "    # Prefer metrics from cov_df if available\n",
    "    rec = None\n",
    "    if isinstance(cov, pd.DataFrame) and not cov.empty and \"slug\" in cov.columns:\n",
    "        m = cov[cov[\"slug\"] == slug]\n",
    "        if not m.empty:\n",
    "            s = m.iloc[0]\n",
    "            rec = {\n",
    "                \"items_valid\": int(_safe_float(s.get(\"items_valid\")) if \"items_valid\" in s else 0),\n",
    "                \"best_ppoz_flower\": _safe_float(s.get(\"best_ppoz_flower\")),\n",
    "                \"median_ppoz_flower\": _safe_float(s.get(\"median_ppoz_flower\")),\n",
    "                \"best_size\": s.get(\"best_size\") if \"best_size\" in s else \"\",\n",
    "                \"best_item\": s.get(\"best_item\") if \"best_item\" in s else \"\",\n",
    "                \"best_price\": _safe_float(s.get(\"best_price\")),\n",
    "                \"min_ppoz_any\": _safe_float(s.get(\"min_ppoz_any\")),\n",
    "                \"shake_pct\": _safe_float(s.get(\"shake_pct\")),\n",
    "                \"bundle_pct\": _safe_float(s.get(\"bundle_pct\")),\n",
    "                \"source\": s.get(\"source\") if \"source\" in s else \"cached\",\n",
    "                \"age\": s.get(\"age\") if \"age\" in s else age,\n",
    "                \"audit\": s.get(\"audit\") if \"audit\" in s else \"\"\n",
    "            }\n",
    "\n",
    "    # If no cov_df record, derive from cached menu\n",
    "    if rec is None:\n",
    "        dfm = _read_cached_menu(slug)\n",
    "        stats = _valid_flower_stats_from_df(dfm)\n",
    "        rec = {\n",
    "            **stats,\n",
    "            \"source\": \"cached\" if not dfm.empty else \"missing\",\n",
    "            \"age\": age,\n",
    "            \"audit\": str(FRS_AUDITS / f\"audit_{slug}.csv\") if (FRS_AUDITS / f\"audit_{slug}.csv\").exists() else \"\"\n",
    "        }\n",
    "\n",
    "    if rec[\"items_valid\"] <= 0 or not np.isfinite(rec[\"best_ppoz_flower\"]):\n",
    "        continue  # hide invalids\n",
    "\n",
    "    adj = rec[\"best_ppoz_flower\"] * (1.0 + 0.02 * miles)\n",
    "    rows.append({\n",
    "        \"slug\": slug, \"name\": name, \"miles\": miles,\n",
    "        \"raw_ppoz\": rec[\"best_ppoz_flower\"],\n",
    "        \"adj_ppoz\": adj,\n",
    "        \"median_ppoz\": rec[\"median_ppoz_flower\"],\n",
    "        \"min_ppoz_any\": rec[\"min_ppoz_any\"],\n",
    "        \"best_size\": rec[\"best_size\"],\n",
    "        \"best_item\": rec[\"best_item\"],\n",
    "        \"best_price\": rec[\"best_price\"],\n",
    "        \"items_valid\": rec[\"items_valid\"],\n",
    "        \"shake_pct\": rec[\"shake_pct\"],\n",
    "        \"bundle_pct\": rec[\"bundle_pct\"],\n",
    "        \"source\": rec.get(\"source\",\"cached\"),\n",
    "        \"age\": rec.get(\"age\",\"—\"),\n",
    "        \"audit\": rec.get(\"audit\",\"\")\n",
    "    })\n",
    "\n",
    "lb_df = pd.DataFrame(rows)\n",
    "if lb_df.empty:\n",
    "    html = \"<div style='padding:16px;border:1px dashed #999;border-radius:10px;'>No valid MED flower found in nearest caches. Run the previous cell or adjust K_NEAREST.</div>\"\n",
    "    out_path = FRS_REPORTS / \"nearby_value_leaderboard.html\"\n",
    "    write_text_atomic(out_path, html, \"utf-8\")\n",
    "    display(HTML(html))\n",
    "    print(f\"Saved HTML to: {out_path.resolve()}\")\n",
    "else:\n",
    "    # sort by adjusted price\n",
    "    lb_df = lb_df.sort_values(\"adj_ppoz\").reset_index(drop=True)\n",
    "\n",
    "    # formatting helpers\n",
    "    def fmt_money(x):\n",
    "        x = _safe_float(x)\n",
    "        return \"—\" if not np.isfinite(x) else f\"${x:,.2f}\"\n",
    "    def fmt_miles(x):\n",
    "        x = _safe_float(x);  return \"—\" if not np.isfinite(x) else f\"{x:.2f} mi\"\n",
    "    def fmt_pct(x):\n",
    "        x = _safe_float(x);  return \"—\" if not np.isfinite(x) else f\"{x:.0f}%\"\n",
    "    def esc(s): \n",
    "        return (str(s or \"\")\n",
    "                .replace(\"&\",\"&amp;\").replace(\"<\",\"&lt;\").replace(\">\",\"&gt;\"))\n",
    "\n",
    "    # bar scale\n",
    "    vmin = float(lb_df[\"adj_ppoz\"].min())\n",
    "    vmax = float(lb_df[\"adj_ppoz\"].max())\n",
    "    def svg_bar(val):\n",
    "        if not np.isfinite(val) or vmax <= vmin:\n",
    "            frac = 1.0\n",
    "        else:\n",
    "            frac = (val - vmin) / (vmax - vmin)\n",
    "        frac = max(0.02, min(1.0, frac))\n",
    "        w = int(6 + 94 * frac)\n",
    "        hue = 140 - int(120 * frac)  # green -> red\n",
    "        return f'''\n",
    "        <svg width=\"100%\" height=\"10\" viewBox=\"0 0 100 10\" preserveAspectRatio=\"none\" aria-hidden=\"true\">\n",
    "          <rect x=\"0\" y=\"0\" width=\"100\" height=\"10\" rx=\"5\" fill=\"rgba(255,255,255,0.12)\"></rect>\n",
    "          <rect x=\"0\" y=\"0\" width=\"{w}\" height=\"10\" rx=\"5\" fill=\"hsl({hue}, 70%, 50%)\"></rect>\n",
    "        </svg>'''\n",
    "\n",
    "    # build cards\n",
    "    cards_html = []\n",
    "    for _, r in lb_df.iterrows():\n",
    "        name   = esc(r[\"name\"])\n",
    "        slug   = esc(r[\"slug\"])\n",
    "        miles  = fmt_miles(r[\"miles\"])\n",
    "        raw    = fmt_money(r[\"raw_ppoz\"])\n",
    "        median = fmt_money(r[\"median_ppoz\"])\n",
    "        adj    = fmt_money(r[\"adj_ppoz\"])\n",
    "        anymin = fmt_money(r[\"min_ppoz_any\"])\n",
    "        size   = esc(r[\"best_size\"])\n",
    "        price  = fmt_money(r[\"best_price\"])\n",
    "        item_full = esc(r[\"best_item\"])\n",
    "        item  = item_full[:90] + (\"…\" if len(item_full) > 90 else \"\")\n",
    "        audit  = esc(r[\"audit\"]) if r[\"audit\"] else \"—\"\n",
    "        shake  = fmt_pct(r[\"shake_pct\"])\n",
    "        bundle = fmt_pct(r[\"bundle_pct\"])\n",
    "        src    = esc(r.get(\"source\",\"cached\"))\n",
    "        age    = esc(r.get(\"age\",\"—\"))\n",
    "        bar    = svg_bar(_safe_float(r[\"adj_ppoz\"]))\n",
    "\n",
    "        cards_html.append(f\"\"\"\n",
    "        <div class=\"card\">\n",
    "          <div class=\"head\">\n",
    "            <div class=\"title\">{name}</div>\n",
    "            <div class=\"slug\"><code>{slug}</code></div>\n",
    "          </div>\n",
    "          <div class=\"kv\"><span class=\"k\">Distance</span><span class=\"v\">{miles}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Raw $/oz (FLOWER)</span><span class=\"v\">{raw}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Adjusted $/oz</span><span class=\"v\">{adj}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Median $/oz (FLOWER)</span><span class=\"v\">{median}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Min $/oz (ANY)</span><span class=\"v\">{anymin}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Best size/price</span><span class=\"v\">{size} • {price}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Best item</span><span class=\"v\" title=\"{item_full}\">{item}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Items</span><span class=\"v\">{int(r['items_valid'])} valid</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Shake / Bundle</span><span class=\"v\">{shake} • {bundle}</span></div>\n",
    "          <div class=\"kv\"><span class=\"k\">Source / Age</span><span class=\"v\">{src} • {age}</span></div>\n",
    "          <hr/>\n",
    "          {bar}\n",
    "        </div>\n",
    "        \"\"\")\n",
    "\n",
    "    now = pd.Timestamp.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "    :root{color-scheme:dark light;}\n",
    "    body{font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, \"Apple Color Emoji\",\"Segoe UI Emoji\";\n",
    "         background:#0b0d10; color:#E6EAF2; margin:0; padding:28px;}\n",
    "    .header{display:flex; align-items:baseline; gap:10px; margin-bottom:16px;}\n",
    "    .h1{font-size:20px; font-weight:700;}\n",
    "    .sub{opacity:.75; font-size:12px}\n",
    "    .grid{display:grid; grid-template-columns: repeat(auto-fill, minmax(280px, 1fr)); gap:14px;}\n",
    "    .card{background:linear-gradient(180deg, rgba(255,255,255,0.06), rgba(255,255,255,0.02));\n",
    "          border:1px solid rgba(255,255,255,0.10); border-radius:14px; padding:14px;\n",
    "          box-shadow:0 6px 24px rgba(0,0,0,0.25);}\n",
    "    .head{display:flex; justify-content:space-between; align-items:center; margin-bottom:8px;}\n",
    "    .title{font-weight:700; font-size:16px;}\n",
    "    .slug code{opacity:.8; font-size:11px;}\n",
    "    .kv{display:flex; align-items:center; justify-content:space-between; font-size:13px; margin:4px 0;}\n",
    "    .k{opacity:.75; min-width:140px;}\n",
    "    hr{border:none; border-top:1px dashed rgba(255,255,255,0.12); margin:8px 0;}\n",
    "    .footer{opacity:.75; font-size:11px; margin-top:12px;}\n",
    "    @media (prefers-reduced-motion: no-preference){\n",
    "      .card{transition: transform .15s ease}\n",
    "      .card:hover{transform: translateY(-2px)}\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    header = f\"\"\"\n",
    "    <div class=\"header\">\n",
    "      <div class=\"h1\">Distance-Adjusted Value Leaderboard</div>\n",
    "      <div class=\"sub\">Adjusted $/oz = best FLOWER $/oz × (1 + 0.02 × miles) • Generated {now}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    footer = \"\"\"\n",
    "    <div class=\"footer\">Lower adjusted price is better. Filters exclude shake/trim/popcorn and bundle/mix-and-match items.\n",
    "    Per-slug audit CSVs list the cheapest items by $/oz for manual review.</div>\n",
    "    \"\"\"\n",
    "\n",
    "    html = f\"<!doctype html><html><head><meta charset='utf-8'>{style}<title>Nearby Value Leaderboard</title></head><body>{header}<div class='grid'>{''.join(cards_html)}</div>{footer}</body></html>\"\n",
    "\n",
    "    out_path = FRS_REPORTS / \"nearby_value_leaderboard.html\"\n",
    "    write_text_atomic(out_path, html, \"utf-8\")\n",
    "    display(HTML(html))\n",
    "    print(f\"Saved HTML to: {out_path.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312-jupyter-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
