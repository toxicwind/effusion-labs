{
  "config/site.js": "/**\n * Global configuration shared across the build.\n * @module config\n */\n\n/** Eleventy directory settings */\nexport const dirs = {\n  input: 'src',\n  output: process.env.ELEVENTY_TEST_OUTPUT || '_site',\n  includes: '_includes',\n  data: '_data',\n};\n\nexport default { dirs };\n",
  "config/build-info.js": "// lib/build-info.js\n// A simple, synchronous utility to get build information without relying on Git.\n\nexport function getBuildInfo() {\n  const date = new Date();\n  const isCI = process.env.GITHUB_ACTIONS === 'true';\n\n  return {\n    // In CI, the commit hash is free. Locally, we don't need it.\n    hash: isCI ? (process.env.GITHUB_SHA || 'ci-build').substring(0, 7) : 'local',\n    fullHash: isCI ? process.env.GITHUB_SHA : null,\n    branch: isCI ? process.env.GITHUB_REF_NAME : null,\n\n    // Author/subject are omitted for speed and simplicity.\n    author: null,\n    subject: null,\n\n    // The date is always the current build time, which is more relevant for a static site.\n    date: date,\n    iso: date.toISOString(),\n\n    // The 'dirty' flag is irrelevant without Git. CI is always clean.\n    dirty: false,\n    \n    // The environment of the build.\n    env: process.env.ELEVENTY_ENV || (isCI ? 'production' : 'development'),\n  };\n}\n\nexport default { getBuildInfo };",
  "config/filters.js": "import generateConceptMapJSONLD from './concept-map.js';\nimport { DateTime } from 'luxon';\nimport path from 'node:path';\nimport { ordinalSuffix, readFileCached, webpageToMarkdown } from './utils.js';\n\nconst toStr = v => String(v ?? '');\n\n/** URL-encode a string for safe query parameters */\nfunction url_encode(v = '') {\n  try {\n    return encodeURIComponent(String(v ?? ''));\n  } catch {\n    return '';\n  }\n}\n\n\n/**\n * Format a Date into a human readable string.\n * @param {Date} d\n * @param {string} [zone='utc'] - timezone identifier\n * @returns {string}\n */\nfunction readableDate(d, zone = 'utc') {\n  if (!(d instanceof Date)) return '';\n  const dt = DateTime.fromJSDate(d, { zone });\n  return `${dt.toFormat('MMMM d')}${ordinalSuffix(dt.day)}, ${dt.toFormat('yyyy')}`;\n}\n\n/**\n * Return a date formatted for HTML date attributes.\n * @param {Date} d\n * @returns {string}\n */\nfunction htmlDateString(d) {\n  return d instanceof Date ? DateTime.fromJSDate(d, { zone: 'utc' }).toFormat('yyyy-MM-dd') : '';\n}\n\n/** Estimate reading time in minutes */\nfunction readingTime(text = '', wordsPerMinute = 200) {\n  const count = toStr(text).trim().split(/\\s+/).filter(Boolean).length;\n  const minutes = Math.max(1, Math.ceil(count / wordsPerMinute));\n  return `${minutes} min read`;\n}\n\nconst ELLIPSIS = 'â€¦';\n\n/**\n * Truncate a string and append an ellipsis when exceeding length.\n * @param {string} str\n * @param {number} n\n * @returns {string}\n */\nfunction truncate(str = '', n = 140) {\n  if (typeof str !== 'string' || n <= 0) return '';\n  return str.length > n ? `${str.slice(0, n)}${ELLIPSIS}` : str;\n}\n\n/**\n * Convert a string into a URL friendly slug.\n * @param {string} str\n * @returns {string}\n */\nfunction slugify(str = '') {\n  return String(str)\n    .toLowerCase()\n    .trim()\n    .replace(/[^a-z0-9]+/g, '-')\n    .replace(/(^-|-$)+/g, '');\n}\n\n/** Limit an array to n items */\nfunction limit(arr = [], n = 5) {\n  return Array.isArray(arr) ? arr.slice(0, n) : [];\n}\n\n/** Determine if a date is within the last `days` days */\nfunction isNew(d, days = 14) {\n  if (!(d instanceof Date)) return false;\n  const now = DateTime.now().toUTC();\n  const then = DateTime.fromJSDate(d, { zone: 'utc' });\n  return now.diff(then, 'days').days <= days;\n}\n\n/** Uppercase text for brutalist accents */\nfunction shout(str = '') {\n  return toStr(str).toUpperCase();\n}\n\n/** Format currency value with ISO code */\nfunction money(value = 0, code = '') {\n  const num = Number(value);\n  const cur = toStr(code).toUpperCase();\n  if (!cur || Number.isNaN(num)) return '';\n  return `${cur} ${num.toFixed(2)}`;\n}\n\n/** Convert boolean to Yes/No */\nfunction yesNo(v) {\n  return v ? 'Yes' : 'No';\n}\n\n/** Render ISO date as YYYY-MM-DD within <time> */\nfunction humanDate(iso = '') {\n  if (typeof iso !== 'string' || !iso) return '';\n  const d = DateTime.fromISO(iso, { zone: 'utc' });\n  if (!d.isValid) return '';\n  const fmt = d.toFormat('yyyy-LL-dd');\n  return `<time datetime=\"${iso}\">${fmt}</time>`;\n}\n\n/** Title-case a slug */\nfunction titleizeSlug(str = '') {\n  return toStr(str)\n    .split('-')\n    .filter(Boolean)\n    .map(s => s.charAt(0).toUpperCase() + s.slice(1))\n    .join(' ');\n}\n\n/** Extract hostname from URL */\nfunction hostname(url = '') {\n  try {\n    return new URL(url).hostname;\n  } catch {\n    return '';\n  }\n}\n\n/** Build absolute URL from path and base */\nfunction absoluteUrl(path = '', base = process.env.SITE_URL || '') {\n  try {\n    return new URL(path, base).toString();\n  } catch {\n    return path;\n  }\n}\n\n/**\n * Load provenance entries from a JSONL file reference.\n * @param {string} ref - provenance_ref path stored on product data\n * @returns {Array<Object>}\n */\nfunction provenanceSources(ref = '') {\n  if (typeof ref !== 'string' || ref.trim() === '') return [];\n  const rel = ref.startsWith('/') ? ref.slice(1) : ref;\n  const full = path.join(process.cwd(), 'src', rel);\n  const raw = readFileCached(full);\n  if (raw === null) return [];\n  const lines = raw.trim().split('\\n').filter(Boolean);\n  return lines\n    .map(line => {\n      try {\n        return JSON.parse(line);\n      } catch {\n        return null;\n      }\n    })\n    .filter(Boolean);\n}\n\n// Map `/content/archives/.../provenance/<file>.jsonl` â†’ `/archives/.../provenance/<slug>/`\nfunction provenanceViewerUrl(ref = '') {\n  if (typeof ref !== 'string' || !ref.includes('/provenance/')) return ref;\n  const clean = ref.replace(/^\\/*content\\//, ''); // remove leading /content/\n  const parts = clean.split('/');\n  // expect: archives/<industry>/<category>/<company>/<line>/provenance/<file>.jsonl\n  const idx = parts.lastIndexOf('provenance');\n  if (idx < 0 || !parts[idx+1]) return ref;\n  const file = parts[idx+1].replace(/\\.jsonl$/, '');\n  const slug = file.replace(/--+/g, '-');\n  const prefix = parts.slice(1, idx).join('/'); // drop leading 'archives'\n  return `/archives/${prefix}/provenance/${slug}/`;\n}\n\n// Map to downloadable static copy alongside viewer\nfunction provenanceDownloadUrl(ref = '') {\n  if (typeof ref !== 'string' || !ref.includes('/provenance/')) return ref;\n  const clean = ref.replace(/^\\/*content\\//, '');\n  const parts = clean.split('/');\n  const idx = parts.lastIndexOf('provenance');\n  if (idx < 0 || !parts[idx+1]) return ref;\n  const file = parts[idx+1].replace(/\\.jsonl$/, '');\n  const slug = file.replace(/--+/g, '-');\n  const prefix = parts.slice(1, idx).join('/');\n  return `/archives/${prefix}/provenance/${slug}.jsonl`;\n}\n\n/**\n * Serialize collection data for graph visualisation.\n * @param {Array<Object>} data - eleventy page objects\n * @returns {string}\n */\nfunction jsonify(data) {\n  if (!Array.isArray(data)) return '[]';\n  return JSON.stringify(\n    data\n      .map(page => {\n        const p = page?.inputPath;\n        if (!p) return null;\n        let raw = readFileCached(p);\n        if (raw === null) {\n          raw = `Error loading ${p}`;\n        }\n        return {\n          url: page.url,\n          fileSlug: page.fileSlug,\n          inputContent: raw,\n          data: {\n            title: page.data?.title || '',\n            aliases: page.data?.aliases || []\n          }\n        };\n      })\n      .filter(Boolean)\n  );\n}\n\nfunction conceptMapJSONLD(pages = []) {\n  return JSON.stringify(generateConceptMapJSONLD(pages));\n}\n\nexport {\n  conceptMapJSONLD,\n  readableDate,\n  htmlDateString,\n  limit,\n  jsonify,\n  readingTime,\n  slugify,\n  truncate,\n  webpageToMarkdown,\n  isNew,\n  shout,\n  money,\n  yesNo,\n  humanDate,\n  titleizeSlug,\n  hostname,\n  absoluteUrl,\n  provenanceSources,\n  provenanceViewerUrl,\n  provenanceDownloadUrl,\n  url_encode,\n};\n\n// Defer default export assembly until end of file (so we can include helper filters)\n\n// ---- Archive utility filters (field counts, status) ----\n// These are appended to the default export at runtime by register.mjs\n// but also exported as named functions for direct import if needed.\n\n/** Determine if a value is considered present/non-empty */\nfunction _isPresent(v) {\n  if (v == null) return false;\n  if (typeof v === 'string') return v.trim().length > 0;\n  if (Array.isArray(v)) return v.length > 0;\n  if (typeof v === 'object') return Object.keys(v).length > 0;\n  return true; // numbers/booleans\n}\n\n/** Count fields on an object, excluding known system keys. */\nfunction fieldCounts(obj = {}, excludeKeys = []) {\n  try {\n    const o = (obj && typeof obj === 'object') ? obj : {};\n    const sys = new Set([\n      // lineage + slugs\n      'industry','industrySlug','category','categorySlug','company','companySlug','line','lineSlug','section','locale',\n      // computed/meta\n      '__source','__rel','url','title','lineTitle','companyTitle','categoryTitle','industryTitle',\n      // ids/slugs\n      'productSlug','product_id','charSlug','name','seriesSlug',\n      // eleventy internals occasionally present\n      'page','collections'\n    ].concat(Array.isArray(excludeKeys) ? excludeKeys : []));\n\n    const keys = Object.keys(o).filter((k) => !sys.has(k));\n    const total = keys.length;\n    let present = 0;\n    for (const k of keys) if (_isPresent(o[k])) present += 1;\n    return { total, present };\n  } catch {\n    return { total: 0, present: 0 };\n  }\n}\n\n/** Convenience: return present/total as a string like \"12/18\". */\nfunction fieldRatio(obj = {}, excludeKeys = []) {\n  const { total, present } = fieldCounts(obj, excludeKeys);\n  return `${present}/${total}`;\n}\n\n/** Safe length for arrays; 0 otherwise */\nfunction len(v) { return Array.isArray(v) ? v.length : 0; }\n\nexport { fieldCounts, fieldRatio, len };\n\n// Assemble default export with all filters (including helpers above)\nconst __defaultFilters = {\n  conceptMapJSONLD,\n  readableDate,\n  htmlDateString,\n  limit,\n  jsonify,\n  readingTime,\n  slugify,\n  truncate,\n  webpageToMarkdown,\n  isNew,\n  shout,\n  money,\n  yesNo,\n  humanDate,\n  titleizeSlug,\n  hostname,\n  provenanceSources,\n  provenanceViewerUrl,\n  provenanceDownloadUrl,\n  url_encode,\n  fieldCounts,\n  fieldRatio,\n  len,\n};\n\nexport default __defaultFilters;\n",
  "config/constants.js": "/**\n * Shared site-wide constants.\n * @module constants\n */\n\nimport path from 'node:path';\n\n/** Root directory for markdown content */\nexport const baseContentPath = 'src/content';\n\n/** Absolute path to concepts directory */\nexport const CONCEPTS_DIR = path.join(baseContentPath, 'concepts');\n\n/** Primary content areas used for collections and navigation */\nexport const CONTENT_AREAS = ['sparks', 'concepts', 'projects', 'archives', 'meta'];\nexport default { baseContentPath, CONTENT_AREAS, CONCEPTS_DIR };\n",
  "config/markdown/footnotes.js": "/**\n * Footnote rendering tweaks for markdown-it.\n * - Enhances footnote references with inline popovers\n * - Renders footnotes as styled cards where they appear in the markdown\n * - Connects blockquotes that immediately follow footnote definitions\n * @module footnotes\n */\n\n/**\n * Enhanced footnote rendering that keeps footnotes where they are in the markdown\n * and connects adjacent blockquotes to footnote content.\n * @param {import('markdown-it')} md markdown-it instance\n */\nfunction hybridFootnoteDefinitions(md) {\n  // Override footnote block rendering to use our card style\n  md.renderer.rules.footnote_block_open = () => {\n    return '<div class=\"footnotes-hybrid\">\\n';\n  };\n\n  md.renderer.rules.footnote_block_close = () => {\n    return '</div>\\n';\n  };\n\n  md.renderer.rules.footnote_open = (tokens, idx, options, env, slf) => {\n    const id = slf.rules.footnote_anchor_name(tokens, idx, options, env, slf);\n    const n = Number(tokens[idx].meta.id + 1).toString();\n    \n    return `<aside class=\"footnote-aside not-prose\" role=\"note\">\n  <div id=\"fn${id}\" class=\"footnote-local\">\n    <div class=\"footnote-content\">`;\n  };\n\n  md.renderer.rules.footnote_close = () => {\n    return `    </div>\n  </div>\n</aside>\\n`;\n  };\n\n  md.renderer.rules.footnote_anchor = (tokens, idx, options, env, slf) => {\n    const id = slf.rules.footnote_anchor_name(tokens, idx, options, env, slf);\n    return `    <a href=\"#fnref${id}\" class=\"footnote-backref\">â†©ï¸Ž</a>\\n`;\n  };\n\n  // Track when we're inside a footnote for blockquote styling\n  let insideFootnote = false;\n  \n  const origFootnoteOpen = md.renderer.rules.footnote_open;\n  const origFootnoteClose = md.renderer.rules.footnote_close;\n  \n  md.renderer.rules.footnote_open = function(tokens, idx, options, env, slf) {\n    insideFootnote = true;\n    return origFootnoteOpen ? origFootnoteOpen(tokens, idx, options, env, slf) : '';\n  };\n  \n  md.renderer.rules.footnote_close = function(tokens, idx, options, env, slf) {\n    insideFootnote = false;\n    return origFootnoteClose ? origFootnoteClose(tokens, idx, options, env, slf) : '';\n  };\n\n  // Style blockquotes that appear within footnotes\n  const origBQOpen = md.renderer.rules.blockquote_open || ((tokens, idx) => '<blockquote>');\n  const origBQClose = md.renderer.rules.blockquote_close || ((tokens, idx) => '</blockquote>');\n\n  md.renderer.rules.blockquote_open = function(tokens, idx, options, env, slf) {\n    if (insideFootnote) {\n      return '<blockquote class=\"footnote-explanation\">';\n    }\n    return origBQOpen(tokens, idx, options, env, slf);\n  };\n\n  md.renderer.rules.blockquote_close = function(tokens, idx, options, env, slf) {\n    return origBQClose(tokens, idx, options, env, slf);\n  };\n}\n\n/**\n * Replace footnote references with popover-enabled anchors.\n * @param {import('markdown-it')} md markdown-it instance\n */\nfunction footnotePopover(md) {\n  const originalFootnoteRef = md.renderer.rules.footnote_ref;\n  if (!originalFootnoteRef) return;\n\n  md.renderer.rules.footnote_ref = function(tokens, idx, options, env, self) {\n    const { id, subId = 0, label = '' } = tokens[idx].meta || {};\n    const list = env.footnotes && env.footnotes.list;\n    \n    if (!Array.isArray(list) || !list[id]) {\n      return originalFootnoteRef(tokens, idx, options, env, self);\n    }\n    \n    const n = id + 1;\n    const footnoteData = list[id];\n    \n    // Render the footnote content for the popover\n    let defHtml = '';\n    try {\n      if (footnoteData.tokens && Array.isArray(footnoteData.tokens)) {\n        // Create a temporary environment for rendering\n        const tempEnv = { ...env };\n        defHtml = md.renderer.render(footnoteData.tokens, options, tempEnv).trim();\n      } else if (footnoteData.content) {\n        defHtml = footnoteData.content;\n      }\n      \n      // Clean up HTML for popover display and separate source attribution\n      defHtml = defHtml\n        .replace(/<\\/?blockquote[^>]*>/g, '')\n        .replace(/<\\/?p[^>]*>/g, '')\n        .replace(/\\n+/g, ' ')\n        .replace(/\\s+/g, ' ')\n        .replace(/\\s*Source:(.*?)(<a href=\"#fnref)/i, '<br><span class=\"footnote-source\">Source:$1</span>$2')\n        .trim();\n        \n    } catch (error) {\n      console.warn('Error rendering footnote content for popover:', error);\n      return originalFootnoteRef(tokens, idx, options, env, self);\n    }\n    \n    const refId = `${n}${subId > 0 ? `:${subId}` : ''}`;\n    const caption = `[${n}${subId > 0 ? `:${subId}` : ''}]`;\n\n    return `<sup class=\"annotation-ref${label ? ' ' + label : ''}\">` +\n           `<a href=\"#fn${n}\" id=\"fnref${refId}\" class=\"annotation-anchor\" aria-describedby=\"popup-${refId}\">${caption}</a>` +\n           `<span id=\"popup-${refId}\" role=\"tooltip\" class=\"annotation-popup\">${defHtml}</span>` +\n           `</sup>`;\n  };\n}\n\n/**\n * Collect footnote tokens so popovers can render full markup.\n * @param {import('markdown-it')} md markdown-it instance\n */\nfunction collectFootnoteTokens(md) {\n  md.core.ruler.after('footnote_tail', 'collect_footnote_tokens', state => {\n    const list = state.env.footnotes && state.env.footnotes.list;\n    if (!Array.isArray(list)) return;\n\n    const tokens = state.tokens;\n    for (let i = 0; i < tokens.length; i++) {\n      if (tokens[i].type === 'footnote_open') {\n        const id = tokens[i].meta.id;\n        let j = i + 1;\n        while (j < tokens.length && tokens[j].type !== 'footnote_close') {\n          j++;\n        }\n        list[id].tokens = tokens.slice(i + 1, j);\n        i = j;\n      }\n    }\n  });\n}\n\n/**\n * Connect blockquotes that immediately follow footnote definitions.\n * This runs during the parsing phase to merge adjacent content.\n * @param {import('markdown-it')} md markdown-it instance\n */\nfunction connectFootnoteBlockquotes(md) {\n  md.core.ruler.after('inline', 'connect_footnote_blockquotes', state => {\n    const tokens = state.tokens;\n    const newTokens = [];\n    let i = 0;\n    \n    while (i < tokens.length) {\n      const token = tokens[i];\n      newTokens.push(token);\n      \n      // Look for footnote_reference_close followed by blockquote_open\n      if (token.type === 'footnote_reference_close') {\n        let j = i + 1;\n        \n        // Skip any whitespace/paragraph tokens\n        while (j < tokens.length && \n               (tokens[j].type === 'paragraph_open' || \n                tokens[j].type === 'paragraph_close' ||\n                (tokens[j].type === 'inline' && !tokens[j].content.trim()))) {\n          j++;\n        }\n        \n        // If we find a blockquote, it belongs to this footnote\n        if (j < tokens.length && tokens[j].type === 'blockquote_open') {\n          // Find the matching blockquote_close\n          let level = 0;\n          let k = j;\n          \n          while (k < tokens.length) {\n            if (tokens[k].type === 'blockquote_open') level++;\n            if (tokens[k].type === 'blockquote_close') {\n              level--;\n              if (level === 0) break;\n            }\n            k++;\n          }\n          \n          // Move all the blockquote tokens inside the footnote\n          // by inserting them before the footnote_reference_close\n          const blockquoteTokens = tokens.slice(j, k + 1);\n          \n          // Remove the blockquote tokens from their original position\n          // We'll skip them when we continue the main loop\n          newTokens.pop(); // Remove the footnote_reference_close we just added\n          \n          // Add blockquote tokens\n          newTokens.push(...blockquoteTokens);\n          \n          // Add the footnote_reference_close back\n          newTokens.push(token);\n          \n          // Skip past the blockquote tokens in the main loop\n          i = k + 1;\n          continue;\n        }\n      }\n      \n      i++;\n    }\n    \n    state.tokens = newTokens;\n  });\n}\n\n/**\n * Disable the default footnote tail if you don't want footnotes at the end.\n * Comment this out if you want both inline AND end-of-document footnotes.\n * @param {import('markdown-it')} md markdown-it instance\n */\nfunction disableFootnoteTail(md) {\n  // md.core.ruler.disable('footnote_tail');\n  // Leave footnote_tail enabled so footnotes render where they are in the markdown\n}\n\nexport {\n  hybridFootnoteDefinitions,\n  footnotePopover,\n  collectFootnoteTokens,\n  connectFootnoteBlockquotes,\n  disableFootnoteTail,\n};\n\nexport default {\n  hybridFootnoteDefinitions,\n  footnotePopover,\n  collectFootnoteTokens,\n  connectFootnoteBlockquotes,\n  disableFootnoteTail,\n};",
  "config/markdown/links.js": "/**\n * Add an external-link class and arrow to outbound links.\n * @param {import('markdown-it')} md - markdown-it instance\n */\nexport function externalLinks(md) {\n  const base = md.renderer.rules.link_open || ((t, i, o, e, s) => s.renderToken(t, i, o));\n  md.renderer.rules.link_open = (tokens, idx, options, env, self) => {\n    const href = tokens[idx].attrGet('href') || '';\n    const isExternal = /^https?:\\/\\//.test(href);\n    if (isExternal) {\n      tokens[idx].attrJoin('class', 'external-link');\n      const nxt = tokens[idx + 1];\n      if (nxt?.type === 'text' && !nxt.content.trim().startsWith('â†—')) {\n        nxt.content = `â†— ${nxt.content}`;\n      }\n    }\n    return base(tokens, idx, options, env, self);\n  };\n}\n\nexport default { externalLinks };\n",
  "config/markdown/inlineMacros.js": "/**\n * Helper to define simple inline macros.\n * @param {string} name - macro name\n * @param {string} after - rule to insert after\n * @param {(value:string)=>string} toHtml - HTML generator\n */\nconst toStringSafe = (v) => (v == null ? '' : (typeof v === 'string' ? v : String(v)));\n\nexport const inlineMacro = (name, after, toHtml) => (md) => {\n  const regex = new RegExp(`^@${name}\\\\(([^)]+)\\\\)`);\n  md.inline.ruler.after(after, name, (state, silent) => {\n    if (!state || typeof state.src !== 'string' || typeof state.pos !== 'number') return false;\n    const src = state.src;\n    const start = Math.max(0, state.pos | 0);\n    const slice = src.slice(start);\n    const m = slice.match(regex);\n    if (!m) return false;\n    if (!silent) state.push({ type: 'html_inline', content: toHtml(toStringSafe(m[1])) });\n    state.pos += m[0].length;\n    return true;\n  });\n};\n\n/** Inline audio embedding macro */\nexport const audioEmbed = inlineMacro('audio', 'emphasis', src => `<audio controls class=\"audio-embed\" src=\"${src}\"></audio>`);\n\n/** Inline QR-code embedding macro */\nexport const qrEmbed = inlineMacro('qr', 'audio', s => {\n  const src = encodeURIComponent(s);\n  return `<img class=\"qr-code\" src=\"https://api.qrserver.com/v1/create-qr-code/?size=150x150&data=${src}\" alt=\"QR code\">`;\n});\n\nexport default { inlineMacro, audioEmbed, qrEmbed };\n",
  "config/markdown/index.js": "// lib/markdown/index.js\nimport {\n  hybridFootnoteDefinitions,\n  footnotePopover,\n  collectFootnoteTokens,\n  connectFootnoteBlockquotes,\n  disableFootnoteTail,\n} from \"./footnotes.js\";\nimport { audioEmbed, qrEmbed } from \"./inlineMacros.js\";\nimport { externalLinks } from \"./links.js\";\n\n/**\n * Array of markdown-it extension functions to apply.\n * NOTE: anchors are configured in eleventy.config.mjs, so not added here.\n */\nconst mdItExtensions = [\n  // anchors, // <-- remove this reference\n  hybridFootnoteDefinitions,\n  footnotePopover,\n  collectFootnoteTokens,\n  connectFootnoteBlockquotes,\n  disableFootnoteTail,\n  audioEmbed,\n  qrEmbed,\n  externalLinks,\n];\n\nexport function applyMarkdownExtensions(md) {\n  mdItExtensions.forEach((fn) => {\n    try { fn(md); } catch (err) {\n      console.error(`[md-it] Failed extension: ${err?.message || err}`);\n    }\n  });\n  return md;\n}\n\nexport {\n  hybridFootnoteDefinitions,\n  footnotePopover,\n  collectFootnoteTokens,\n  connectFootnoteBlockquotes,\n  disableFootnoteTail,\n  audioEmbed,\n  qrEmbed,\n  externalLinks,\n  mdItExtensions,\n};\n\nexport default {\n  hybridFootnoteDefinitions,\n  footnotePopover,\n  collectFootnoteTokens,\n  connectFootnoteBlockquotes,\n  disableFootnoteTail,\n  audioEmbed,\n  qrEmbed,\n  externalLinks,\n  mdItExtensions,\n  applyMarkdownExtensions,\n};\n",
  "config/register.mjs": "// lib/eleventy/register.mjs\nimport markdownItFootnote from \"markdown-it-footnote\";\nimport markdownItAttrs from \"markdown-it-attrs\";\nimport markdownItAnchor from \"markdown-it-anchor\";\nimport markdownItShiki from \"@shikijs/markdown-it\";\nimport { transformerNotationDiff, transformerNotationHighlight } from \"@shikijs/transformers\";\nimport { eleventyImageTransformPlugin } from \"@11ty/eleventy-img\";\nimport path from \"node:path\";\nimport fs from \"node:fs\";\nimport slugify from \"slugify\";\nimport { dirs } from \"../config.js\";\nimport { icons } from \"lucide\";\nimport defaultAttributes from \"lucide/dist/esm/defaultAttributes.js\";\n\nimport getPlugins from \"../plugins.js\";\nimport filters from \"../filters.js\";\nimport { applyMarkdownExtensions } from \"../markdown/index.js\";\nimport { specnote } from \"../shortcodes.js\";\nimport { CONTENT_AREAS, baseContentPath } from \"../constants.js\";\nimport { runPostcssAll } from \"../postcss.js\";\nimport { summarizeAndGate } from \"../interlinkers/unresolved-report.mjs\";\nimport { snapshotDocs } from \"../../tools/docs-snapshot.mjs\";\n\nconst glob = (d) => `${baseContentPath}/${d}/**/*.md`;\n\nexport default function register(eleventyConfig) {\n  const plugins = getPlugins();\n  plugins.forEach(([plugin, opts = {}]) => eleventyConfig.addPlugin(plugin, opts));\n\n  if (process.env.ELEVENTY_ENV !== \"test\") {\n    eleventyConfig.ignores.add(\"test/**\");\n    eleventyConfig.ignores.add(\"src/test/**\");\n  }\n\n  const isTest = process.env.ELEVENTY_ENV === \"test\";\n  const allowImages = process.env.ELEVENTY_TEST_ENABLE_IMAGES === \"1\";\n\n  // Markdown (Shiki @ build time, footnotes, attrs, anchors)\n  eleventyConfig.amendLibrary(\"md\", (md) => {\n    md.use(markdownItShiki, {\n      themes: { light: \"github-light\", dark: \"github-dark\" },\n      transformers: [\n        {\n          pre(node) {\n            node.properties.tabindex = 0;\n          },\n          line(node, i) {\n            node.properties[\"data-line\"] = i + 1;\n          },\n        },\n        transformerNotationDiff(),\n        transformerNotationHighlight(),\n      ],\n    });\n    md.use(markdownItFootnote);\n    md.use(markdownItAttrs);\n    md.use(\n      markdownItAnchor,\n      {\n        permalink: markdownItAnchor.permalink.headerLink({\n          symbol: \"#\",\n          class: \"heading-anchor\",\n          placement: \"before\",\n        }),\n      }\n    );\n    applyMarkdownExtensions(md);\n    return md;\n  });\n\n  // Server-side Lucide (for macros like components/icons.njk)\n  // lucide@0.5xx exports icons as arrays under PascalCase keys (e.g., Sun, FlaskConical).\n  // This filter accepts kebab-case (\"sun\", \"flask-conical\") and renders inline SVG strings.\n  eleventyConfig.addFilter(\"lucide\", (name, attrs = {}) => {\n    try {\n      if (!name || typeof name !== \"string\") return \"\";\n\n      // Convert kebab/underscore/space to PascalCase expected by lucide exports\n      const toPascal = (s) =>\n        s\n          .split(/[:._\\-\\s]+/)\n          .filter(Boolean)\n          .map((p) => p.charAt(0).toUpperCase() + p.slice(1))\n          .join(\"\");\n\n      const key = toPascal(name);\n      const node = icons[key] || icons[name] || icons[name?.charAt(0)?.toUpperCase() + name?.slice(1)] ;\n      if (!node) return \"\";\n\n      const attrsMerged = { ...defaultAttributes, ...attrs };\n      const esc = (v) => String(v).replace(/&/g, \"&amp;\").replace(/\"/g, \"&quot;\");\n      const toAttrString = (obj) =>\n        Object.entries(obj)\n          .filter(([k, v]) => v !== false && v != null)\n          .map(([k, v]) => `${k}=\"${esc(v)}\"`)\n          .join(\" \");\n\n      const children = Array.isArray(node)\n        ? node\n            .map(([tag, a = {}, kids]) => {\n              const inner = Array.isArray(kids)\n                ? kids\n                    .map(([t, aa = {}]) => `<${t} ${toAttrString(aa)} />`)\n                    .join(\"\")\n                : \"\";\n              return `<${tag} ${toAttrString(a)}${inner ? `>${inner}</${tag}>` : \" />\"}`;\n            })\n            .join(\"\")\n        : \"\";\n\n      return `<svg ${toAttrString(attrsMerged)}>${children}</svg>`;\n    } catch (e) {\n      return \"\";\n    }\n  });\n\n  // Project filters\n  Object.entries(filters).forEach(([key, value]) => {\n    eleventyConfig.addFilter(key, value);\n  });\n\n  // Content-area collections\n  const singular = { sparks: \"spark\", concepts: \"concept\", projects: \"project\", meta: \"meta\" };\n  const workAreas = [\"sparks\", \"concepts\", \"projects\", \"meta\"];\n\n  CONTENT_AREAS.forEach((name) => {\n    eleventyConfig.addCollection(name, (api) =>\n      api\n        .getFilteredByGlob(glob(name))\n        .sort((a, b) => b.date - a.date)\n        .map((page) => {\n          page.data.type = singular[name];\n          return page;\n        })\n    );\n  });\n\n  eleventyConfig.addCollection(\"work\", (api) =>\n    workAreas\n      .flatMap((name) =>\n        api.getFilteredByGlob(glob(name)).map((page) => ({\n          url: page.url,\n          data: page.data,\n          date: page.date,\n          type: singular[name],\n        }))\n      )\n      .sort((a, b) => b.date - a.date)\n  );\n\n  // JSONL Provenance viewer entries (SSR or client-rendered)\n  // Scans src/content/archives for *.jsonl and exposes metadata for pagination\n  eleventyConfig.addCollection(\"jsonlProvenance\", () => {\n    const base = path.join('src','content','archives');\n    const toPosix = (p) => p.replaceAll('\\\\','/');\n    const out = [];\n    const walk = (d) => {\n      if (!fs.existsSync(d)) return;\n      for (const ent of fs.readdirSync(d, { withFileTypes: true })) {\n        const p = path.join(d, ent.name);\n        if (ent.isDirectory()) walk(p);\n        else if (ent.isFile() && p.endsWith('.jsonl')) {\n          const rel = toPosix(path.relative(base, p));\n          const parts = rel.split('/');\n          const industry = parts[0], category = parts[1], company = parts[2], line = parts[3];\n          const baseName = path.basename(p, '.jsonl');\n          const slug = baseName.replace(/--+/g, '-');\n          out.push({\n            abs: p,\n            rel,\n            industry,\n            category,\n            company,\n            line,\n            base: baseName,\n            slug,\n            rawUrl: `/content/${rel}`,\n            viewerUrl: `/archives/${industry}/${category}/${company}/${line}/provenance/${slug}/`,\n          });\n        }\n      }\n    };\n    walk(base);\n    return out.sort((a,b)=> a.base.localeCompare(b.base));\n  });\n\n  // Group JSONL entries by directory (industry/category/company/line)\n  eleventyConfig.addCollection(\"jsonlDirs\", () => {\n    const base = path.join('src','content','archives');\n    const toPosix = (p) => p.replaceAll('\\\\','/');\n    const out = [];\n    const walk = (d) => {\n      if (!fs.existsSync(d)) return;\n      for (const ent of fs.readdirSync(d, { withFileTypes: true })) {\n        const p = path.join(d, ent.name);\n        if (ent.isDirectory()) walk(p);\n        else if (ent.isFile() && p.endsWith('.jsonl')) {\n          const rel = toPosix(path.relative(base, p));\n          const parts = rel.split('/');\n          out.push({\n            rel,\n            industry: parts[0], category: parts[1], company: parts[2], line: parts[3],\n            base: path.basename(p, '.jsonl'),\n            slug: path.basename(p, '.jsonl').replace(/--+/g, '-'),\n            rawUrl: `/content/${rel}`,\n          });\n        }\n      }\n    };\n    walk(base);\n    const groups = new Map();\n    for (const f of out) {\n      const relDir = [f.industry, f.category, f.company, f.line].join('/');\n      if (!groups.has(relDir)) groups.set(relDir, []);\n      groups.get(relDir).push(f);\n    }\n    return Array.from(groups.entries()).map(([rel, items]) => ({ rel, url: `/content/archives/${rel}/`, items: items.sort((a,b)=> a.base.localeCompare(b.base)) }));\n  });\n\n  eleventyConfig.addCollection(\"nodes\", (api) =>\n    api\n      .getFilteredByGlob(CONTENT_AREAS.map(glob))\n      .map((page) => {\n        const type = singular[CONTENT_AREAS.find((a) => page.inputPath.includes(a))];\n        if (type) page.data.type = type;\n        return page;\n      })\n      .sort((a, b) => b.date - a.date)\n  );\n\n  // Images\n  if (!isTest || allowImages) {\n    eleventyConfig.addPlugin(eleventyImageTransformPlugin, {\n      urlPath: \"/assets/images/\",\n      outputDir: path.join(dirs.output, \"assets/images/\"),\n      formats: [\"avif\", \"webp\", \"auto\"],\n      widths: [320, 640, 960, 1200, 1800, \"auto\"],\n      htmlOptions: {\n        imgAttributes: { loading: \"lazy\", decoding: \"async\" },\n        pictureAttributes: {},\n      },\n      filenameFormat: (id, src, width, format) => {\n        const { name } = path.parse(src);\n        const s = slugify(name, { lower: true, strict: true });\n        return `${s}-${width}.${format}`;\n      },\n    });\n  }\n\n  // Assets & watches\n  eleventyConfig.addPassthroughCopy({ \"src/scripts\": \"assets/js\" });\n  eleventyConfig.addPassthroughCopy({ \"src/favicon.ico\": \"favicon.ico\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/static\": \"assets\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/css\": \"assets/css\" });\n  // Intentionally avoid publishing /content/**; JSONL is re-published under /archives/**.\n  // Keep namespaced copies under /assets/icons for direct references\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons\": \"assets/icons\" });\n  // Also publish key icons + manifest to web root for standard link tags\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons/favicon.svg\": \"favicon.svg\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons/favicon-96x96.png\": \"favicon-96x96.png\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons/apple-touch-icon.png\": \"apple-touch-icon.png\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons/site.webmanifest\": \"site.webmanifest\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons/web-app-manifest-192x192.png\": \"web-app-manifest-192x192.png\" });\n  eleventyConfig.addPassthroughCopy({ \"src/assets/icons/web-app-manifest-512x512.png\": \"web-app-manifest-512x512.png\" });\n  eleventyConfig.addWatchTarget(\"src/styles\");\n  eleventyConfig.addWatchTarget(\"src/assets/static\");\n  // Watch archives so raw JSONL changes live-reload in dev\n  eleventyConfig.addWatchTarget(\"src/content/archives\");\n  eleventyConfig.addWatchTarget(\"tailwind.config.mjs\");\n  eleventyConfig.addWatchTarget(\"postcss.config.mjs\");\n\n  // Eleventy Dev Server (v3) â€” enable DOM-diffing and watch compiled CSS for quick injection\n  if (eleventyConfig.setServerOptions) {\n    // Always serve .jsonl with a proper NDJSON content type in dev\n    const onRequest = {\n      \"/content/:rest*\": ({ url, patternGroups }) => {\n        const rest = patternGroups?.rest || \"\";\n        const rel = path.posix.join(\"content\", rest);\n        const abs = path.join(dirs.output, rel);\n        if (!fs.existsSync(abs)) return; // let static chain decide (likely 404)\n        const isDir = fs.statSync(abs).isDirectory();\n        if (isDir) {\n          const entries = fs.readdirSync(abs, { withFileTypes: true });\n          const rows = entries\n            .sort((a,b)=> a.name.localeCompare(b.name))\n            .map(ent => {\n              const href = url.pathname.replace(/\\/$/, \"\") + \"/\" + ent.name + (ent.isDirectory()? \"/\" : \"\");\n              const label = ent.name + (ent.isDirectory()? \"/\" : \"\");\n              return `<li><a class=\"link\" href=\"${href}\">${label}</a></li>`;}\n            ).join(\"\\n\");\n          const up = url.pathname.replace(/\\/$/, \"\").split(\"/\").slice(0,-1).join(\"/\") + \"/\";\n          const body = `<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/><title>Index of ${url.pathname}</title><link rel=\"stylesheet\" href=\"/assets/css/app.css\"/></head><body><main class=\"p-4 max-w-4xl mx-auto\"><h1 class=\"text-xl font-mono mb-3\">Index of ${url.pathname}</h1><p class=\"mb-3\"><a class=\"link\" href=\"${up}\">../</a></p><ul class=\"space-y-1\">${rows}</ul></main></body></html>`;\n          return { headers: { \"Content-Type\": \"text/html; charset=utf-8\" }, body };\n        }\n        // File response\n        const ext = path.extname(abs).toLowerCase();\n        const headers = {};\n        if (ext === \".jsonl\") headers[\"Content-Type\"] = \"application/x-ndjson; charset=utf-8\";\n        else if (ext === \".json\") headers[\"Content-Type\"] = \"application/json; charset=utf-8\";\n        else headers[\"Content-Type\"] = \"application/octet-stream\";\n        if (url.searchParams.get(\"download\") === \"1\") {\n          const filename = path.basename(abs);\n          headers[\"Content-Disposition\"] = `attachment; filename=\\\"${filename}\\\"`;\n        }\n        const body = fs.readFileSync(abs);\n        return { headers, body };\n      },\n      // Dev-only dynamic viewer for provenance JSONL using Shiki\n      \"/archives/:industry/:category/:company/:line/provenance/:slug\": async ({ url, patternGroups }) => {\n        try {\n          const { codeToHtml } = await import('shiki');\n          const { industry, category, company, line, slug } = patternGroups;\n          const baseDir = path.join('src','content','archives', industry, category, company, line, 'provenance');\n          if (!fs.existsSync(baseDir)) return;\n          const toSlug = (b) => String(b).replace(/--+/g, '-');\n          const files = fs.readdirSync(baseDir).filter(f => f.endsWith('.jsonl'));\n          const match = files.find(f => toSlug(f.replace(/\\.jsonl$/, '')) === slug);\n          if (!match) return; // let static try (likely 404)\n          const abs = path.join(baseDir, match);\n          const code = fs.readFileSync(abs, 'utf8');\n          const html = await codeToHtml(code, { lang: 'jsonl', themes: { light: 'github-light', dark: 'github-dark' } });\n          const title = match.replace(/\\.jsonl$/, '');\n          const rawUrl = `/content/archives/${industry}/${category}/${company}/${line}/provenance/${match}`;\n          const body = `\n<!doctype html>\n<html lang=\"en\">\n<head>\n  <meta charset=\"utf-8\" />\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n  <title>Provenance â€” ${title}</title>\n  <link rel=\"stylesheet\" href=\"/assets/css/app.css\" />\n  <style>main{max-width:72rem;margin:0 auto;padding:1rem}</style>\n  </head>\n<body>\n  <main>\n    <nav class=\"breadcrumbs text-sm mb-2 overflow-x-auto whitespace-nowrap\" aria-label=\"Breadcrumb\">\n      <ul>\n        <li><a href=\"/archives/\">Archives</a></li>\n        <li><a href=\"/archives/${industry}/\">${industry}</a></li>\n        <li><a href=\"/archives/${industry}/${category}/\">${category}</a></li>\n        <li><a href=\"/archives/${industry}/${category}/${company}/\">${company}</a></li>\n        <li><a href=\"/archives/${industry}/${category}/${company}/${line}/\">${line}</a></li>\n        <li class=\"opacity-70\">Provenance</li>\n      </ul>\n    </nav>\n    <header class=\"mb-4\">\n      <h1 class=\"font-heading text-3xl uppercase tracking-[-0.02em] text-primary mb-1\">${title}</h1>\n      <div class=\"text-sm opacity-80 space-x-3\">\n        <a class=\"link\" href=\"${rawUrl}\">View raw JSONL</a>\n        <a class=\"link\" href=\"${rawUrl}?download=1\">Download</a>\n      </div>\n    </header>\n    <section class=\"card bg-base-100 border shadow-sm\">\n      <div class=\"card-body p-0\">\n        <div class=\"overflow-auto\" style=\"max-height: 70vh\">${html}</div>\n      </div>\n    </section>\n  </main>\n</body>\n</html>`;\n          return { headers: { 'Content-Type': 'text/html; charset=utf-8' }, body };\n        } catch (e) {\n          console.error('[jsonl viewer] error', e);\n        }\n      },\n      \"/archives/:industry/:category/:company/:line/provenance/:slug/\": async (args) => onRequest[\"/archives/:industry/:category/:company/:line/provenance/:slug\"](args),\n    };\n    eleventyConfig.setServerOptions({\n      showAllHosts: true,\n      domDiff: true,\n      port: 8080,\n      encoding: \"utf-8\",\n      watch: [\"_site/assets/css/**/*.css\"],\n      onRequest,\n    });\n  } else {\n    // Fallback for BrowserSync\n    eleventyConfig.setBrowserSyncConfig({\n      index: \"index.html\",\n      server: { baseDir: \"_site\" },\n      files: [\"_site/assets/css/**/*.css\"],\n    });\n  }\n\n  eleventyConfig.addShortcode(\"specnote\", specnote);\n\n  if (!isTest) {\n    eleventyConfig.on(\"eleventy.before\", async () => {\n      console.log(\"ðŸš€ Eleventy build starting with enhanced footnote system...\");\n      // Always attempt to snapshot docs (non-fatal on errors)\n      //try { await snapshotDocs(); } catch (e) { console.warn(\"[docs-snapshot] skipped:\", e?.message || e); }\n      if (process.env.CSS_WATCH === \"1\") return; // external watcher handles CSS\n      await runPostcssAll([\n        { src: \"src/styles/app.tailwind.css\", dest: \"src/assets/css/app.css\" },\n        { src: \"src/styles/mschf-overlay.css\", dest: \"src/assets/css/mschf-overlay.css\" },\n      ]);\n    });\n    eleventyConfig.on(\"eleventy.after\", ({ results }) => {\n      console.log(`âœ… Eleventy build completed. Generated ${results.length} files.`);\n      try { summarizeAndGate(); } catch (e) { console.error(String(e?.message || e)); process.exitCode = 1; }\n    });\n  }\n}\n",
  "config/interlinkers/resolvers.mjs": "// lib/interlinkers/resolvers.mjs\n// Generalized resolvers powered by the Route Registry; crash-safe and dynamic-by-default.\n\nimport { routeRegistry, getByPath } from './route-registry.mjs';\nimport { recordUnresolved } from './unresolved-report.mjs';\n\nconst toStr = (v) => (v == null ? '' : String(v));\nconst slugify = (s) => toStr(s)\n  .normalize('NFKD')\n  .toLowerCase()\n  .replace(/[^\\w\\s-]/g, '')\n  .trim()\n  .replace(/\\s+/g, '-')\n  .replace(/-+/g, '-');\n\nconst escapeHtml = (str) => toStr(str)\n  .replaceAll('&', '&amp;')\n  .replaceAll('<', '&lt;')\n  .replaceAll('>', '&gt;')\n  .replaceAll('\"', '&quot;')\n  .replaceAll(\"'\", '&#39;');\n\nfunction buildIndex(kind, arr) {\n  const def = routeRegistry.kinds[kind];\n  const idx = new Map();\n  const put = (key, entry) => {\n    const k = slugify(key);\n    if (k) idx.set(k, entry);\n  };\n  for (const entry of arr ?? []) {\n    const data = entry?.data || entry; // collections expose page objects; archives expose { data }\n    const href = entry?.url || def.canonicalFromData(data);\n    const labels = [data?.title, data?.name, data?.product_id, data?.seriesSlug, data?.charSlug, entry?.fileSlug].filter(Boolean);\n    const record = { href, data, labels };\n    for (const kf of def.keyFields) {\n      const v = kf.includes('.') ? getByPath(entry, kf) || getByPath(record, kf) : (data?.[kf] ?? entry?.[kf]);\n      if (v) put(v, record);\n    }\n    for (const a of def.aliasesFromData(data)) put(a, record);\n  }\n  return idx;\n}\n\nfunction localePrefix(currentPage) {\n  if (!routeRegistry.localePrefixEnabled) return '';\n  const pageLocale = currentPage?.data?.locale || currentPage?.data?.page?.lang || routeRegistry.defaultLocale;\n  return pageLocale && pageLocale !== routeRegistry.defaultLocale ? `/${pageLocale}` : '';\n}\n\nfunction guessHref(kind, nameSlug, currentPage) {\n  const def = routeRegistry.kinds[kind];\n  const prefix = localePrefix(currentPage);\n  return `${prefix}${def.basePath}/${nameSlug}/`;\n}\n\nfunction resolverFor(kind) {\n  const def = routeRegistry.kinds[kind];\n  if (!def) throw new Error(`Unknown kind: ${kind}`);\n  return (link, currentPage /*, interlinker */) => {\n    try {\n      const data = currentPage?.data || {};\n      let dataset = [];\n      for (const key of def.datasetKeys) {\n        const arr = getByPath(data, key);\n        if (Array.isArray(arr) && arr.length) { dataset = arr; break; }\n      }\n      const index = buildIndex(kind, dataset);\n      const wantSlug = slugify(link?.name);\n      const entry = index.get(wantSlug);\n      let href = entry?.href || def.canonicalFromData(entry?.data || {});\n      const prefix = localePrefix(currentPage);\n      if (prefix && typeof href === 'string' && href.startsWith('/')) href = prefix + href;\n      if (!entry) href = guessHref(kind, wantSlug, currentPage);\n      const label = escapeHtml(link?.title || entry?.data?.title || entry?.labels?.find(Boolean) || link?.name);\n      if (!entry) {\n        recordUnresolved({ kind, key: link?.name, sourcePage: currentPage?.inputPath || currentPage?.data?.page?.inputPath || null, guessedKind: kind, attemptedKinds: [kind] });\n        link.href = href;\n        return `<a class=\"interlink interlink--${kind} interlink--soft\" href=\"${href}\">${label}</a>`;\n      }\n      link.href = href;\n      return `<a class=\"interlink interlink--${kind}\" href=\"${href}\">${label}</a>`;\n    } catch (e) {\n      const wantSlug = slugify(link?.name);\n      const href = guessHref(kind, wantSlug, currentPage);\n      const label = escapeHtml(link?.title || link?.name);\n      return `<a class=\"interlink interlink--${kind} interlink--soft\" href=\"${href}\">${label}</a>`;\n    }\n  };\n}\n\nfunction dispatcherForOmittedKind() {\n  const order = routeRegistry.defaultKindsPriority;\n  const subResolvers = new Map(order.map((k) => [k, resolverFor(k)]));\n  return (link, currentPage /*, interlinker */) => {\n    const attempted = [];\n    const nameSlug = slugify(link?.name);\n    for (const kind of order) {\n      attempted.push(kind);\n      const html = subResolvers.get(kind)(link, currentPage);\n      // Soft links contain interlink--soft; if missing, we found a match\n      if (!/interlink--soft/.test(html)) return html;\n    }\n    // None resolved; record once with guesses\n    recordUnresolved({ kind: 'unknown', key: link?.name, sourcePage: currentPage?.inputPath || currentPage?.data?.page?.inputPath || null, guessedKind: order[0], attemptedKinds: attempted });\n    const href = guessHref(order[0], nameSlug, currentPage);\n    const label = escapeHtml(link?.title || link?.name);\n    return `<a class=\"interlink interlink--soft\" href=\"${href}\">${label}</a>`;\n  };\n}\n\nexport function createResolvers() {\n  const map = new Map();\n  // Default\n  map.set('default', (link) => {\n    const href = link.href || link.link || '#';\n    const label = link.title || link.name || href;\n    return `<a class=\"interlink\" href=\"${href}\">${label}</a>`;\n  });\n  // Named kinds\n  for (const kind of Object.keys(routeRegistry.kinds)) {\n    map.set(kind, resolverFor(kind));\n  }\n  // Back-compat synonyms: archive:product etc.\n  map.set('archive', (link, currentPage) => {\n    const raw = toStr(link?.name);\n    const idx = raw.indexOf(':');\n    if (idx === -1) return dispatcherForOmittedKind()(link, currentPage);\n    const type = raw.slice(0, idx).trim();\n    const name = raw.slice(idx + 1).trim();\n    const sub = map.get(type) || dispatcherForOmittedKind();\n    const next = { ...link, name };\n    return sub(next, currentPage);\n  });\n  map.set('archive:product', map.get('product'));\n  map.set('archive:character', map.get('character'));\n  map.set('archive:series', map.get('series'));\n  // Omitted kind dispatcher\n  map.set('omitted', dispatcherForOmittedKind());\n  return map;\n}\n",
  "config/interlinkers/unresolved-report.mjs": "// lib/interlinkers/unresolved-report.mjs\n// Stable unresolved link reporting with dedupe, schema, and CI gating.\n\nimport fs from 'node:fs';\nimport path from 'node:path';\n\nconst OUT_PATH = path.join('artifacts', 'reports', 'interlinker-unresolved.json');\nconst keyFor = (kind, key, sourcePage) => `${kind}::${key || ''}::${sourcePage || ''}`;\n\nconst state = {\n  map: new Map(), // key -> item\n  count: 0,\n};\n\nfunction toISO(d = new Date()) { return new Date(d).toISOString(); }\n\nexport function recordUnresolved({ kind, key, sourcePage, guessedKind, attemptedKinds }) {\n  const k = keyFor(kind, key, sourcePage);\n  if (!state.map.has(k)) {\n    state.map.set(k, {\n      kind,\n      key: String(key ?? ''),\n      sourcePage: sourcePage || null,\n      guessedKind: guessedKind || null,\n      attemptedKinds: Array.isArray(attemptedKinds) ? attemptedKinds : [],\n      when: toISO(),\n    });\n    state.count++;\n  }\n}\n\nexport function getUnresolvedItems() {\n  return Array.from(state.map.values());\n}\n\nexport function flushUnresolved() {\n  const items = getUnresolvedItems();\n  const payload = {\n    schemaVersion: 1,\n    generatedAt: toISO(),\n    count: items.length,\n    items,\n  };\n  fs.mkdirSync(path.dirname(OUT_PATH), { recursive: true });\n  fs.writeFileSync(OUT_PATH, JSON.stringify(payload, null, 2));\n  return payload;\n}\n\nfunction parseBool(v, fallback = false) {\n  if (v == null) return fallback;\n  const s = String(v).toLowerCase();\n  return s === '1' || s === 'true' || s === 'yes' || s === 'on';\n}\n\nfunction parseNum(v, fallback) {\n  const n = Number(v);\n  return Number.isFinite(n) ? n : fallback;\n}\n\nexport function summarizeAndGate() {\n  const isCI = parseBool(process.env.CI, false);\n  const defaultThreshold = isCI ? 200 : Infinity;\n  const maxUnresolved = parseNum(process.env.INTERLINKER_MAX_UNRESOLVED, defaultThreshold);\n  const shouldFail = parseBool(process.env.INTERLINKER_FAIL_ON_UNRESOLVED, false);\n\n  const payload = flushUnresolved();\n  const count = payload.count;\n  const action = shouldFail && count > maxUnresolved ? 'fail' : 'warn';\n  // eslint-disable-next-line no-console\n  console.log(`Interlinker: unresolved=${count} threshold=${maxUnresolved} action=${action}`);\n  if (action === 'fail') {\n    throw new Error(`Interlinker unresolved links (${count}) exceeded threshold (${maxUnresolved}).`);\n  }\n}\n\n// Auto-flush on exit to keep behavior consistent with prior array report\nprocess.on('exit', () => { try { flushUnresolved(); } catch {} });\nprocess.on('beforeExit', () => { try { flushUnresolved(); } catch {} });\nprocess.on('SIGINT', () => { try { flushUnresolved(); } catch {}; process.exit(130); });\nprocess.on('SIGTERM', () => { try { flushUnresolved(); } catch {}; process.exit(143); });\n",
  "config/interlinkers/archives-resolvers.mjs": "// lib/interlinkers/archives-resolvers.mjs\n// Canonical-aware wikilink resolvers that target dynamic Eleventy archive pages\n// produced by lib/eleventy/archives.mjs.\n//\n// Goals:\n// - Resolve against normalized data (slugCanonical, canonicalUrl, slugAliases, legacyPaths)\n// - Emit canonical URLs only (never alias/legacy)\n// - Be defensive: never call String.match on non-strings; normalize inputs\n// - Record unresolved wikilinks to artifacts/reports/interlinker-unresolved.json\n//\n// Usage examples in Markdown:\n//   [[series:lets-checkmate]]\n//   [[character:labubu|Labubu character]]\n//   [[product:pop-mart-the-monsters-labubu-best-of-luck-plush]]\n\nexport const toStringSafe = (v) => (v == null ? \"\" : String(v));\n\nconst slug = (s) =>\n  toStringSafe(s)\n    .normalize(\"NFKD\")\n    .toLowerCase()\n    .replace(/[^\\w\\s-]/g, \"\")\n    .trim()\n    .replace(/\\s+/g, \"-\")\n    .replace(/-+/g, \"-\");\n\nconst escapeHtml = (str) =>\n  toStringSafe(str)\n    .replaceAll(\"&\", \"&amp;\")\n    .replaceAll(\"<\", \"&lt;\")\n    .replaceAll(\">\", \"&gt;\")\n    .replaceAll('\"', \"&quot;\")\n    .replaceAll(\"'\", \"&#39;\");\n\nimport fs from \"node:fs\";\nimport path from \"node:path\";\n\n// --- Unresolved capture -------------------------------------------------\nconst unresolved = [];\nconst UNRESOLVED_OUT = path.join(\n  \"artifacts\",\n  \"reports\",\n  \"interlinker-unresolved.json\"\n);\n\nprocess.on(\"exit\", () => {\n  try {\n    fs.mkdirSync(path.dirname(UNRESOLVED_OUT), { recursive: true });\n    fs.writeFileSync(UNRESOLVED_OUT, JSON.stringify(unresolved, null, 2));\n  } catch {}\n});\n\nfunction recordUnresolved(kind, key, ctx = {}) {\n  unresolved.push({\n    kind,\n    key: String(key ?? \"\"),\n    sourcePage: ctx.sourcePage || null,\n  });\n}\n\n// Build a canonical-first index for a given archive list.\n// Keys are slugified to ensure robust matching.\nfunction buildIndex(type, list) {\n  const idx = new Map();\n  const put = (key, entry) => {\n    const k = slug(key);\n    if (k && !idx.has(k)) idx.set(k, entry);\n  };\n  for (const it of list ?? []) {\n    const d = it?.data ?? {};\n    const href = typeof d.canonicalUrl === \"string\" && d.canonicalUrl\n      ? d.canonicalUrl\n      : `/archives/${type}/${type === 'product' ? (d.slugCanonical || d.productSlug || d.slug) : (d.charSlug || d.seriesSlug || d.slug)}/`;\n    const label = d.title || d.name || d.product_id || d.productSlug || d.charSlug || d.seriesSlug || d.slug || href;\n    const entry = { href, label, data: d };\n\n    if (type === \"product\") {\n      // Priority: slugCanonical â†’ slugAliases[] â†’ legacyPaths[] â†’ ids/titles\n      put(d.slugCanonical, entry);\n      if (Array.isArray(d.slugAliases)) d.slugAliases.forEach((a) => put(a, entry));\n      if (Array.isArray(d.legacyPaths)) {\n        for (const p of d.legacyPaths) {\n          const str = typeof p === \"string\" ? p : \"\";\n          const m = str.match?.(/\\/archives\\/product\\/([^/]+)\\/?$/);\n          if (m && m[1]) put(m[1], entry);\n        }\n      }\n      put(d.productSlug, entry);\n      put(d.product_id, entry);\n      put(d.title, entry);\n    } else if (type === \"character\") {\n      put(d.charSlug, entry);\n      put(d.name, entry);\n      put(d.title, entry);\n    } else if (type === \"series\") {\n      put(d.seriesSlug, entry);\n      put(d.title, entry);\n    }\n  }\n  return idx;\n}\n\nfunction makeResolver(type, getList, pickLabel) {\n  return (link, currentPage /*, interlinker */) => {\n    try {\n      const list = getList(currentPage?.data ?? {});\n      const index = buildIndex(type, list);\n      const wantKey = slug(link?.name ?? \"\");\n      const entry = index.get(wantKey);\n      const canonical = `/archives/${type}/${wantKey}/`;\n\n      if (!entry) {\n        // Default to canonical dynamic route; record unresolved for analysis.\n        const raw = escapeHtml(link?.title || link?.name);\n        recordUnresolved(type, link?.name, {\n          sourcePage: currentPage?.inputPath || null,\n        });\n        link.href = canonical;\n        return `<a class=\"interlink interlink--${type} interlink--soft\" href=\"${canonical}\">${raw}</a>`;\n      }\n\n      const href = entry.href || canonical; // always canonical\n      const label = escapeHtml(link?.title || pickLabel(entry.data) || entry.label);\n      // Do not set link.exists here; we donâ€™t own Eleventy page objects for backlinks\n      link.href = href;\n      return `<a class=\"interlink interlink--${type}\" href=\"${href}\">${label}</a>`;\n    } catch {\n      const raw = escapeHtml(link?.title || link?.name);\n      const nameSlug = slug(link?.name);\n      const canonical = `/archives/${type}/${nameSlug}/`;\n      return `<a class=\"interlink interlink--${type} interlink--soft\" href=\"${canonical}\">${raw}</a>`;\n    }\n  };\n}\n\nexport function createArchiveResolvers() {\n  /**\n   * Accessors resolve from current page data, falling back to global names\n   * added via registerArchive(eleventyConfig.addGlobalData)\n   */\n  const getProducts = (data) => data.archiveProductsEn || data.archiveAllProducts || data.archiveProducts || [];\n  const getCharacters = (data) => data.archiveCharactersEn || data.archiveAllCharacters || data.archiveCharacters || [];\n  const getSeries = (data) => data.archiveSeriesEn || data.archiveAllSeries || data.archiveSeries || [];\n\n  const product = makeResolver('product', getProducts, (d) => d.title || d.product_id || d.productSlug);\n\n  const character = makeResolver('character', getCharacters, (d) => d.name || d.title || d.charSlug);\n\n  const series = makeResolver('series', getSeries, (d) => d.title || d.seriesSlug);\n\n  const map = new Map([\n    ['product', product],\n    ['character', character],\n    ['series', series],\n  ]);\n  // Generic dispatcher: [[archive:product:foo]] / [[archive:series:bar]]\n  map.set('archive', (link, currentPage) => {\n    const raw = String(link?.name ?? '');\n    const idx = raw.indexOf(':');\n    if (idx === -1) return character(link, currentPage); // default bias is character\n    const type = raw.slice(0, idx).trim();\n    const name = raw.slice(idx + 1).trim();\n    const sub = map.get(type) || character;\n    const next = { ...link, name };\n    return sub(next, currentPage);\n  });\n  // Synonyms prefixed with archive: to improve LLM legibility\n  map.set('archive:product', product);\n  map.set('archive:character', character);\n  map.set('archive:series', series);\n  return map;\n}\n",
  "config/interlinkers/route-registry.mjs": "// lib/interlinkers/route-registry.mjs\n// Central registry of linkable kinds and how to index/resolve them.\n\nfunction _defaultRegistry() {\n  return {\n    // Locale handling\n    defaultLocale: 'en',\n    localePrefixEnabled: false, // when true, prefix hrefs with /:locale/\n\n    // If a wikilink omits kind (e.g., [[labubu]]), check kinds in order\n    defaultKindsPriority: ['work', 'character', 'product', 'series', 'concept', 'project', 'spark', 'meta'],\n\n    // Kind definitions\n    kinds: {\n      // Archives â€” canonical dynamic routes\n      product: {\n        basePath: '/archives/product',\n        // Where to find items from current page context\n        datasetKeys: ['archiveProductsEn', 'archiveAllProducts', 'archiveProducts'],\n        keyFields: ['slugCanonical', 'productSlug', 'slug', 'product_id', 'title'],\n        canonicalFromData: (d) => `/archives/product/${d.slugCanonical || d.productSlug || d.slug}/`,\n        aliasesFromData: (d) => [\n          ...(Array.isArray(d.slugAliases) ? d.slugAliases : []),\n          ...(Array.isArray(d.legacyPaths) ? d.legacyPaths.map((p) => (typeof p === 'string' ? (p.match(/\\/archives\\/product\\/([^/]+)/)?.[1] || null) : null)).filter(Boolean) : []),\n        ],\n      },\n      character: {\n        basePath: '/archives/character',\n        datasetKeys: ['archiveCharactersEn', 'archiveAllCharacters', 'archiveCharacters'],\n        keyFields: ['charSlug', 'name', 'title', 'slug'],\n        canonicalFromData: (d) => `/archives/character/${d.charSlug || d.slug}/`,\n        aliasesFromData: () => [],\n      },\n      series: {\n        basePath: '/archives/series',\n        datasetKeys: ['archiveSeriesEn', 'archiveAllSeries', 'archiveSeries'],\n        keyFields: ['seriesSlug', 'title', 'slug'],\n        canonicalFromData: (d) => `/archives/series/${d.seriesSlug || d.slug}/`,\n        aliasesFromData: () => [],\n      },\n\n      // First-class content scaffolds\n      spark: {\n        basePath: '/sparks',\n        datasetKeys: ['collections.sparks'],\n        keyFields: ['fileSlug', 'data.title'],\n        canonicalFromData: (d) => `/sparks/${d.fileSlug || d.slug || ''}/`,\n        aliasesFromData: (d) => Array.isArray(d?.data?.aliases) ? d.data.aliases : [],\n      },\n      concept: {\n        basePath: '/concepts',\n        datasetKeys: ['collections.concepts'],\n        keyFields: ['fileSlug', 'data.title'],\n        canonicalFromData: (d) => `/concepts/${d.fileSlug || d.slug || ''}/`,\n        aliasesFromData: (d) => Array.isArray(d?.data?.aliases) ? d.data.aliases : [],\n      },\n      project: {\n        basePath: '/projects',\n        datasetKeys: ['collections.projects'],\n        keyFields: ['fileSlug', 'data.title'],\n        canonicalFromData: (d) => `/projects/${d.fileSlug || d.slug || ''}/`,\n        aliasesFromData: (d) => Array.isArray(d?.data?.aliases) ? d.data.aliases : [],\n      },\n      meta: {\n        basePath: '/meta',\n        datasetKeys: ['collections.meta'],\n        keyFields: ['fileSlug', 'data.title'],\n        canonicalFromData: (d) => `/meta/${d.fileSlug || d.slug || ''}/`,\n        aliasesFromData: (d) => Array.isArray(d?.data?.aliases) ? d.data.aliases : [],\n      },\n      // Work: aggregator over content areas\n      work: {\n        basePath: '/work',\n        datasetKeys: ['collections.work', 'collections.sparks', 'collections.concepts', 'collections.projects', 'collections.meta'],\n        keyFields: ['fileSlug', 'data.title'],\n        canonicalFromData: (d) => d?.url || `/${d?.data?.type || 'work'}/${d?.fileSlug || ''}/`,\n        aliasesFromData: (d) => Array.isArray(d?.data?.aliases) ? d.data.aliases : [],\n      },\n    },\n  };\n}\n\nimport fs from 'node:fs';\nimport path from 'node:path';\n\nfunction _mergeFromDiscovery(reg) {\n  try {\n    const p = path.join('artifacts','reports','interlinker-discovery.json');\n    if (!fs.existsSync(p)) return reg;\n    const disc = JSON.parse(fs.readFileSync(p, 'utf8'));\n    if (disc?.i18n) {\n      reg.defaultLocale = disc.i18n.defaultLocale || reg.defaultLocale;\n      reg.localePrefixEnabled = !!disc.i18n.localePrefixes;\n    }\n    if (Array.isArray(disc?.scaffoldMap)) {\n      const order = disc.scaffoldMap.map(k => k.kind);\n      if (order.length) reg.defaultKindsPriority = order;\n      for (const k of disc.scaffoldMap) {\n        if (reg.kinds[k.kind]) {\n          reg.kinds[k.kind].datasetKeys = Array.isArray(k.datasetKeys) && k.datasetKeys.length ? k.datasetKeys : reg.kinds[k.kind].datasetKeys;\n          reg.kinds[k.kind].basePath = k.base || reg.kinds[k.kind].basePath;\n        } else {\n          // Generic kind using discovery base/datasets; shallow semantics\n          reg.kinds[k.kind] = {\n            basePath: `/${k.base?.replace(/^\\//,'') || k.kind}`,\n            datasetKeys: Array.isArray(k.datasetKeys) ? k.datasetKeys : [],\n            keyFields: Array.isArray(k.keyFields) ? k.keyFields : ['slug','fileSlug','title'],\n            canonicalFromData: (d) => `${`/${k.base?.replace(/^\\//,'') || k.kind}`}/${d.slug || d.fileSlug || ''}/`,\n            aliasesFromData: (d) => Array.isArray(d?.slugAliases) ? d.slugAliases : [],\n          };\n        }\n      }\n    }\n  } catch {}\n  return reg;\n}\n\n// Initialize registry and attempt to hydrate from discovery artifact if present\nexport const routeRegistry = _mergeFromDiscovery(_defaultRegistry());\n\n// Helper to read a nested key like 'collections.work'\nexport function getByPath(obj, key) {\n  if (!obj || !key) return undefined;\n  const parts = key.split('.');\n  let cur = obj;\n  for (const p of parts) {\n    if (cur && typeof cur === 'object' && p in cur) cur = cur[p];\n    else return undefined;\n  }\n  return cur;\n}\n",
  "config/css/postcss.js": "import fs from 'node:fs/promises'; // Use the promises API for async operations\nimport path from 'node:path';\nimport postcss from 'postcss';\nimport loadPostcssPlugins from './postcssPlugins.mjs';\n\n/**\n * Compiles a CSS file using PostCSS with plugins from the project config.\n * Skips processing when the destination is newer than the source in production.\n *\n * @param {string} inputPath  Source CSS file path\n * @param {string} outputPath Destination path for compiled CSS\n * @returns {Promise<void>}\n */\nexport default async function runPostcss(inputPath, outputPath) {\n  const isDev = process.env.ELEVENTY_SERVE === 'true' || process.env.NODE_ENV !== 'production';\n\n  // In production, check if the output file is already up-to-date\n  if (!isDev) {\n    try {\n      const [inputStat, outStat] = await Promise.all([\n        fs.stat(inputPath),\n        fs.stat(outputPath)\n      ]);\n      // If the output file exists and is newer than the input file, skip processing\n      if (outStat.mtimeMs >= inputStat.mtimeMs) {\n        console.log(`[PostCSS] Skipping ${inputPath} (already up-to-date).`);\n        return;\n      }\n    } catch (error) {\n      // If the output file doesn't exist, stat will throw an error, which is fine.\n      // We just continue to process the file.\n      if (error.code !== 'ENOENT') {\n        throw error; // Re-throw any other type of error\n      }\n    }\n  }\n\n  try {\n    const css = await fs.readFile(inputPath, 'utf8');\n    const plugins = await loadPostcssPlugins();\n    const result = await postcss(plugins).process(css, {\n      from: inputPath,\n      to: outputPath,\n      map: { inline: true }\n    });\n\n    // Ensure the output directory exists before writing the file\n    await fs.mkdir(path.dirname(outputPath), { recursive: true });\n    await fs.writeFile(outputPath, result.css);\n\n    console.log(`[PostCSS] Compiled ${inputPath} -> ${outputPath}`);\n  } catch (error) {\n    console.error(`[PostCSS Error] Failed to process ${inputPath}:`, error);\n    throw error; // Re-throw the error to be handled by the caller\n  }\n}\n\n/**\n * Compile multiple CSS files sequentially via PostCSS.\n *\n * @param {Array<{ src: string, dest: string }>} entries\n * Files to process: each object should define `src` and `dest` paths.\n * @returns {Promise<void>}\n */\nexport async function runPostcssAll(entries = []) {\n  for (const { src, dest } of entries) {\n    await runPostcss(src, dest);\n  }\n}\n",
  "config/css/postcssPlugins.mjs": "import postcssConfig from '../postcss.config.mjs';\n\nexport default async function loadPostcssPlugins() {\n  const plugins = postcssConfig.plugins || [];\n  if (Array.isArray(plugins)) return plugins;\n  const loaded = await Promise.all(\n    Object.entries(plugins).map(async ([name, opts]) => (await import(name)).default(opts)),\n  );\n  return loaded;\n}\n",
  "config/plugins.js": "// lib/eleventy/getPlugins.js\n\nimport interlinker from \"@photogabble/eleventy-plugin-interlinker\";\nimport navigation from \"@11ty/eleventy-navigation\";\nimport rss from \"@11ty/eleventy-plugin-rss\";\nimport sitemap from \"@quasibit/eleventy-plugin-sitemap\";\nimport schema from \"@quasibit/eleventy-plugin-schema\";\nimport { createResolvers } from \"./interlinkers/resolvers.mjs\";\nimport { summarizeAndGate } from \"./interlinkers/unresolved-report.mjs\";\n\nexport default function getPlugins() {\n\n  return [\n    [\n      interlinker,\n      {\n        defaultLayout: \"layouts/embed.njk\",\n        resolvingFns: createResolvers(),\n        deadLinkReport: \"json\", // can be \"console\" or \"none\"\n      },\n    ],\n    [navigation],\n    [rss],\n    [sitemap, { sitemap: { hostname: \"https://effusionlabs.com\" } }],\n    [schema],\n  ];\n}\n",
  "config/archives.mjs": "// ESM only; no external deps\nimport fs from \"node:fs\";\nimport path from \"node:path\";\nimport { slugCanonicalProduct } from \"../naming-canon.mjs\";\n\nconst TYPES = [\"products\", \"characters\", \"series\"];\n\n// Accept both layouts: src/content/archives OR src/archives (or plain archives)\nconst CANDIDATES = [\n  path.join(\"src\", \"content\", \"archives\"),\n  path.join(\"src\", \"archives\"),\n  \"archives\",\n];\n\nconst toPosix = (p) => p.replaceAll(\"\\\\\", \"/\");\nconst exists = (p) => { try { return fs.existsSync(p); } catch { return false; } };\nconst ARCHIVES_BASE = CANDIDATES.find(exists) ?? CANDIDATES[0]; // best-effort\n\n// Tiny, safe slugify (no dep)\nfunction slugify(s) {\n  return String(s ?? \"\")\n    .normalize(\"NFKD\")\n    .toLowerCase()\n    .replace(/[^\\w\\s-]/g, \"\")\n    .trim()\n    .replace(/\\s+/g, \"-\")\n    .replace(/-+/g, \"-\") || \"item\";\n}\n\nfunction titleFromSlug(slug) {\n  return String(slug || \"\")\n    .split(\"-\")\n    .filter(Boolean)\n    .map((w) => w[0]?.toUpperCase() + w.slice(1))\n    .join(\" \");\n}\n\nfunction walkJsonFiles(dirAbs) {\n  const out = [];\n  if (!exists(dirAbs)) return out;\n  for (const ent of fs.readdirSync(dirAbs, { withFileTypes: true })) {\n    const p = path.join(dirAbs, ent.name);\n    if (ent.isDirectory()) out.push(...walkJsonFiles(p));\n    else if (ent.isFile() && p.endsWith(\".json\")) out.push(p);\n  }\n  return out;\n}\n\n// Parse path â†’ industry/category/company/line/section/locale\nfunction parsePath(absPath) {\n  const rel = toPosix(path.relative(ARCHIVES_BASE, absPath));\n  const parts = rel.split(\"/\");\n  const file = parts.at(-1);\n  let section, line, company, category, industry, locale = \"en\";\n\n  const i18nIdx = parts.lastIndexOf(\"i18n\");\n  if (i18nIdx !== -1) {\n    locale   = parts[i18nIdx + 1] || \"en\";\n    section  = parts[i18nIdx + 2];\n    line     = parts[i18nIdx - 1];\n    company  = parts[i18nIdx - 2];\n    category = parts[i18nIdx - 3];\n    industry = parts[i18nIdx - 4];\n  } else {\n    section  = parts.at(-2);\n    line     = parts.at(-3);\n    company  = parts.at(-4);\n    category = parts.at(-5);\n    industry = parts.at(-6);\n  }\n\n  return {\n    file,\n    section,\n    line,\n    company,\n    category,\n    industry,\n    locale,\n    rel,\n  };\n}\n\nfunction buildUrl({ industry, category, company, line, section, slug }) {\n  return `/archives/${industry}/${category}/${company}/${line}/${section}/${slug}/`;\n}\n\nfunction normalizeData(absPath) {\n  const raw = JSON.parse(fs.readFileSync(absPath, \"utf8\"));\n  const { section, line, company, category, industry, locale } = parsePath(absPath);\n  const fileSlug = path.basename(absPath, \".json\");\n\n  // IDs/slugs by section\n  const productId   = raw.product_id ?? raw.id ?? raw.slug ?? fileSlug;\n  const characterId = raw.slug ?? raw.name ?? raw.character ?? fileSlug;\n  const seriesId    = raw.slug ?? raw.title ?? fileSlug;\n\n  const lineSlug    = slugify(line);\n  const companySlug = slugify(company);\n  const categorySlug= slugify(category);\n  const industrySlug= slugify(industry);\n\n  const data = {\n    // lineage\n    industry, industrySlug,\n    category, categorySlug,\n    company,  companySlug,\n    line,     lineSlug,\n    section,  locale,\n\n    __source: toPosix(absPath),\n    __rel: toPosix(path.relative(ARCHIVES_BASE, absPath)),\n\n    product_id: productId,\n    productSlug: slugify(productId),\n    name: raw.name ?? null,\n    charSlug: slugify(characterId),\n    seriesSlug: slugify(seriesId),\n    title: raw.title ?? raw.name ?? productId,\n\n    ...raw,\n  };\n\n  if (section === \"products\") {\n    let slugCanonical = slugCanonicalProduct(raw);\n    if (!slugCanonical || slugCanonical === \"item\") slugCanonical = data.productSlug;\n    data.slugCanonical = slugCanonical;\n    data.canonicalUrl = `/archives/product/${slugCanonical}/`;\n\n    // Aliases and legacy path handling\n    const aliasSet = new Set();\n    if (data.productSlug && data.productSlug !== data.slugCanonical) aliasSet.add(data.productSlug);\n    if (Array.isArray(raw.slugAliases)) raw.slugAliases.forEach((s)=> s && aliasSet.add(slugify(s)));\n    data.slugAliases = Array.from(aliasSet);\n\n    data.urlLegacy = buildUrl({\n      industry: industrySlug, category: categorySlug, company: companySlug,\n      line: lineSlug, section: \"products\", slug: data.productSlug,\n    });\n    data.legacyPaths = [data.urlLegacy, ...data.slugAliases.map((a)=> `/archives/product/${a}/`)];\n  } else if (section === \"characters\") {\n    data.canonicalUrl = `/archives/character/${data.charSlug}/`;\n    data.urlLegacy = buildUrl({\n      industry: industrySlug, category: categorySlug, company: companySlug,\n      line: lineSlug, section: \"characters\", slug: data.charSlug,\n    });\n  } else if (section === \"series\") {\n    data.canonicalUrl = `/archives/series/${data.seriesSlug}/`;\n    data.urlLegacy = buildUrl({\n      industry: industrySlug, category: categorySlug, company: companySlug,\n      line: lineSlug, section: \"series\", slug: data.seriesSlug,\n    });\n  }\n\n  data.lineTitle    = titleFromSlug(line);\n  data.companyTitle = titleFromSlug(company);\n  data.categoryTitle= titleFromSlug(category);\n  data.industryTitle= titleFromSlug(industry);\n\n  return { data };\n}\n\nfunction aggregateCompanies(items) {\n  const map = new Map();\n  for (const it of items) {\n    const d = it.data;\n    const key = `${d.industrySlug}/${d.categorySlug}/${d.companySlug}`;\n    if (!map.has(key)) {\n      map.set(key, {\n        key,\n        industry: d.industry, industrySlug: d.industrySlug,\n        category: d.category, categorySlug: d.categorySlug,\n        company:  d.company,  companySlug:  d.companySlug,\n        companyTitle: d.companyTitle,\n        lines: new Map(),\n      });\n    }\n    const comp = map.get(key);\n    if (!comp.lines.has(d.lineSlug)) {\n      comp.lines.set(d.lineSlug, {\n        lineSlug: d.lineSlug,\n        lineTitle: d.lineTitle,\n      });\n    }\n  }\n  return Array.from(map.values()).map((c) => ({\n    ...c,\n    lines: Array.from(c.lines.values()).sort((a,b)=>a.lineTitle.localeCompare(b.lineTitle)),\n  })).sort((a,b)=>a.companyTitle.localeCompare(b.companyTitle));\n}\n\n// Public API ------------------------------------------------------------\nexport default function registerArchive(eleventyConfig) {\n  const files = walkJsonFiles(ARCHIVES_BASE);\n  const normalized = files\n    .map(normalizeData)\n    .filter((it) => TYPES.includes(it.data.section));\n\n  const archiveProducts   = normalized.filter((it) => it.data.section === \"products\");\n  const archiveCharacters = normalized.filter((it) => it.data.section === \"characters\");\n  const archiveSeries     = normalized.filter((it) => it.data.section === \"series\");\n\n  // Locale-scoped unique helpers\n  const uniqueBy = (arr, key) => {\n    const seen = new Set();\n    const out = [];\n    for (const x of arr) {\n      const v = x?.data?.[key];\n      if (!seen.has(v)) { seen.add(v); out.push(x); }\n    }\n    return out;\n  };\n  const archiveProductsEn   = uniqueBy(archiveProducts.filter(x => x.data.locale === 'en'), 'productSlug');\n  const archiveCharactersEn = uniqueBy(archiveCharacters.filter(x => x.data.locale === 'en'), 'charSlug');\n  const archiveSeriesEn     = uniqueBy(archiveSeries.filter(x => x.data.locale === 'en'), 'seriesSlug');\n\n  eleventyConfig.addCollection(\"archiveProducts\",   () => archiveProducts);\n  eleventyConfig.addCollection(\"archiveCharacters\", () => archiveCharacters);\n  eleventyConfig.addCollection(\"archiveSeries\",     () => archiveSeries);\n\n  eleventyConfig.addFilter(\"byLine\",     (arr, lineSlug)     => (arr ?? []).filter((x) => x.data.lineSlug === slugify(lineSlug)));\n  eleventyConfig.addFilter(\"byCompany\",  (arr, companySlug)  => (arr ?? []).filter((x) => x.data.companySlug === slugify(companySlug)));\n  eleventyConfig.addFilter(\"byLocale\",   (arr, locale)       => (arr ?? []).filter((x) => x.data.locale === (locale || \"en\")));\n  eleventyConfig.addFilter(\"uniqueBy\",   (arr, key) => {\n    const seen = new Set(); const out = [];\n    for (const x of arr ?? []) { const v = x?.data?.[key]; if (!seen.has(v)) { seen.add(v); out.push(x); } }\n    return out;\n  });\n\n  const companies = aggregateCompanies(normalized);\n  const linesFlat = normalized\n    .map((it) => ({\n      industry: it.data.industry, industrySlug: it.data.industrySlug,\n      category: it.data.category, categorySlug: it.data.categorySlug,\n      company:  it.data.company,  companySlug:  it.data.companySlug,\n      line:     it.data.line,     lineSlug:    it.data.lineSlug,\n      lineTitle:it.data.lineTitle,\n    }))\n    .filter((v, i, arr) => arr.findIndex(x => x.lineSlug === v.lineSlug && x.companySlug === v.companySlug) === i)\n    .sort((a,b)=> a.lineTitle.localeCompare(b.lineTitle));\n\n  if (typeof eleventyConfig.addGlobalData === \"function\") {\n    eleventyConfig.addGlobalData(\"archiveCompanies\", companies);\n    eleventyConfig.addGlobalData(\"archiveLines\", linesFlat);\n    eleventyConfig.addGlobalData(\"archiveAllProducts\", archiveProducts);\n    eleventyConfig.addGlobalData(\"archiveAllCharacters\", archiveCharacters);\n    eleventyConfig.addGlobalData(\"archiveAllSeries\", archiveSeries);\n    eleventyConfig.addGlobalData(\"archiveProductsEn\", archiveProductsEn);\n    eleventyConfig.addGlobalData(\"archiveCharactersEn\", archiveCharactersEn);\n    eleventyConfig.addGlobalData(\"archiveSeriesEn\", archiveSeriesEn);\n  }\n\n  console.log(`ðŸ—‚  Archives loaded from \"${ARCHIVES_BASE}\": ${normalized.length} items (${archiveProducts.length} products, ${archiveCharacters.length} characters, ${archiveSeries.length} series)`);\n\n  // Collision handling\n  const collisions = new Map();\n  const canonIndex = new Map();\n  for (const it of archiveProducts) {\n    const canon = it.data.slugCanonical || it.data.productSlug;\n    if (canonIndex.has(canon)) {\n      if (!collisions.has(canon)) collisions.set(canon, []);\n      collisions.get(canon).push(it);\n    } else {\n      canonIndex.set(canon, it);\n    }\n  }\n\n  for (const [slug, items] of collisions.entries()) {\n    let counter = 2;\n    for (const it of items) {\n      const newSlug = `${slug}-v${counter++}`;\n      it.data.slugCanonical = newSlug;\n      it.data.canonicalUrl = `/archives/product/${newSlug}/`;\n      const s = new Set(it.data.slugAliases || []);\n      s.add(slug);\n      it.data.slugAliases = Array.from(s);\n      it.data.legacyPaths = [it.data.urlLegacy, ...it.data.slugAliases.map((a)=> `/archives/product/${a}/`)];\n    }\n  }\n\n  eleventyConfig.addGlobalData(\"archiveProductMap\", archiveProducts.map(p => ({\n    id: p.data.product_id,\n    title: p.data.title || p.data.product_title || p.data.product_id,\n    slugCanonical: p.data.slugCanonical,\n    canonicalUrl: p.data.canonicalUrl,\n    slugAliases: p.data.slugAliases || [],\n    legacyPaths: p.data.legacyPaths || [],\n  })));\n}",
  "config/shortcodes.js": "/**\n * Shortcodes for Eleventy templates.\n * @module shortcodes\n */\n\n/**\n * Render an inline specification note span.\n *\n * @param {string} variant - Style variant name\n * @param {string} content - Inner HTML content\n * @param {string} [tooltip] - Optional tooltip text\n * @returns {string} HTML string\n */\nexport function specnote(variant, content, tooltip) {\n  const cls = {\n    soft: 'spec-note-soft',\n    subtle: 'spec-note-subtle',\n    liminal: 'spec-note-liminal',\n    archival: 'spec-note-archival',\n    ghost: 'spec-note-ghost'\n  }[variant] || 'spec-note-soft';\n\n  const safeTooltip = tooltip?.replace(/\"/g, '&quot;') || '';\n  return `<span class=\"${cls}\" title=\"${safeTooltip}\">${content}</span>`;\n}\n\nexport default { specnote };\n"
}
